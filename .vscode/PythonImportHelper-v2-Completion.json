[
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "NamedTuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "open3d",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "open3d",
        "description": "open3d",
        "detail": "open3d",
        "documentation": {}
    },
    {
        "label": "small_gicp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "small_gicp",
        "description": "small_gicp",
        "detail": "small_gicp",
        "documentation": {}
    },
    {
        "label": "NDArray",
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "isExtraImport": true,
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "NDArray",
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "isExtraImport": true,
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "NDArray",
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "isExtraImport": true,
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "NDArray",
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "isExtraImport": true,
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "NDArray",
        "importPath": "numpy.typing",
        "description": "numpy.typing",
        "isExtraImport": true,
        "detail": "numpy.typing",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Tensor",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "Visualizer",
        "importPath": "open3d.visualization",
        "description": "open3d.visualization",
        "isExtraImport": true,
        "detail": "open3d.visualization",
        "documentation": {}
    },
    {
        "label": "BaseDataset",
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "isExtraImport": true,
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "get_data_set",
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "isExtraImport": true,
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "to_tensor",
        "importPath": "src.data.utils",
        "description": "src.data.utils",
        "isExtraImport": true,
        "detail": "src.data.utils",
        "documentation": {}
    },
    {
        "label": "to_tensor",
        "importPath": "src.data.utils",
        "description": "src.data.utils",
        "isExtraImport": true,
        "detail": "src.data.utils",
        "documentation": {}
    },
    {
        "label": "depth_to_points",
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "isExtraImport": true,
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "depth_to_normal",
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "isExtraImport": true,
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "nerfview",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nerfview",
        "description": "nerfview",
        "detail": "nerfview",
        "documentation": {}
    },
    {
        "label": "Viewer",
        "importPath": "nerfview",
        "description": "nerfview",
        "isExtraImport": true,
        "detail": "nerfview",
        "documentation": {}
    },
    {
        "label": "LearnedPerceptualImagePatchSimilarity",
        "importPath": "torchmetrics.image",
        "description": "torchmetrics.image",
        "isExtraImport": true,
        "detail": "torchmetrics.image",
        "documentation": {}
    },
    {
        "label": "PeakSignalNoiseRatio",
        "importPath": "torchmetrics.image",
        "description": "torchmetrics.image",
        "isExtraImport": true,
        "detail": "torchmetrics.image",
        "documentation": {}
    },
    {
        "label": "StructuralSimilarityIndexMeasure",
        "importPath": "torchmetrics.image",
        "description": "torchmetrics.image",
        "isExtraImport": true,
        "detail": "torchmetrics.image",
        "documentation": {}
    },
    {
        "label": "PeakSignalNoiseRatio",
        "importPath": "torchmetrics.image",
        "description": "torchmetrics.image",
        "isExtraImport": true,
        "detail": "torchmetrics.image",
        "documentation": {}
    },
    {
        "label": "StructuralSimilarityIndexMeasure",
        "importPath": "torchmetrics.image",
        "description": "torchmetrics.image",
        "isExtraImport": true,
        "detail": "torchmetrics.image",
        "documentation": {}
    },
    {
        "label": "viser",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "viser",
        "description": "viser",
        "detail": "viser",
        "documentation": {}
    },
    {
        "label": "ViserServer",
        "importPath": "viser",
        "description": "viser",
        "isExtraImport": true,
        "detail": "viser",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "natsorted",
        "importPath": "natsort",
        "description": "natsort",
        "isExtraImport": true,
        "detail": "natsort",
        "documentation": {}
    },
    {
        "label": "scipy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy",
        "description": "scipy",
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "NDArray",
        "importPath": "numpy._typing",
        "description": "numpy._typing",
        "isExtraImport": true,
        "detail": "numpy._typing",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "importPath": "src.data.base",
        "description": "src.data.base",
        "isExtraImport": true,
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "importPath": "src.data.base",
        "description": "src.data.base",
        "isExtraImport": true,
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "src.data.base",
        "description": "src.data.base",
        "isExtraImport": true,
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "importPath": "src.data.base",
        "description": "src.data.base",
        "isExtraImport": true,
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "Config",
        "importPath": "src.data.base",
        "description": "src.data.base",
        "isExtraImport": true,
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "importPath": "src.data.base",
        "description": "src.data.base",
        "isExtraImport": true,
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "importPath": "src.data.base",
        "description": "src.data.base",
        "isExtraImport": true,
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "Scan2ScanICP",
        "importPath": "src.component",
        "description": "src.component",
        "isExtraImport": true,
        "detail": "src.component",
        "documentation": {}
    },
    {
        "label": "RGBDImage",
        "importPath": "src.data.Image",
        "description": "src.data.Image",
        "isExtraImport": true,
        "detail": "src.data.Image",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "importPath": "src.eval.logger",
        "description": "src.eval.logger",
        "isExtraImport": true,
        "detail": "src.eval.logger",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "importPath": "src.eval.logger",
        "description": "src.eval.logger",
        "isExtraImport": true,
        "detail": "src.eval.logger",
        "documentation": {}
    },
    {
        "label": "calculate_rotation_error_np",
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "isExtraImport": true,
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "calculate_translation_error_np",
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "isExtraImport": true,
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "isExtraImport": true,
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "isExtraImport": true,
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "isExtraImport": true,
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "isExtraImport": true,
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "wandb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wandb",
        "description": "wandb",
        "detail": "wandb",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "kornia",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "kornia",
        "description": "kornia",
        "detail": "kornia",
        "documentation": {}
    },
    {
        "label": "geometry",
        "importPath": "kornia",
        "description": "kornia",
        "isExtraImport": true,
        "detail": "kornia",
        "documentation": {}
    },
    {
        "label": "geometry",
        "importPath": "kornia",
        "description": "kornia",
        "isExtraImport": true,
        "detail": "kornia",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "importPath": "gsplat",
        "description": "gsplat",
        "isExtraImport": true,
        "detail": "gsplat",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "importPath": "gsplat",
        "description": "gsplat",
        "isExtraImport": true,
        "detail": "gsplat",
        "documentation": {}
    },
    {
        "label": "quat_scale_to_covar_preci",
        "importPath": "gsplat",
        "description": "gsplat",
        "isExtraImport": true,
        "detail": "gsplat",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "importPath": "gsplat",
        "description": "gsplat",
        "isExtraImport": true,
        "detail": "gsplat",
        "documentation": {}
    },
    {
        "label": "quat_scale_to_covar_preci",
        "importPath": "gsplat",
        "description": "gsplat",
        "isExtraImport": true,
        "detail": "gsplat",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "default_timer",
        "importPath": "timeit",
        "description": "timeit",
        "isExtraImport": true,
        "detail": "timeit",
        "documentation": {}
    },
    {
        "label": "default_timer",
        "importPath": "timeit",
        "description": "timeit",
        "isExtraImport": true,
        "detail": "timeit",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tqdm",
        "description": "tqdm",
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "AlignData",
        "importPath": "src.data",
        "description": "src.data",
        "isExtraImport": true,
        "detail": "src.data",
        "documentation": {}
    },
    {
        "label": "Parser",
        "importPath": "src.data",
        "description": "src.data",
        "isExtraImport": true,
        "detail": "src.data",
        "documentation": {}
    },
    {
        "label": "AlignData",
        "importPath": "src.data",
        "description": "src.data",
        "isExtraImport": true,
        "detail": "src.data",
        "documentation": {}
    },
    {
        "label": "Parser",
        "importPath": "src.data",
        "description": "src.data",
        "isExtraImport": true,
        "detail": "src.data",
        "documentation": {}
    },
    {
        "label": "TUM",
        "importPath": "src.data",
        "description": "src.data",
        "isExtraImport": true,
        "detail": "src.data",
        "documentation": {}
    },
    {
        "label": "Replica",
        "importPath": "src.data",
        "description": "src.data",
        "isExtraImport": true,
        "detail": "src.data",
        "documentation": {}
    },
    {
        "label": "RGBDImage",
        "importPath": "src.data",
        "description": "src.data",
        "isExtraImport": true,
        "detail": "src.data",
        "documentation": {}
    },
    {
        "label": "ExperimentBase",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "ExperimentBase",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "ICPExperiment",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "RegistrationConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "ICPExperiment",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "RegistrationConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "ICPExperiment",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "RegistrationConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "isExtraImport": true,
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Optimizer",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "Namespace",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "Runner",
        "importPath": "src.my_gsplat.gs_trainer_total",
        "description": "src.my_gsplat.gs_trainer_total",
        "isExtraImport": true,
        "detail": "src.my_gsplat.gs_trainer_total",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "show_image",
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "isExtraImport": true,
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "visualize_dataset",
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "isExtraImport": true,
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "exp",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "exp",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "exp",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "imageio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imageio",
        "description": "imageio",
        "detail": "imageio",
        "documentation": {}
    },
    {
        "label": "PlyData",
        "importPath": "plyfile",
        "description": "plyfile",
        "isExtraImport": true,
        "detail": "plyfile",
        "documentation": {}
    },
    {
        "label": "PlyElement",
        "importPath": "plyfile",
        "description": "plyfile",
        "isExtraImport": true,
        "detail": "plyfile",
        "documentation": {}
    },
    {
        "label": "PlyData",
        "importPath": "plyfile",
        "description": "plyfile",
        "isExtraImport": true,
        "detail": "plyfile",
        "documentation": {}
    },
    {
        "label": "PlyElement",
        "importPath": "plyfile",
        "description": "plyfile",
        "isExtraImport": true,
        "detail": "plyfile",
        "documentation": {}
    },
    {
        "label": "distCUDA2",
        "importPath": "simple_knn._C",
        "description": "simple_knn._C",
        "isExtraImport": true,
        "detail": "simple_knn._C",
        "documentation": {}
    },
    {
        "label": "RGB2SH",
        "importPath": "src.utils.gaussian_model_utils",
        "description": "src.utils.gaussian_model_utils",
        "isExtraImport": true,
        "detail": "src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "build_scaling_rotation",
        "importPath": "src.utils.gaussian_model_utils",
        "description": "src.utils.gaussian_model_utils",
        "isExtraImport": true,
        "detail": "src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "get_expon_lr_func",
        "importPath": "src.utils.gaussian_model_utils",
        "description": "src.utils.gaussian_model_utils",
        "isExtraImport": true,
        "detail": "src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "importPath": "src.utils.gaussian_model_utils",
        "description": "src.utils.gaussian_model_utils",
        "isExtraImport": true,
        "detail": "src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "strip_symmetric",
        "importPath": "src.utils.gaussian_model_utils",
        "description": "src.utils.gaussian_model_utils",
        "isExtraImport": true,
        "detail": "src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "src.utils.gaussian_model_utils",
        "description": "src.utils.gaussian_model_utils",
        "isExtraImport": true,
        "detail": "src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "OptimizationParams",
        "importPath": "src.entities.arguments",
        "description": "src.entities.arguments",
        "isExtraImport": true,
        "detail": "src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "OptimizationParams",
        "importPath": "src.entities.arguments",
        "description": "src.entities.arguments",
        "isExtraImport": true,
        "detail": "src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "OptimizationParams",
        "importPath": "src.entities.arguments",
        "description": "src.entities.arguments",
        "isExtraImport": true,
        "detail": "src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "OptimizationParams",
        "importPath": "src.entities.arguments",
        "description": "src.entities.arguments",
        "isExtraImport": true,
        "detail": "src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "OptimizationParams",
        "importPath": "src.entities.arguments",
        "description": "src.entities.arguments",
        "isExtraImport": true,
        "detail": "src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "importPath": "src.entities.datasets",
        "description": "src.entities.datasets",
        "isExtraImport": true,
        "detail": "src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "TUM_RGBD",
        "importPath": "src.entities.datasets",
        "description": "src.entities.datasets",
        "isExtraImport": true,
        "detail": "src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "BaseDataset",
        "importPath": "src.entities.datasets",
        "description": "src.entities.datasets",
        "isExtraImport": true,
        "detail": "src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "ScanNet",
        "importPath": "src.entities.datasets",
        "description": "src.entities.datasets",
        "isExtraImport": true,
        "detail": "src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "BaseDataset",
        "importPath": "src.entities.datasets",
        "description": "src.entities.datasets",
        "isExtraImport": true,
        "detail": "src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "importPath": "src.entities.datasets",
        "description": "src.entities.datasets",
        "isExtraImport": true,
        "detail": "src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "GaussianModel",
        "importPath": "src.entities.gaussian_model",
        "description": "src.entities.gaussian_model",
        "isExtraImport": true,
        "detail": "src.entities.gaussian_model",
        "documentation": {}
    },
    {
        "label": "GaussianModel",
        "importPath": "src.entities.gaussian_model",
        "description": "src.entities.gaussian_model",
        "isExtraImport": true,
        "detail": "src.entities.gaussian_model",
        "documentation": {}
    },
    {
        "label": "GaussianModel",
        "importPath": "src.entities.gaussian_model",
        "description": "src.entities.gaussian_model",
        "isExtraImport": true,
        "detail": "src.entities.gaussian_model",
        "documentation": {}
    },
    {
        "label": "GaussianModel",
        "importPath": "src.entities.gaussian_model",
        "description": "src.entities.gaussian_model",
        "isExtraImport": true,
        "detail": "src.entities.gaussian_model",
        "documentation": {}
    },
    {
        "label": "GaussianModel",
        "importPath": "src.entities.gaussian_model",
        "description": "src.entities.gaussian_model",
        "isExtraImport": true,
        "detail": "src.entities.gaussian_model",
        "documentation": {}
    },
    {
        "label": "Mapper",
        "importPath": "src.entities.mapper",
        "description": "src.entities.mapper",
        "isExtraImport": true,
        "detail": "src.entities.mapper",
        "documentation": {}
    },
    {
        "label": "Tracker",
        "importPath": "src.entities.tracker",
        "description": "src.entities.tracker",
        "isExtraImport": true,
        "detail": "src.entities.tracker",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "src.entities.logger",
        "description": "src.entities.logger",
        "isExtraImport": true,
        "detail": "src.entities.logger",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "src.entities.logger",
        "description": "src.entities.logger",
        "isExtraImport": true,
        "detail": "src.entities.logger",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "src.entities.logger",
        "description": "src.entities.logger",
        "isExtraImport": true,
        "detail": "src.entities.logger",
        "documentation": {}
    },
    {
        "label": "save_dict_to_ckpt",
        "importPath": "src.utils.io_utils",
        "description": "src.utils.io_utils",
        "isExtraImport": true,
        "detail": "src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "save_dict_to_yaml",
        "importPath": "src.utils.io_utils",
        "description": "src.utils.io_utils",
        "isExtraImport": true,
        "detail": "src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "load_config",
        "importPath": "src.utils.io_utils",
        "description": "src.utils.io_utils",
        "isExtraImport": true,
        "detail": "src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "save_dict_to_json",
        "importPath": "src.utils.io_utils",
        "description": "src.utils.io_utils",
        "isExtraImport": true,
        "detail": "src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "load_config",
        "importPath": "src.utils.io_utils",
        "description": "src.utils.io_utils",
        "isExtraImport": true,
        "detail": "src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "log_metrics_to_wandb",
        "importPath": "src.utils.io_utils",
        "description": "src.utils.io_utils",
        "isExtraImport": true,
        "detail": "src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "exceeds_motion_thresholds",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "calc_psnr",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_camera_frustum_corners",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_frustum_point_ids",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_new_points_ids",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_opt_views_distribution",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "create_point_cloud",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "geometric_edge_mask",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "sample_pixels_based_on_gradient",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "calc_psnr",
        "importPath": "src.utils.mapper_utils",
        "description": "src.utils.mapper_utils",
        "isExtraImport": true,
        "detail": "src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "np2torch",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "setup_seed",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "torch2np",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "get_render_settings",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2ptcloud",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2torch",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "render_gaussian_model",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "torch2np",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "get_render_settings",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2torch",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "render_gaussian_model",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "torch2np",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "batch_search_faiss",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "get_render_settings",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2ptcloud",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "render_gaussian_model",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "torch2np",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "get_render_settings",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2torch",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "render_gaussian_model",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "setup_seed",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "torch2np",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2torch",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "setup_seed",
        "importPath": "src.utils.utils",
        "description": "src.utils.utils",
        "isExtraImport": true,
        "detail": "src.utils.utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "src.utils.vis_utils",
        "description": "src.utils.vis_utils",
        "isExtraImport": true,
        "detail": "src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "src.utils.vis_utils",
        "description": "src.utils.vis_utils",
        "isExtraImport": true,
        "detail": "src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "isotropic_loss",
        "importPath": "src.entities.losses",
        "description": "src.entities.losses",
        "isExtraImport": true,
        "detail": "src.entities.losses",
        "documentation": {}
    },
    {
        "label": "l1_loss",
        "importPath": "src.entities.losses",
        "description": "src.entities.losses",
        "isExtraImport": true,
        "detail": "src.entities.losses",
        "documentation": {}
    },
    {
        "label": "ssim",
        "importPath": "src.entities.losses",
        "description": "src.entities.losses",
        "isExtraImport": true,
        "detail": "src.entities.losses",
        "documentation": {}
    },
    {
        "label": "l1_loss",
        "importPath": "src.entities.losses",
        "description": "src.entities.losses",
        "isExtraImport": true,
        "detail": "src.entities.losses",
        "documentation": {}
    },
    {
        "label": "isotropic_loss",
        "importPath": "src.entities.losses",
        "description": "src.entities.losses",
        "isExtraImport": true,
        "detail": "src.entities.losses",
        "documentation": {}
    },
    {
        "label": "l1_loss",
        "importPath": "src.entities.losses",
        "description": "src.entities.losses",
        "isExtraImport": true,
        "detail": "src.entities.losses",
        "documentation": {}
    },
    {
        "label": "ssim",
        "importPath": "src.entities.losses",
        "description": "src.entities.losses",
        "isExtraImport": true,
        "detail": "src.entities.losses",
        "documentation": {}
    },
    {
        "label": "Rotation",
        "importPath": "scipy.spatial.transform",
        "description": "scipy.spatial.transform",
        "isExtraImport": true,
        "detail": "scipy.spatial.transform",
        "documentation": {}
    },
    {
        "label": "Rotation",
        "importPath": "scipy.spatial.transform",
        "description": "scipy.spatial.transform",
        "isExtraImport": true,
        "detail": "scipy.spatial.transform",
        "documentation": {}
    },
    {
        "label": "Rotation",
        "importPath": "scipy.spatial.transform",
        "description": "scipy.spatial.transform",
        "isExtraImport": true,
        "detail": "scipy.spatial.transform",
        "documentation": {}
    },
    {
        "label": "Rotation",
        "importPath": "scipy.spatial.transform",
        "description": "scipy.spatial.transform",
        "isExtraImport": true,
        "detail": "scipy.spatial.transform",
        "documentation": {}
    },
    {
        "label": "VisualOdometer",
        "importPath": "src.entities.visual_odometer",
        "description": "src.entities.visual_odometer",
        "isExtraImport": true,
        "detail": "src.entities.visual_odometer",
        "documentation": {}
    },
    {
        "label": "compute_camera_opt_params",
        "importPath": "src.utils.tracker_utils",
        "description": "src.utils.tracker_utils",
        "isExtraImport": true,
        "detail": "src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "extrapolate_poses",
        "importPath": "src.utils.tracker_utils",
        "description": "src.utils.tracker_utils",
        "isExtraImport": true,
        "detail": "src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "multiply_quaternions",
        "importPath": "src.utils.tracker_utils",
        "description": "src.utils.tracker_utils",
        "isExtraImport": true,
        "detail": "src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "transformation_to_quaternion",
        "importPath": "src.utils.tracker_utils",
        "description": "src.utils.tracker_utils",
        "isExtraImport": true,
        "detail": "src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "open3d.core",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "open3d.core",
        "description": "open3d.core",
        "detail": "open3d.core",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "trimesh",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "trimesh",
        "description": "trimesh",
        "detail": "trimesh",
        "documentation": {}
    },
    {
        "label": "run_evaluation",
        "importPath": "evaluate_3d_reconstruction",
        "description": "evaluate_3d_reconstruction",
        "isExtraImport": true,
        "detail": "evaluate_3d_reconstruction",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "cycle",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "ms_ssim",
        "importPath": "pytorch_msssim",
        "description": "pytorch_msssim",
        "isExtraImport": true,
        "detail": "pytorch_msssim",
        "documentation": {}
    },
    {
        "label": "ms_ssim",
        "importPath": "pytorch_msssim",
        "description": "pytorch_msssim",
        "isExtraImport": true,
        "detail": "pytorch_msssim",
        "documentation": {}
    },
    {
        "label": "ms_ssim",
        "importPath": "pytorch_msssim",
        "description": "pytorch_msssim",
        "isExtraImport": true,
        "detail": "pytorch_msssim",
        "documentation": {}
    },
    {
        "label": "median_filter",
        "importPath": "scipy.ndimage",
        "description": "scipy.ndimage",
        "isExtraImport": true,
        "detail": "scipy.ndimage",
        "documentation": {}
    },
    {
        "label": "LearnedPerceptualImagePatchSimilarity",
        "importPath": "torchmetrics.image.lpip",
        "description": "torchmetrics.image.lpip",
        "isExtraImport": true,
        "detail": "torchmetrics.image.lpip",
        "documentation": {}
    },
    {
        "label": "LearnedPerceptualImagePatchSimilarity",
        "importPath": "torchmetrics.image.lpip",
        "description": "torchmetrics.image.lpip",
        "isExtraImport": true,
        "detail": "torchmetrics.image.lpip",
        "documentation": {}
    },
    {
        "label": "LearnedPerceptualImagePatchSimilarity",
        "importPath": "torchmetrics.image.lpip",
        "description": "torchmetrics.image.lpip",
        "isExtraImport": true,
        "detail": "torchmetrics.image.lpip",
        "documentation": {}
    },
    {
        "label": "LearnedPerceptualImagePatchSimilarity",
        "importPath": "torchmetrics.image.lpip",
        "description": "torchmetrics.image.lpip",
        "isExtraImport": true,
        "detail": "torchmetrics.image.lpip",
        "documentation": {}
    },
    {
        "label": "save_image",
        "importPath": "torchvision.utils",
        "description": "torchvision.utils",
        "isExtraImport": true,
        "detail": "torchvision.utils",
        "documentation": {}
    },
    {
        "label": "RenderFrames",
        "importPath": "src.evaluation.evaluate_merged_map",
        "description": "src.evaluation.evaluate_merged_map",
        "isExtraImport": true,
        "detail": "src.evaluation.evaluate_merged_map",
        "documentation": {}
    },
    {
        "label": "merge_submaps",
        "importPath": "src.evaluation.evaluate_merged_map",
        "description": "src.evaluation.evaluate_merged_map",
        "isExtraImport": true,
        "detail": "src.evaluation.evaluate_merged_map",
        "documentation": {}
    },
    {
        "label": "refine_global_map",
        "importPath": "src.evaluation.evaluate_merged_map",
        "description": "src.evaluation.evaluate_merged_map",
        "isExtraImport": true,
        "detail": "src.evaluation.evaluate_merged_map",
        "documentation": {}
    },
    {
        "label": "evaluate_reconstruction",
        "importPath": "src.evaluation.evaluate_reconstruction",
        "description": "src.evaluation.evaluate_reconstruction",
        "isExtraImport": true,
        "detail": "src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "evaluate_trajectory",
        "importPath": "src.evaluation.evaluate_trajectory",
        "description": "src.evaluation.evaluate_trajectory",
        "isExtraImport": true,
        "detail": "src.evaluation.evaluate_trajectory",
        "documentation": {}
    },
    {
        "label": "faiss.contrib.torch_utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss.contrib.torch_utils",
        "description": "faiss.contrib.torch_utils",
        "detail": "faiss.contrib.torch_utils",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizationSettings",
        "importPath": "gaussian_rasterizer",
        "description": "gaussian_rasterizer",
        "isExtraImport": true,
        "detail": "gaussian_rasterizer",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "gaussian_rasterizer",
        "description": "gaussian_rasterizer",
        "isExtraImport": true,
        "detail": "gaussian_rasterizer",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "src.evaluation.evaluator",
        "description": "src.evaluation.evaluator",
        "isExtraImport": true,
        "detail": "src.evaluation.evaluator",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "src.evaluation.evaluator",
        "description": "src.evaluation.evaluator",
        "isExtraImport": true,
        "detail": "src.evaluation.evaluator",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "GaussianSLAM",
        "importPath": "src.entities.gaussian_slam",
        "description": "src.entities.gaussian_slam",
        "isExtraImport": true,
        "detail": "src.entities.gaussian_slam",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "imageio.v2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imageio.v2",
        "description": "imageio.v2",
        "detail": "imageio.v2",
        "documentation": {}
    },
    {
        "label": "abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "abc",
        "description": "abc",
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "compose_transformations",
        "importPath": "kornia.geometry.linalg",
        "description": "kornia.geometry.linalg",
        "isExtraImport": true,
        "detail": "kornia.geometry.linalg",
        "documentation": {}
    },
    {
        "label": "inverse_transformation",
        "importPath": "kornia.geometry.linalg",
        "description": "kornia.geometry.linalg",
        "isExtraImport": true,
        "detail": "kornia.geometry.linalg",
        "documentation": {}
    },
    {
        "label": "data",
        "importPath": "torch.utils",
        "description": "torch.utils",
        "isExtraImport": true,
        "detail": "torch.utils",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "CUDAExtension",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "BuildExtension",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_get_build_directory",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_import_module_from_library",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_get_build_directory",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_import_module_from_library",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_get_build_directory",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_import_module_from_library",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_get_build_directory",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "_import_module_from_library",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "SourceFileLoader",
        "importPath": "importlib.machinery",
        "description": "importlib.machinery",
        "isExtraImport": true,
        "detail": "importlib.machinery",
        "documentation": {}
    },
    {
        "label": "load_dataset_config",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ICLDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaV2Dataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "AzureKinectDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Ai2thorDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Record3DDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "RealsenseDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "TUMDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetPPDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "NeRFCaptureDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset_config",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ICLDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaV2Dataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "AzureKinectDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Ai2thorDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Record3DDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "RealsenseDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "TUMDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetPPDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "NeRFCaptureDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset_config",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ICLDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaV2Dataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "AzureKinectDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Ai2thorDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Record3DDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "RealsenseDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "TUMDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetPPDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "NeRFCaptureDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset_config",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ICLDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ReplicaV2Dataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "AzureKinectDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Ai2thorDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "Record3DDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "RealsenseDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "TUMDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "ScannetPPDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "NeRFCaptureDataset",
        "importPath": "datasets.gradslam_datasets",
        "description": "datasets.gradslam_datasets",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params_ckpt",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params_ckpt",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "importPath": "utils.common_utils",
        "description": "utils.common_utils",
        "isExtraImport": true,
        "detail": "utils.common_utils",
        "documentation": {}
    },
    {
        "label": "eval",
        "importPath": "utils.eval_helpers",
        "description": "utils.eval_helpers",
        "isExtraImport": true,
        "detail": "utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "eval_nvs",
        "importPath": "utils.eval_helpers",
        "description": "utils.eval_helpers",
        "isExtraImport": true,
        "detail": "utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "report_progress",
        "importPath": "utils.eval_helpers",
        "description": "utils.eval_helpers",
        "isExtraImport": true,
        "detail": "utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "report_loss",
        "importPath": "utils.eval_helpers",
        "description": "utils.eval_helpers",
        "isExtraImport": true,
        "detail": "utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "report_progress",
        "importPath": "utils.eval_helpers",
        "description": "utils.eval_helpers",
        "isExtraImport": true,
        "detail": "utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "eval",
        "importPath": "utils.eval_helpers",
        "description": "utils.eval_helpers",
        "isExtraImport": true,
        "detail": "utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "importPath": "utils.recon_helpers",
        "description": "utils.recon_helpers",
        "isExtraImport": true,
        "detail": "utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "params2rendervar",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "params2depthplussilhouette",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2depthplussilhouette",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "transform_to_frame",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "report_progress",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "eval",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "l1_loss_v1",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "matrix_to_quaternion",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "params2rendervar",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "params2depthplussilhouette",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "report_progress",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "eval",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "l1_loss_v1",
        "importPath": "utils.gs_helpers",
        "description": "utils.gs_helpers",
        "isExtraImport": true,
        "detail": "utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "calc_ssim",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "densify",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "get_expon_lr_func",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "update_learning_rate",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "calc_ssim",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "densify",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "get_expon_lr_func",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "update_learning_rate",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.gs_external",
        "description": "utils.gs_external",
        "isExtraImport": true,
        "detail": "utils.gs_external",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizationSettings",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizationSettings",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizer",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "GaussianRasterizationSettings",
        "importPath": "diff_gaussian_rasterization",
        "description": "diff_gaussian_rasterization",
        "isExtraImport": true,
        "detail": "diff_gaussian_rasterization",
        "documentation": {}
    },
    {
        "label": "relative_transformation",
        "importPath": "datasets.gradslam_datasets.geometryutils",
        "description": "datasets.gradslam_datasets.geometryutils",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "relative_transformation",
        "importPath": "datasets.gradslam_datasets.geometryutils",
        "description": "datasets.gradslam_datasets.geometryutils",
        "isExtraImport": true,
        "detail": "datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "keyframe_selection_overlap",
        "importPath": "utils.keyframe_selection",
        "description": "utils.keyframe_selection",
        "isExtraImport": true,
        "detail": "utils.keyframe_selection",
        "documentation": {}
    },
    {
        "label": "keyframe_selection_overlap",
        "importPath": "utils.keyframe_selection",
        "description": "utils.keyframe_selection",
        "isExtraImport": true,
        "detail": "utils.keyframe_selection",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "prune_gaussians",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "densify",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "calc_ssim",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "prune_gaussians",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "densify",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "calc_psnr",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "calc_psnr",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "importPath": "utils.slam_external",
        "description": "utils.slam_external",
        "isExtraImport": true,
        "detail": "utils.slam_external",
        "documentation": {}
    },
    {
        "label": "matrix_to_quaternion",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2rendervar",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2depthplussilhouette",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transform_to_frame",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "l1_loss_v1",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "matrix_to_quaternion",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transform_to_frame",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2rendervar",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2depthplussilhouette",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "quat_mult",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "matrix_to_quaternion",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "get_depth_and_silhouette",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "get_depth_and_silhouette",
        "importPath": "utils.slam_helpers",
        "description": "utils.slam_helpers",
        "isExtraImport": true,
        "detail": "utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "get_loss",
        "importPath": "scripts.splatam",
        "description": "scripts.splatam",
        "isExtraImport": true,
        "detail": "scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_optimizer",
        "importPath": "scripts.splatam",
        "description": "scripts.splatam",
        "isExtraImport": true,
        "detail": "scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_params",
        "importPath": "scripts.splatam",
        "description": "scripts.splatam",
        "isExtraImport": true,
        "detail": "scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_camera_pose",
        "importPath": "scripts.splatam",
        "description": "scripts.splatam",
        "isExtraImport": true,
        "detail": "scripts.splatam",
        "documentation": {}
    },
    {
        "label": "get_pointcloud",
        "importPath": "scripts.splatam",
        "description": "scripts.splatam",
        "isExtraImport": true,
        "detail": "scripts.splatam",
        "documentation": {}
    },
    {
        "label": "add_new_gaussians",
        "importPath": "scripts.splatam",
        "description": "scripts.splatam",
        "isExtraImport": true,
        "detail": "scripts.splatam",
        "documentation": {}
    },
    {
        "label": "cyclonedds.idl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cyclonedds.idl",
        "description": "cyclonedds.idl",
        "detail": "cyclonedds.idl",
        "documentation": {}
    },
    {
        "label": "cyclonedds.idl.annotations",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cyclonedds.idl.annotations",
        "description": "cyclonedds.idl.annotations",
        "detail": "cyclonedds.idl.annotations",
        "documentation": {}
    },
    {
        "label": "cyclonedds.idl.types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cyclonedds.idl.types",
        "description": "cyclonedds.idl.types",
        "detail": "cyclonedds.idl.types",
        "documentation": {}
    },
    {
        "label": "DomainParticipant",
        "importPath": "cyclonedds.domain",
        "description": "cyclonedds.domain",
        "isExtraImport": true,
        "detail": "cyclonedds.domain",
        "documentation": {}
    },
    {
        "label": "Domain",
        "importPath": "cyclonedds.domain",
        "description": "cyclonedds.domain",
        "isExtraImport": true,
        "detail": "cyclonedds.domain",
        "documentation": {}
    },
    {
        "label": "DomainParticipant",
        "importPath": "cyclonedds.domain",
        "description": "cyclonedds.domain",
        "isExtraImport": true,
        "detail": "cyclonedds.domain",
        "documentation": {}
    },
    {
        "label": "Domain",
        "importPath": "cyclonedds.domain",
        "description": "cyclonedds.domain",
        "isExtraImport": true,
        "detail": "cyclonedds.domain",
        "documentation": {}
    },
    {
        "label": "Qos",
        "importPath": "cyclonedds.core",
        "description": "cyclonedds.core",
        "isExtraImport": true,
        "detail": "cyclonedds.core",
        "documentation": {}
    },
    {
        "label": "Policy",
        "importPath": "cyclonedds.core",
        "description": "cyclonedds.core",
        "isExtraImport": true,
        "detail": "cyclonedds.core",
        "documentation": {}
    },
    {
        "label": "Qos",
        "importPath": "cyclonedds.core",
        "description": "cyclonedds.core",
        "isExtraImport": true,
        "detail": "cyclonedds.core",
        "documentation": {}
    },
    {
        "label": "Policy",
        "importPath": "cyclonedds.core",
        "description": "cyclonedds.core",
        "isExtraImport": true,
        "detail": "cyclonedds.core",
        "documentation": {}
    },
    {
        "label": "DataReader",
        "importPath": "cyclonedds.sub",
        "description": "cyclonedds.sub",
        "isExtraImport": true,
        "detail": "cyclonedds.sub",
        "documentation": {}
    },
    {
        "label": "DataReader",
        "importPath": "cyclonedds.sub",
        "description": "cyclonedds.sub",
        "isExtraImport": true,
        "detail": "cyclonedds.sub",
        "documentation": {}
    },
    {
        "label": "Topic",
        "importPath": "cyclonedds.topic",
        "description": "cyclonedds.topic",
        "isExtraImport": true,
        "detail": "cyclonedds.topic",
        "documentation": {}
    },
    {
        "label": "Topic",
        "importPath": "cyclonedds.topic",
        "description": "cyclonedds.topic",
        "isExtraImport": true,
        "detail": "cyclonedds.topic",
        "documentation": {}
    },
    {
        "label": "duration",
        "importPath": "cyclonedds.util",
        "description": "cyclonedds.util",
        "isExtraImport": true,
        "detail": "cyclonedds.util",
        "documentation": {}
    },
    {
        "label": "duration",
        "importPath": "cyclonedds.util",
        "description": "cyclonedds.util",
        "isExtraImport": true,
        "detail": "cyclonedds.util",
        "documentation": {}
    },
    {
        "label": "sort_splats",
        "importPath": "gsplat.compression.sort",
        "description": "gsplat.compression.sort",
        "isExtraImport": true,
        "detail": "gsplat.compression.sort",
        "documentation": {}
    },
    {
        "label": "sort_splats",
        "importPath": "gsplat.compression.sort",
        "description": "gsplat.compression.sort",
        "isExtraImport": true,
        "detail": "gsplat.compression.sort",
        "documentation": {}
    },
    {
        "label": "inverse_log_transform",
        "importPath": "gsplat.utils",
        "description": "gsplat.utils",
        "isExtraImport": true,
        "detail": "gsplat.utils",
        "documentation": {}
    },
    {
        "label": "log_transform",
        "importPath": "gsplat.utils",
        "description": "gsplat.utils",
        "isExtraImport": true,
        "detail": "gsplat.utils",
        "documentation": {}
    },
    {
        "label": "normalized_quat_to_rotmat",
        "importPath": "gsplat.utils",
        "description": "gsplat.utils",
        "isExtraImport": true,
        "detail": "gsplat.utils",
        "documentation": {}
    },
    {
        "label": "inverse_log_transform",
        "importPath": "gsplat.utils",
        "description": "gsplat.utils",
        "isExtraImport": true,
        "detail": "gsplat.utils",
        "documentation": {}
    },
    {
        "label": "log_transform",
        "importPath": "gsplat.utils",
        "description": "gsplat.utils",
        "isExtraImport": true,
        "detail": "gsplat.utils",
        "documentation": {}
    },
    {
        "label": "normalized_quat_to_rotmat",
        "importPath": "gsplat.utils",
        "description": "gsplat.utils",
        "isExtraImport": true,
        "detail": "gsplat.utils",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "DEVNULL",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "DEVNULL",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "DEVNULL",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "DEVNULL",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "Console",
        "importPath": "rich.console",
        "description": "rich.console",
        "isExtraImport": true,
        "detail": "rich.console",
        "documentation": {}
    },
    {
        "label": "Console",
        "importPath": "rich.console",
        "description": "rich.console",
        "isExtraImport": true,
        "detail": "rich.console",
        "documentation": {}
    },
    {
        "label": "Console",
        "importPath": "rich.console",
        "description": "rich.console",
        "isExtraImport": true,
        "detail": "rich.console",
        "documentation": {}
    },
    {
        "label": "Console",
        "importPath": "rich.console",
        "description": "rich.console",
        "isExtraImport": true,
        "detail": "rich.console",
        "documentation": {}
    },
    {
        "label": "struct",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "struct",
        "description": "struct",
        "detail": "struct",
        "documentation": {}
    },
    {
        "label": "Float",
        "importPath": "jaxtyping",
        "description": "jaxtyping",
        "isExtraImport": true,
        "detail": "jaxtyping",
        "documentation": {}
    },
    {
        "label": "Float",
        "importPath": "jaxtyping",
        "description": "jaxtyping",
        "isExtraImport": true,
        "detail": "jaxtyping",
        "documentation": {}
    },
    {
        "label": "Int",
        "importPath": "jaxtyping",
        "description": "jaxtyping",
        "isExtraImport": true,
        "detail": "jaxtyping",
        "documentation": {}
    },
    {
        "label": "Float",
        "importPath": "jaxtyping",
        "description": "jaxtyping",
        "isExtraImport": true,
        "detail": "jaxtyping",
        "documentation": {}
    },
    {
        "label": "Float",
        "importPath": "jaxtyping",
        "description": "jaxtyping",
        "isExtraImport": true,
        "detail": "jaxtyping",
        "documentation": {}
    },
    {
        "label": "Int",
        "importPath": "jaxtyping",
        "description": "jaxtyping",
        "isExtraImport": true,
        "detail": "jaxtyping",
        "documentation": {}
    },
    {
        "label": "compute_relocation",
        "importPath": "gsplat.relocation",
        "description": "gsplat.relocation",
        "isExtraImport": true,
        "detail": "gsplat.relocation",
        "documentation": {}
    },
    {
        "label": "compute_relocation",
        "importPath": "gsplat.relocation",
        "description": "gsplat.relocation",
        "isExtraImport": true,
        "detail": "gsplat.relocation",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "torch.distributed.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed.nn.functional",
        "description": "torch.distributed.nn.functional",
        "detail": "torch.distributed.nn.functional",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "assert_never",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "tyro",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tyro",
        "description": "tyro",
        "detail": "tyro",
        "documentation": {}
    },
    {
        "label": "SceneManager",
        "importPath": "pycolmap",
        "description": "pycolmap",
        "isExtraImport": true,
        "detail": "pycolmap",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "datasets.colmap",
        "description": "datasets.colmap",
        "isExtraImport": true,
        "detail": "datasets.colmap",
        "documentation": {}
    },
    {
        "label": "Parser",
        "importPath": "datasets.colmap",
        "description": "datasets.colmap",
        "isExtraImport": true,
        "detail": "datasets.colmap",
        "documentation": {}
    },
    {
        "label": "generate_interpolated_path",
        "importPath": "datasets.traj",
        "description": "datasets.traj",
        "isExtraImport": true,
        "detail": "datasets.traj",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "AppearanceOptModule",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "CameraOptModule",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "knn",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "rgb_to_sh",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "PngCompression",
        "importPath": "gsplat.compression",
        "description": "gsplat.compression",
        "isExtraImport": true,
        "detail": "gsplat.compression",
        "documentation": {}
    },
    {
        "label": "cli",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "cli",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "cli",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_gather_int32",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_gather_tensor_list",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_to_all_int32",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_to_all_tensor_list",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "cli",
        "importPath": "gsplat.distributed",
        "description": "gsplat.distributed",
        "isExtraImport": true,
        "detail": "gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "importPath": "gsplat.rendering",
        "description": "gsplat.rendering",
        "isExtraImport": true,
        "detail": "gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "importPath": "gsplat.rendering",
        "description": "gsplat.rendering",
        "isExtraImport": true,
        "detail": "gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "importPath": "gsplat.rendering",
        "description": "gsplat.rendering",
        "isExtraImport": true,
        "detail": "gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "DefaultStrategy",
        "importPath": "gsplat.strategy",
        "description": "gsplat.strategy",
        "isExtraImport": true,
        "detail": "gsplat.strategy",
        "documentation": {}
    },
    {
        "label": "MCMCStrategy",
        "importPath": "gsplat.strategy",
        "description": "gsplat.strategy",
        "isExtraImport": true,
        "detail": "gsplat.strategy",
        "documentation": {}
    },
    {
        "label": "load_test_data",
        "importPath": "gsplat._helper",
        "description": "gsplat._helper",
        "isExtraImport": true,
        "detail": "gsplat._helper",
        "documentation": {}
    },
    {
        "label": "load_test_data",
        "importPath": "gsplat._helper",
        "description": "gsplat._helper",
        "isExtraImport": true,
        "detail": "gsplat._helper",
        "documentation": {}
    },
    {
        "label": "load_test_data",
        "importPath": "gsplat._helper",
        "description": "gsplat._helper",
        "isExtraImport": true,
        "detail": "gsplat._helper",
        "documentation": {}
    },
    {
        "label": "NearestNeighbors",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "pathos",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathos",
        "description": "pathos",
        "detail": "pathos",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pyridescence",
        "description": "pyridescence",
        "isExtraImport": true,
        "detail": "pyridescence",
        "documentation": {}
    },
    {
        "label": "KDTree",
        "importPath": "scipy.spatial",
        "description": "scipy.spatial",
        "isExtraImport": true,
        "detail": "scipy.spatial",
        "documentation": {}
    },
    {
        "label": "Scan2ScanICP",
        "kind": 6,
        "importPath": "src.component.tracker",
        "description": "src.component.tracker",
        "peekOfCode": "class Scan2ScanICP:\n    \"\"\"\n    Scan-to-Scan ICP class for depth image-derived point clouds using small_gicp library.\n    Each scan is aligned with the previous scan to estimate the relative transformation.\n    \"\"\"\n    def __init__(\n        self,\n        max_corresponding_distance=0.1,\n        voxel_downsampling_resolutions: float = 0.0,\n        knn: int = 20,",
        "detail": "src.component.tracker",
        "documentation": {}
    },
    {
        "label": "PcdVisualizer",
        "kind": 6,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "class PcdVisualizer:\n    def __init__(self, intrinsic_matrix: NDArray[np.int32], view_scale=1.0):\n        self.o3d_vis = Visualizer()\n        self.o3d_vis.create_window(\n            window_name=\"Complete Point Cloud\", width=1600, height=1200, visible=True\n        )\n        # Set camera parameters for following the camera pose\n        self.view_control = self.o3d_vis.get_view_control()\n        self.camera_params = o3d.camera.PinholeCameraParameters()\n        intrinsic = o3d.camera.PinholeCameraIntrinsic()",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "visualize_dataset",
        "kind": 2,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "def visualize_dataset(data_set: BaseDataset):\n    vis = PcdVisualizer(intrinsic_matrix=data_set.K)\n    for i, rgbd_image in enumerate(data_set):\n        print(f\"Processing image {i + 1}/{len(data_set)}...\")\n        vis.update_render(\n            rgbd_image.points.cpu().numpy(),\n            rgbd_image.pose.cpu().numpy(),\n            new_color=rgbd_image.colors.cpu().numpy(),\n            down_sample=0.01,\n        )",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "visualize_trajectory",
        "kind": 2,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "def visualize_trajectory(data_set: BaseDataset):\n    \"\"\"vis 3d trajectory\"\"\"\n    poses = [\n        rgbd_image.pose.cpu().numpy()\n        for rgbd_image in data_set\n        if rgbd_image.pose is not None\n    ]\n    translations = [pose[:3, 3] for pose in poses]\n    # Plot the trajectory\n    fig = plt.figure()",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "multi_vis_img",
        "kind": 2,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "def multi_vis_img(imgs: list[NDArray]) -> None:\n    \"\"\"Visualize multiple images in a grid layout.\"\"\"\n    n = len(imgs)  # Number of depth images\n    cols = 2  # Number of columns in subplot grid\n    rows = (n + cols - 1) // cols  # Calculate required rows, round up division\n    plt.figure(figsize=(15, 5 * rows))  # Adjusted figsize based on content\n    for i, img in enumerate(imgs):\n        plt.subplot(rows, cols, i + 1)  # Dynamic subplot positioning\n        plt.imshow(img)\n        # plt.title(f\"Image:{img}\")",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "vis_depth_filter",
        "kind": 2,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "def vis_depth_filter(depths: list[NDArray]) -> None:\n    \"\"\"Visualize the depth images as colormap in a grid layout.\"\"\"\n    multi_vis_img([depth_to_colormap(depth) for depth in depths])\ndef depth_to_colormap(depth_image: NDArray):\n    # Normalize and convert the depth image to an 8-bit format, and apply a colormap\n    depth_normalized = (depth_image - np.min(depth_image)) / (\n        np.max(depth_image) - np.min(depth_image)\n    )\n    depth_8bit = np.uint8(depth_normalized * 255)\n    depth_colormap = plt.cm.jet(depth_8bit)  # Using matplotlib's colormap",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "depth_to_colormap",
        "kind": 2,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "def depth_to_colormap(depth_image: NDArray):\n    # Normalize and convert the depth image to an 8-bit format, and apply a colormap\n    depth_normalized = (depth_image - np.min(depth_image)) / (\n        np.max(depth_image) - np.min(depth_image)\n    )\n    depth_8bit = np.uint8(depth_normalized * 255)\n    depth_colormap = plt.cm.jet(depth_8bit)  # Using matplotlib's colormap\n    return depth_colormap\ndef show_image(color: NDArray, depth: NDArray):\n    # Plot color image",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "show_image",
        "kind": 2,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "def show_image(color: NDArray, depth: NDArray):\n    # Plot color image\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    if color.max() > 1.0:\n        color = color / 255.0\n    plt.imshow(color)\n    plt.title(\"Color Image\")\n    plt.axis(\"off\")\n    # Plot depth image with colormap",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "visualize_point_cloud",
        "kind": 2,
        "importPath": "src.component.visualize",
        "description": "src.component.visualize",
        "peekOfCode": "def visualize_point_cloud(points: torch.Tensor, colors: torch.Tensor):\n    \"\"\"\n    Visualize point cloud data using Open3D.\n    Parameters:\n    points (torch.Tensor): Tensor of point coordinates with shape (N, 3).\n    colors (torch.Tensor): Tensor of colors with shape (N, 3), values range from 0 to 1.\n    \"\"\"\n    # Ensure input has correct shape\n    assert points.shape[1] == 3, \"Point coordinates should have shape (N, 3)\"\n    assert colors.shape[1] == 3, \"Colors should have shape (N, 3)\"",
        "detail": "src.component.visualize",
        "documentation": {}
    },
    {
        "label": "RGBDImage",
        "kind": 6,
        "importPath": "src.data.Image",
        "description": "src.data.Image",
        "peekOfCode": "class RGBDImage:\n    \"\"\"\n    Initialize an RGBDImage with depth and camera intrinsic matrix, all as Tensors.\n    \"\"\"\n    def __init__(\n        self,\n        rgb: np.ndarray,\n        depth: np.ndarray,\n        K: np.ndarray,\n        pose: NDArray[np.float32],",
        "detail": "src.data.Image",
        "documentation": {}
    },
    {
        "label": "OptimizationConfig",
        "kind": 6,
        "importPath": "src.data.base",
        "description": "src.data.base",
        "peekOfCode": "class OptimizationConfig:\n    max_steps: int = 1000\n    ssim_lambda: float = 0.5\n    depth_lambda: float = 0.8\n    normal_lambda: float = 0.0\n    ssim: StructuralSimilarityIndexMeasure = None\n    psnr: PeakSignalNoiseRatio = None\n    lpips: LearnedPerceptualImagePatchSimilarity = None\n    early_stop: bool = True\n    patience = 200",
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "ViewerConfig",
        "kind": 6,
        "importPath": "src.data.base",
        "description": "src.data.base",
        "peekOfCode": "class ViewerConfig:\n    disable_viewer: bool = True\n    port: int = 8080\n    # init view\n    server: ViserServer | None = None\n    viewer: Viewer | None = None\n    def init_view(self, viewer_render_fn: Callable):\n        if not self.disable_viewer:\n            self.server = ViserServer(port=self.port, verbose=False)\n            self.viewer = Viewer(",
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "src.data.base",
        "description": "src.data.base",
        "peekOfCode": "class Config(\n    OptimizationConfig,\n    ViewerConfig,\n):\n    ckpt: str | None = None\n    def adjust_steps(self, factor: float = 1.0):\n        self.max_steps = int(self.max_steps * factor)\n@dataclass\nclass TensorWrapper:\n    def to(self, device: torch.device) -> \"TensorWrapper\":",
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "TensorWrapper",
        "kind": 6,
        "importPath": "src.data.base",
        "description": "src.data.base",
        "peekOfCode": "class TensorWrapper:\n    def to(self, device: torch.device) -> \"TensorWrapper\":\n        \"\"\"\n        Move all Tensor attributes to the specified device.\n        \"\"\"\n        for attr_name, attr_value in self.__dict__.items():\n            if torch.is_tensor(attr_value):\n                setattr(self, attr_name, attr_value.to(device))\n        return self\n    def enable_gradients(self) -> \"TensorWrapper\":",
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "AlignData",
        "kind": 6,
        "importPath": "src.data.base",
        "description": "src.data.base",
        "peekOfCode": "class AlignData(TensorWrapper):\n    \"\"\"normed data\"\"\"\n    # for GS\n    colors: Tensor  # N,3\n    pixels: Tensor  # [1, H, W, 3]\n    # points: Tensor  # N,3\n    tar_points: Tensor\n    src_points: Tensor\n    src_depth: Tensor  # B,H,w,1\n    tar_c2w: Tensor  # 4,4",
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "TrainData",
        "kind": 6,
        "importPath": "src.data.base",
        "description": "src.data.base",
        "peekOfCode": "class TrainData(TensorWrapper):\n    \"\"\"normed data\"\"\"\n    # for GS\n    points: Tensor  # N,3  in camera\n    colors: Tensor  # N,3\n    pixels: Tensor  # [1, H, W, 3]\n    depth: Tensor  # [1, H, W, 1]\n    c2w: Tensor  # 4,4\n    pca_factor: Tensor = torch.scalar_tensor(\n        1.0",
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "kind": 5,
        "importPath": "src.data.base",
        "description": "src.data.base",
        "peekOfCode": "DEVICE = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n)\nprint(f\"Using {DEVICE} DEVICE\")\n@dataclass\nclass OptimizationConfig:\n    max_steps: int = 1000\n    ssim_lambda: float = 0.5",
        "detail": "src.data.base",
        "documentation": {}
    },
    {
        "label": "BaseDataset",
        "kind": 6,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "class BaseDataset(Sequence[RGBDImage]):\n    def __init__(self, input_folder: str, cfg_file: str):\n        assert Path(input_folder).exists(), f\"Path {input_folder} does not exist.\"\n        assert Path(cfg_file).exists(), f\"Path {cfg_file} does not exist.\"\n        self.input_folder = Path(input_folder)\n        cfg_file = Path(cfg_file)\n        self.cfg = load_camera_cfg(cfg_file.as_posix())[\"camera\"]\n        self.scale = self.cfg[\"scale\"]\n        self.poses = None\n        self.distortion = (",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "Replica",
        "kind": 6,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "class Replica(BaseDataset):\n    \"\"\"\n    Parameters:\n        name: [\"room\" + str(i) for i in range(3)] + [\n            \"office\" + str(i) for i in range(5)\n        ]\n    \"\"\"\n    def __init__(\n        self,\n        name: str = \"room0\",",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "TUM",
        "kind": 6,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "class TUM(BaseDataset):\n    \"\"\"\n    Parameters:\n        name: Literal['freiburg1_desk',\n                    'freiburg1_desk2','freiburg1_room',\n                    'freiburg2_xyz',freiburg3_long_office_household']\n    \"\"\"\n    def __init__(\n        self,\n        name: Literal[",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "Parser",
        "kind": 6,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "class Parser:\n    def __init__(\n        self,\n        data_set: Literal[\"Replica\", \"TUM\"] = \"Replica\",\n        name: str = \"room0\",\n        normalize: bool = False,\n    ):\n        self._data = Replica(name) if data_set == \"Replica\" else TUM(name)\n        self.K = to_tensor(self._data.K, requires_grad=True)\n        # normalize points and pose",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "get_data_set",
        "kind": 2,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "def get_data_set(name: Literal[\"TUM\", \"Replica\"], room: str):\n    if name == \"TUM\":\n        return TUM(room)\n    elif name == \"Replica\":\n        return Replica(room)\n    else:\n        raise ValueError(\"data set name should be in ['TUM,Replica']\")\nclass Parser:\n    def __init__(\n        self,",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "align_principle_axes",
        "kind": 2,
        "importPath": "src.data.normalize",
        "description": "src.data.normalize",
        "peekOfCode": "def align_principle_axes(point_cloud: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Align the principal axes of a point cloud to the coordinate axes using PCA.\n    Parameters\n    ----------\n    point_cloud : torch.Tensor\n        Nx3 tensor containing the 3D point cloud.\n    Returns\n    -------\n    torch.Tensor",
        "detail": "src.data.normalize",
        "documentation": {}
    },
    {
        "label": "transform_points",
        "kind": 2,
        "importPath": "src.data.normalize",
        "description": "src.data.normalize",
        "peekOfCode": "def transform_points(matrix: torch.Tensor, points: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Transform points using a SE(3) transformation matrix.\n    Parameters\n    ----------\n    matrix : torch.Tensor\n        A 4x4 SE(3) transformation matrix.\n    points : torch.Tensor\n        An Nx3 tensor of points to be transformed.\n    Returns",
        "detail": "src.data.normalize",
        "documentation": {}
    },
    {
        "label": "transform_cameras",
        "kind": 2,
        "importPath": "src.data.normalize",
        "description": "src.data.normalize",
        "peekOfCode": "def transform_cameras(\n    matrix: torch.Tensor, c2w: torch.Tensor\n) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Apply a SE(3) transformation to a set of camera-to-world matrices.\n    Parameters\n    ----------\n    matrix : torch.Tensor\n        A 4x4 SE(3) transformation matrix.\n    c2w : torch.Tensor",
        "detail": "src.data.normalize",
        "documentation": {}
    },
    {
        "label": "normalize_2C",
        "kind": 2,
        "importPath": "src.data.normalize",
        "description": "src.data.normalize",
        "peekOfCode": "def normalize_2C(tar: RGBDImage, src: RGBDImage) -> tuple[RGBDImage, RGBDImage, Tensor]:\n    # calculate tar points normalization transform\n    transform = align_principle_axes(tar.points)\n    # apply transform\n    scale_factor = apply_normalize_T(tar, transform)\n    _ = apply_normalize_T(src, transform)\n    return tar, src, scale_factor\ndef apply_normalize_T(tar: RGBDImage, T: Tensor) -> Tensor:\n    # NOTE: must in world\n    tar.points = transform_points(T, tar.points)",
        "detail": "src.data.normalize",
        "documentation": {}
    },
    {
        "label": "apply_normalize_T",
        "kind": 2,
        "importPath": "src.data.normalize",
        "description": "src.data.normalize",
        "peekOfCode": "def apply_normalize_T(tar: RGBDImage, T: Tensor) -> Tensor:\n    # NOTE: must in world\n    tar.points = transform_points(T, tar.points)\n    normed_tar_pose, scale_factor = transform_cameras(T, tar.pose.unsqueeze(0))\n    tar.pose = normed_tar_pose.squeeze(0)\n    return scale_factor",
        "detail": "src.data.normalize",
        "documentation": {}
    },
    {
        "label": "PointClouds",
        "kind": 6,
        "importPath": "src.data.pcd",
        "description": "src.data.pcd",
        "peekOfCode": "class PointClouds:\n    \"\"\"\n    Point clouds data structure.\n    \"\"\"\n    def __init__(\n        self,\n        pcd: NDArray[np.float64],\n        # rgb: NDArray[np.float64],\n        *,\n        threads: int = 32,",
        "detail": "src.data.pcd",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "src.data.traj",
        "description": "src.data.traj",
        "peekOfCode": "def normalize(x: np.ndarray) -> np.ndarray:\n    \"\"\"Normalization helper function.\"\"\"\n    return x / np.linalg.norm(x)\ndef viewmatrix(lookdir: np.ndarray, up: np.ndarray, position: np.ndarray) -> np.ndarray:\n    \"\"\"Construct lookat view matrix.\"\"\"\n    vec2 = normalize(lookdir)\n    vec0 = normalize(np.cross(up, vec2))\n    vec1 = normalize(np.cross(vec2, vec0))\n    m = np.stack([vec0, vec1, vec2, position], axis=1)\n    return m",
        "detail": "src.data.traj",
        "documentation": {}
    },
    {
        "label": "viewmatrix",
        "kind": 2,
        "importPath": "src.data.traj",
        "description": "src.data.traj",
        "peekOfCode": "def viewmatrix(lookdir: np.ndarray, up: np.ndarray, position: np.ndarray) -> np.ndarray:\n    \"\"\"Construct lookat view matrix.\"\"\"\n    vec2 = normalize(lookdir)\n    vec0 = normalize(np.cross(up, vec2))\n    vec1 = normalize(np.cross(vec2, vec0))\n    m = np.stack([vec0, vec1, vec2, position], axis=1)\n    return m\ndef focus_point_fn(poses: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate nearest point to all focal axes in poses.\"\"\"\n    directions, origins = poses[:, :3, 2:3], poses[:, :3, 3:4]",
        "detail": "src.data.traj",
        "documentation": {}
    },
    {
        "label": "focus_point_fn",
        "kind": 2,
        "importPath": "src.data.traj",
        "description": "src.data.traj",
        "peekOfCode": "def focus_point_fn(poses: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate nearest point to all focal axes in poses.\"\"\"\n    directions, origins = poses[:, :3, 2:3], poses[:, :3, 3:4]\n    m = np.eye(3) - directions * np.transpose(directions, [0, 2, 1])\n    mt_m = np.transpose(m, [0, 2, 1]) @ m\n    focus_pt = np.linalg.inv(mt_m.mean(0)) @ (mt_m @ origins).mean(0)[:, 0]\n    return focus_pt\ndef generate_ellipse_path_z(\n    poses: np.ndarray,\n    n_frames: int = 120,",
        "detail": "src.data.traj",
        "documentation": {}
    },
    {
        "label": "generate_ellipse_path_z",
        "kind": 2,
        "importPath": "src.data.traj",
        "description": "src.data.traj",
        "peekOfCode": "def generate_ellipse_path_z(\n    poses: np.ndarray,\n    n_frames: int = 120,\n    # const_speed: bool = True,\n    variation: float = 0.0,\n    phase: float = 0.0,\n    height: float = 0.0,\n) -> np.ndarray:\n    \"\"\"Generate an elliptical render path based on the given poses.\"\"\"\n    # Calculate the focal point for the path (cameras point toward this).",
        "detail": "src.data.traj",
        "documentation": {}
    },
    {
        "label": "generate_ellipse_path_y",
        "kind": 2,
        "importPath": "src.data.traj",
        "description": "src.data.traj",
        "peekOfCode": "def generate_ellipse_path_y(\n    poses: np.ndarray,\n    n_frames: int = 120,\n    # const_speed: bool = True,\n    variation: float = 0.0,\n    phase: float = 0.0,\n    height: float = 0.0,\n) -> np.ndarray:\n    \"\"\"Generate an elliptical render path based on the given poses.\"\"\"\n    # Calculate the focal point for the path (cameras point toward this).",
        "detail": "src.data.traj",
        "documentation": {}
    },
    {
        "label": "generate_interpolated_path",
        "kind": 2,
        "importPath": "src.data.traj",
        "description": "src.data.traj",
        "peekOfCode": "def generate_interpolated_path(\n    poses: np.ndarray,\n    n_interp: int,\n    spline_degree: int = 5,\n    smoothness: float = 0.03,\n    rot_weight: float = 0.1,\n):\n    \"\"\"Creates a smooth spline path between input keyframe camera poses.\n    Spline is calculated with poses in format (position, lookat-point, up-point).\n    Args:",
        "detail": "src.data.traj",
        "documentation": {}
    },
    {
        "label": "load_camera_cfg",
        "kind": 2,
        "importPath": "src.data.utils",
        "description": "src.data.utils",
        "peekOfCode": "def load_camera_cfg(cfg_path: str) -> dict:\n    \"\"\"\n    Load camera configuration from YAML or Json file.\n    \"\"\"\n    cfg_path = Path(cfg_path)\n    assert cfg_path.exists(), f\"File not found: {cfg_path}\"\n    with open(cfg_path) as file:\n        if cfg_path.suffix in [\".yaml\", \".yml\"]:\n            cfg = yaml.safe_load(file)\n        elif cfg_path.suffix == \".json\":",
        "detail": "src.data.utils",
        "documentation": {}
    },
    {
        "label": "to_tensor",
        "kind": 2,
        "importPath": "src.data.utils",
        "description": "src.data.utils",
        "peekOfCode": "def to_tensor(data, device=DEVICE, requires_grad=False, dtype=torch.float32):\n    \"\"\"\n    Convert numpy array or list to a PyTorch tensor.\n    \"\"\"\n    if (\n        not isinstance(data, list)\n        and not isinstance(data, np.ndarray)\n        and not torch.is_tensor(data)\n        and not isinstance(data, int)\n    ):",
        "detail": "src.data.utils",
        "documentation": {}
    },
    {
        "label": "as_intrinsics_matrix",
        "kind": 2,
        "importPath": "src.data.utils",
        "description": "src.data.utils",
        "peekOfCode": "def as_intrinsics_matrix(intrinsics: list[float]) -> NDArray:\n    \"\"\"\n    Get matrix representation of intrinsics.\n    :param intrinsics : [fx,fy,cx,cy]\n    :return: K matrix.shape=(3,3)\n    \"\"\"\n    K = np.eye(3)\n    K[0, 0] = intrinsics[0]\n    K[1, 1] = intrinsics[1]\n    K[0, 2] = intrinsics[2]",
        "detail": "src.data.utils",
        "documentation": {}
    },
    {
        "label": "RegistrationConfig",
        "kind": 6,
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "peekOfCode": "class RegistrationConfig(NamedTuple):\n    max_corresponding_distance: float = 0.1\n    num_threads: int = 32\n    registration_type: Literal[\"ICP\", \"PLANE_ICP\", \"GICP\", \"COLORED_ICP\", \"HYBRID\"] = (\n        \"GICP\"\n    )\n    voxel_downsampling_resolutions: float | None = None\n    implementation: str | None = None\n    # knn: int = 10\n    def as_dict(self):",
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbConfig",
        "kind": 6,
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "peekOfCode": "class WandbConfig(NamedTuple):\n    algorithm: str = \"GICP\"\n    dataset: Literal[\"TUM\", \"Replica\"] = \"Replica\"\n    sub_set: str = \"office0\"\n    description: str = \"GICP on Replica dataset\"\n    normalize: bool = True\n    implementation: str | None = None\n    num_iters: int | None = None\n    learning_rate: float | None = None\n    optimizer: str | None = None",
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "ExperimentBase",
        "kind": 6,
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "peekOfCode": "class ExperimentBase:\n    def __init__(\n        self, wandb_config: WandbConfig, extra_config: dict = None, backends=None\n    ):\n        # self.data: DataLoaderBase = Replica(wandb_config.sub_set)\n        self.sub_set = wandb_config.sub_set\n        self.backends = backends\n        if extra_config is None:\n            extra_config = {}\n        wandb_config = wandb_config.as_dict()",
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "ICPExperiment",
        "kind": 6,
        "importPath": "src.eval.experiment",
        "description": "src.eval.experiment",
        "peekOfCode": "class ICPExperiment(ExperimentBase):\n    def __init__(\n        self,\n        registration_config: RegistrationConfig,\n        wandb_config: WandbConfig,\n    ):\n        super().__init__(\n            backends=Scan2ScanICP(**registration_config.as_dict()),\n            wandb_config=wandb_config,\n            extra_config=registration_config.as_dict(),",
        "detail": "src.eval.experiment",
        "documentation": {}
    },
    {
        "label": "WandbLogger",
        "kind": 6,
        "importPath": "src.eval.logger",
        "description": "src.eval.logger",
        "peekOfCode": "class WandbLogger:\n    def __init__(self, run_name: str | None = None, config: dict | None = None):\n        \"\"\"\n        Initialize the Weights & Biases logging.\n        use wandb login with api key https://wandb.ai/authorize, then wandb login --relogin\n        wandb login --cloud\n        \"\"\"\n        if run_name is None:\n            run_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n        else:",
        "detail": "src.eval.logger",
        "documentation": {}
    },
    {
        "label": "calculate_translation_error_np",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def calculate_translation_error_np(\n    estimated_pose: NDArray[np.float64], true_pose: NDArray[np.float64]\n) -> float:\n    \"\"\"\n    Calculate the translation error between estimated pose and true pose.\n    Parameters\n    ----------\n    estimated_pose: NDArray[np.float64], shape=(4, 4)\n    true_pose: NDArray[np.float64], shape=(4, 4)\n    Returns",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "calculate_rotation_error_np",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def calculate_rotation_error_np(\n    estimated_pose: NDArray[np.float64], true_pose: NDArray[np.float64]\n) -> float:\n    \"\"\"\n    Calculate the rotation error between estimated pose and true pose.\n    Parameters\n    ----------\n    estimated_pose: NDArray[np.float64], shape=(4, 4)\n    true_pose: NDArray[np.float64], shape=(4, 4)\n    Returns",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "calculate_pointcloud_rmse_np",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def calculate_pointcloud_rmse_np(\n    estimated_points: NDArray[np.float64], true_points: NDArray[np.float64]\n) -> float:\n    \"\"\"\n    Calculate the RMSE between estimated points and true points.\n    Parameters\n    ----------\n    estimated_points: NDArray[np.float64], shape=(n, 3) or (n, 4)\n    true_points: NDArray[np.float64], shape=(n, 3) or (n, 4)\n    Returns",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "diff_pcd_COM_np",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def diff_pcd_COM_np(pcd_1: NDArray[np.float64], pcd_2: NDArray[np.float64]) -> float:\n    \"\"\"\n    Calculate the difference in center of mass between two\n    point clouds.\n    Parameters\n    ----------\n    pcd_1: NDArray[np.float64], shape=(n, 3)\n    pcd_2: NDArray[np.float64], shape=(n, 3)\n    Returns\n    -------",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "calculate_RMSE_np",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def calculate_RMSE_np(eT: NDArray) -> float:\n    \"\"\"\n    Returns\n    -------\n    RMSE: float\n    \"\"\"\n    return np.sqrt(np.mean(np.square(eT)))\ndef calculate_translation_error(\n    estimated_pose: torch.Tensor, true_pose: torch.Tensor\n) -> float:",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "calculate_translation_error",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def calculate_translation_error(\n    estimated_pose: torch.Tensor, true_pose: torch.Tensor\n) -> float:\n    \"\"\"\n    Calculate the translation error between estimated pose and true pose using PyTorch.\n    Parameters\n    ----------\n    estimated_pose: torch.Tensor, shape=(4, 4)\n    true_pose: torch.Tensor, shape=(4, 4)\n    Returns",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "calculate_rotation_error",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def calculate_rotation_error(\n    estimated_pose: torch.Tensor, true_pose: torch.Tensor\n) -> float:\n    \"\"\"\n    Calculate the rotation error between estimated pose and true pose using PyTorch.\n    Parameters\n    ----------\n    estimated_pose: torch.Tensor, shape=(4, 4)\n    true_pose: torch.Tensor, shape=(4, 4)\n    Returns",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def set_random_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\ndef compute_silhouette_diff(depth: Tensor, rastered_depth: Tensor) -> Tensor:\n    \"\"\"\n    Compute the difference between the sobel edges of two depth images.\n    Parameters\n    ----------\n    depth : torch.Tensor",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "compute_silhouette_diff",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def compute_silhouette_diff(depth: Tensor, rastered_depth: Tensor) -> Tensor:\n    \"\"\"\n    Compute the difference between the sobel edges of two depth images.\n    Parameters\n    ----------\n    depth : torch.Tensor\n        The depth image with dimensions [height, width].\n    rastered_depth : torch.Tensor\n        The depth image with dimensions [height, width].\n    Returns",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "count_images",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def count_images(media_dir):\n    image_extensions = {\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\"}\n    return sum(\n        1 for file in media_dir.glob(\"**/*\") if file.suffix.lower() in image_extensions\n    )\ndef clean_wandb_runs(wandb_dir):\n    wandb_path = pathlib.Path(wandb_dir)\n    for run_dir in wandb_path.iterdir():\n        if not run_dir.is_dir():\n            continue",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "clean_wandb_runs",
        "kind": 2,
        "importPath": "src.eval.utils",
        "description": "src.eval.utils",
        "peekOfCode": "def clean_wandb_runs(wandb_dir):\n    wandb_path = pathlib.Path(wandb_dir)\n    for run_dir in wandb_path.iterdir():\n        if not run_dir.is_dir():\n            continue\n        config_path = run_dir / \"files\" / \"config.yaml\"\n        summary_path = run_dir / \"files\" / \"wandb-summary.json\"\n        media_dir = run_dir / \"files\" / \"media\"\n        # 检查 config.yaml 是否存在并包含正确的 dataset 值\n        if config_path.exists():",
        "detail": "src.eval.utils",
        "documentation": {}
    },
    {
        "label": "construct_full_pose",
        "kind": 2,
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "peekOfCode": "def construct_full_pose(rotation: Tensor, translation: Tensor):\n    \"\"\"\n    Constructs the full 4x4 transformation matrix from rotation and translation.\n    Ensures that gradients are tracked for rotation and translation.\n    \"\"\"\n    pose = torch.eye(4, dtype=rotation.dtype, device=\"cuda:0\")\n    pose[:3, :3] = rotation\n    pose[:3, 3] = translation\n    return pose\ndef transform_points(matrix: torch.Tensor, points: torch.Tensor) -> torch.Tensor:",
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "transform_points",
        "kind": 2,
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "peekOfCode": "def transform_points(matrix: torch.Tensor, points: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Transform points using a SE(3) transformation matrix.\n    Parameters\n    ----------\n    matrix : torch.Tensor\n        A 4x4 SE(3) transformation matrix.\n    points : torch.Tensor\n        An Nx3 tensor of points to be transformed.\n    Returns",
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "init_gs_scales",
        "kind": 2,
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "peekOfCode": "def init_gs_scales(points: torch.Tensor, k: int = 5, eps: float = 1e-24) -> Tensor:\n    \"\"\"\n    Initialize scales for Gaussian Splatting with safeguards against large scales.\n    Parameters\n    ----------\n    points: tensor, shape (N, 3)\n        Input point cloud\n    k: int\n        Number of nearest neighbors to consider\n    Returns",
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "compute_depth_gt",
        "kind": 2,
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "peekOfCode": "def compute_depth_gt(\n    points: Tensor,  # N,3\n    rgbs: Tensor,  # N,3\n    Ks: Tensor,\n    c2w: Tensor,\n    height: int,\n    width: int,\n) -> Tensor:\n    \"\"\"\n    Parameters",
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "depth_to_points",
        "kind": 2,
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "peekOfCode": "def depth_to_points(\n    depth: Tensor,\n    K: Tensor,\n    include_homogeneous: bool = False,\n) -> Tensor:\n    \"\"\"\n    Project depth map to point clouds using intrinsic matrix.\n    Parameters\n    ----------\n    depth: shape=(H,W)",
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "depth_to_normal",
        "kind": 2,
        "importPath": "src.my_gsplat.geometry",
        "description": "src.my_gsplat.geometry",
        "peekOfCode": "def depth_to_normal(depth: Tensor, K: Tensor) -> Tensor:\n    \"\"\"\n    Convert depth map to normal map using the provided depth_to_points function.\n    Args:\n        depth (Tensor): Depth map of shape [H, W]\n        K (Tensor): Camera intrinsic matrix of shape [4, 4]\n    Returns:\n        Tensor: Normal map of shape [H, W, 3]\n    \"\"\"\n    H, W = depth.shape",
        "detail": "src.my_gsplat.geometry",
        "documentation": {}
    },
    {
        "label": "Runner",
        "kind": 6,
        "importPath": "src.my_gsplat.gs_trainer",
        "description": "src.my_gsplat.gs_trainer",
        "peekOfCode": "class Runner(ExperimentBase):\n    \"\"\"Engine for training and testing.\"\"\"\n    def __init__(\n        self,\n        wandb_config: WandbConfig,\n        base_config: Config = Config(),\n        extra_config: dict = None,\n    ) -> None:\n        super().__init__(wandb_config=wandb_config, extra_config=extra_config)\n        # Setup output directories.",
        "detail": "src.my_gsplat.gs_trainer",
        "documentation": {}
    },
    {
        "label": "Runner",
        "kind": 6,
        "importPath": "src.my_gsplat.gs_trainer_total",
        "description": "src.my_gsplat.gs_trainer_total",
        "peekOfCode": "class Runner(ExperimentBase):\n    \"\"\"Engine for training and testing.\"\"\"\n    def __init__(\n        self,\n        wandb_config: WandbConfig,\n        base_config: Config = Config(),\n        extra_config: dict = None,\n    ) -> None:\n        super().__init__(wandb_config=wandb_config, extra_config=extra_config)\n        set_random_seed(42)",
        "detail": "src.my_gsplat.gs_trainer_total",
        "documentation": {}
    },
    {
        "label": "compute_depth_loss",
        "kind": 2,
        "importPath": "src.my_gsplat.loss",
        "description": "src.my_gsplat.loss",
        "peekOfCode": "def compute_depth_loss(\n    depth_A: Tensor, depth_B: Tensor, *, loss_type: Literal[\"l1\", \"mse\"] = \"l1\"\n) -> Tensor:\n    \"\"\"\n    Compute the mean squared error between two depth images.\n    Parameters\n    ----------\n    depth_A: shape=(*,H,W,*)\n    depth_B: shape=(*,H,W,*)\n    loss_type: Literal[\"l1\", \"mse\"]",
        "detail": "src.my_gsplat.loss",
        "documentation": {}
    },
    {
        "label": "compute_silhouette_loss",
        "kind": 2,
        "importPath": "src.my_gsplat.loss",
        "description": "src.my_gsplat.loss",
        "peekOfCode": "def compute_silhouette_loss(\n    depth_A: Tensor, depth_B: Tensor, *, loss_type: Literal[\"l1\", \"mse\"] = \"l1\"\n) -> Tensor:\n    \"\"\"\n    Compute the mean squared error between the sobel edges of two depth images.\n    Parameters\n    ----------\n    depth_A: shape=(B, H, W, 1)\n    depth_B: shape=(B, H, W, 1)\n    loss_type: Literal[\"l1\", \"mse\"]",
        "detail": "src.my_gsplat.loss",
        "documentation": {}
    },
    {
        "label": "compute_normal_consistency_loss",
        "kind": 2,
        "importPath": "src.my_gsplat.loss",
        "description": "src.my_gsplat.loss",
        "peekOfCode": "def compute_normal_consistency_loss(\n    depth_real: Tensor,\n    depth_rendered: Tensor,\n    *,\n    K: Tensor,\n    loss_type: Literal[\"cosine\", \"l1\", \"mse\"] = \"cosine\"\n) -> Tensor:\n    \"\"\"\n    Compute the normal consistency loss between two depth images.\n    Args:",
        "detail": "src.my_gsplat.loss",
        "documentation": {}
    },
    {
        "label": "CameraConfig",
        "kind": 6,
        "importPath": "src.my_gsplat.model",
        "description": "src.my_gsplat.model",
        "peekOfCode": "class CameraConfig:\n    trans_lr: float = 1e-3\n    quat_lr: float = 5 * 1e-4\n    quat_opt_reg: float = 1e-3\n    trans_opt_reg: float = 1e-3\n# NOTE: quat + tans\nclass CameraOptModule_quat_tans(nn.Module):\n    def __init__(self, init_pose: Tensor, *, config: CameraConfig = CameraConfig()):\n        super().__init__()\n        self.config = config",
        "detail": "src.my_gsplat.model",
        "documentation": {}
    },
    {
        "label": "CameraOptModule_quat_tans",
        "kind": 6,
        "importPath": "src.my_gsplat.model",
        "description": "src.my_gsplat.model",
        "peekOfCode": "class CameraOptModule_quat_tans(nn.Module):\n    def __init__(self, init_pose: Tensor, *, config: CameraConfig = CameraConfig()):\n        super().__init__()\n        self.config = config\n        self.quat_cur = nn.Parameter(rotation_matrix_to_quaternion(init_pose[:3, :3]))\n        self.t_cur = nn.Parameter(init_pose[:3, 3])\n        # Add these lines to store previous poses\n        self.prev_quat = self.quat_cur.detach().clone()\n        self.prev_t = self.t_cur.detach().clone()\n        self.optimizers = self._create_optimizers()",
        "detail": "src.my_gsplat.model",
        "documentation": {}
    },
    {
        "label": "GsConfig",
        "kind": 6,
        "importPath": "src.my_gsplat.model",
        "description": "src.my_gsplat.model",
        "peekOfCode": "class GsConfig:\n    init_opa: float = 1.0\n    sparse_grad: bool = False\n    packed: bool = False\n    absgrad: bool = False\n    antialiased: bool = False\n    # Degree of spherical harmonics\n    sh_degree: int = 1\n    # RasterizeConfig\n    # Near plane clipping distance",
        "detail": "src.my_gsplat.model",
        "documentation": {}
    },
    {
        "label": "GSModel",
        "kind": 6,
        "importPath": "src.my_gsplat.model",
        "description": "src.my_gsplat.model",
        "peekOfCode": "class GSModel(nn.Module):\n    def __init__(\n        self,\n        # dataset\n        points: Tensor,  # N,3\n        colors: Tensor,  # N,3\n        *,\n        # config\n        config: GsConfig = GsConfig(),\n    ):",
        "detail": "src.my_gsplat.model",
        "documentation": {}
    },
    {
        "label": "rotation_6d_to_matrix",
        "kind": 2,
        "importPath": "src.my_gsplat.transform",
        "description": "src.my_gsplat.transform",
        "peekOfCode": "def rotation_6d_to_matrix(d6: Tensor) -> Tensor:\n    \"\"\"\n    Converts 6D rotation representation by Zhou et al. [1] to rotation matrix\n    using Gram--Schmidt orthogonalization per Section B of [1]. Adapted from pytorch3d.\n    Args:\n        d6: 6D rotation representation, of size (*, 6)\n    Returns:\n        batch of rotation matrices of size (*, 3, 3)\n    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n    On the Continuity of Rotation Representations in Neural Networks.",
        "detail": "src.my_gsplat.transform",
        "documentation": {}
    },
    {
        "label": "matrix_to_rotation_6d",
        "kind": 2,
        "importPath": "src.my_gsplat.transform",
        "description": "src.my_gsplat.transform",
        "peekOfCode": "def matrix_to_rotation_6d(matrix: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Converts rotation matrices to 6D rotation representation by Zhou et al. [1]\n    by dropping the last row. Note that 6D representation is not unique. Adapted from pytorch3d.\n    Args:\n        matrix: batch of rotation matrices of size (*, 3, 3)\n    Returns:\n        6D rotation representation, of size (*, 6)\n    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n    On the Continuity of Rotation Representations in Neural Networks.",
        "detail": "src.my_gsplat.transform",
        "documentation": {}
    },
    {
        "label": "quat_to_rotation_matrix",
        "kind": 2,
        "importPath": "src.my_gsplat.transform",
        "description": "src.my_gsplat.transform",
        "peekOfCode": "def quat_to_rotation_matrix(quaternion: Tensor) -> Tensor:\n    \"\"\"\n    Convert a quaternion to a rotation matrix.\n    Parameters\n    ----------\n    quaternion : torch.Tensor\n        The quaternion with dimensions [4].\n    Returns\n    -------\n    torch.Tensor",
        "detail": "src.my_gsplat.transform",
        "documentation": {}
    },
    {
        "label": "rotation_matrix_to_quaternion",
        "kind": 2,
        "importPath": "src.my_gsplat.transform",
        "description": "src.my_gsplat.transform",
        "peekOfCode": "def rotation_matrix_to_quaternion(rotation_matrix: Tensor) -> Tensor:\n    \"\"\"\n    Convert a rotation matrix to a quaternion.\n    Parameters\n    ----------\n    rotation_matrix : torch.Tensor\n        The rotation matrix with dimensions (..., 3, 3).\n    Returns\n    -------\n    torch.Tensor",
        "detail": "src.my_gsplat.transform",
        "documentation": {}
    },
    {
        "label": "knn",
        "kind": 2,
        "importPath": "src.my_gsplat.utils",
        "description": "src.my_gsplat.utils",
        "peekOfCode": "def knn(x: Tensor, K: int = 4) -> Tensor:\n    x_np = x.cpu().numpy() if not x.requires_grad else x.detach().cpu().numpy()\n    pcd = small_gicp.PointCloud(x_np.astype(np.float64))\n    model = small_gicp.KdTree(pcd, num_threads=32)\n    _, distances = model.batch_knn_search(x_np, k=K, num_threads=64)\n    return to_tensor(distances, device=DEVICE, requires_grad=True)\ndef remove_outliers(\n    points: torch.Tensor, k: int = 10, std_ratio: float = 10.0, verbose: bool = False\n) -> tuple[torch.Tensor, torch.Tensor]:\n    # Calculate distances for initial scale and outlier detection",
        "detail": "src.my_gsplat.utils",
        "documentation": {}
    },
    {
        "label": "remove_outliers",
        "kind": 2,
        "importPath": "src.my_gsplat.utils",
        "description": "src.my_gsplat.utils",
        "peekOfCode": "def remove_outliers(\n    points: torch.Tensor, k: int = 10, std_ratio: float = 10.0, verbose: bool = False\n) -> tuple[torch.Tensor, torch.Tensor]:\n    # Calculate distances for initial scale and outlier detection\n    distances = knn(points, k)\n    dist2_avg = (distances[:, 1:] ** 2).mean(dim=-1)\n    dist_avg = torch.sqrt(dist2_avg)\n    # Outlier detection\n    mean_dist = dist_avg.mean()\n    std_dist = dist_avg.std()",
        "detail": "src.my_gsplat.utils",
        "documentation": {}
    },
    {
        "label": "rgb_to_sh",
        "kind": 2,
        "importPath": "src.my_gsplat.utils",
        "description": "src.my_gsplat.utils",
        "peekOfCode": "def rgb_to_sh(rgb: Tensor) -> Tensor:\n    C0 = 0.28209479177387814\n    return (rgb - 0.5) / C0",
        "detail": "src.my_gsplat.utils",
        "documentation": {}
    },
    {
        "label": "load_finished_experiments",
        "kind": 2,
        "importPath": "src.wandb.run-20240827_122829-zf5mypqh.files.code.src.icps_eval",
        "description": "src.wandb.run-20240827_122829-zf5mypqh.files.code.src.icps_eval",
        "peekOfCode": "def load_finished_experiments(file_path: Path):\n    \"\"\"Load the list of finished experiments from the file.\"\"\"\n    if not file_path.exists():\n        return []\n    with file_path.open(\"r\") as file:\n        return [tuple(json.loads(line)) for line in file]\ndef save_finished_experiment(file_path: Path, finished: tuple):\n    \"\"\"Append a new finished experiment to the file.\"\"\"\n    with file_path.open(\"a\") as file:\n        file.write(json.dumps(finished) + \"\\n\")",
        "detail": "src.wandb.run-20240827_122829-zf5mypqh.files.code.src.icps_eval",
        "documentation": {}
    },
    {
        "label": "save_finished_experiment",
        "kind": 2,
        "importPath": "src.wandb.run-20240827_122829-zf5mypqh.files.code.src.icps_eval",
        "description": "src.wandb.run-20240827_122829-zf5mypqh.files.code.src.icps_eval",
        "peekOfCode": "def save_finished_experiment(file_path: Path, finished: tuple):\n    \"\"\"Append a new finished experiment to the file.\"\"\"\n    with file_path.open(\"a\") as file:\n        file.write(json.dumps(finished) + \"\\n\")\nif __name__ == \"__main__\":\n    file_path = Path(\"grip_o3d_finished_experiments.json\")\n    methods = [\n        # \"GICP\",\n        # \"PLANE_ICP\",\n        # \"COLORED_ICP\",",
        "detail": "src.wandb.run-20240827_122829-zf5mypqh.files.code.src.icps_eval",
        "documentation": {}
    },
    {
        "label": "load_finished_experiments",
        "kind": 2,
        "importPath": "src.wandb.run-20240828_113055-sxozzcto.files.code.src.icps_eval",
        "description": "src.wandb.run-20240828_113055-sxozzcto.files.code.src.icps_eval",
        "peekOfCode": "def load_finished_experiments(file_path: Path):\n    \"\"\"Load the list of finished experiments from the file.\"\"\"\n    if not file_path.exists():\n        return []\n    with file_path.open(\"r\") as file:\n        return [tuple(json.loads(line)) for line in file]\ndef save_finished_experiment(file_path: Path, finished: tuple):\n    \"\"\"Append a new finished experiment to the file.\"\"\"\n    with file_path.open(\"a\") as file:\n        file.write(json.dumps(finished) + \"\\n\")",
        "detail": "src.wandb.run-20240828_113055-sxozzcto.files.code.src.icps_eval",
        "documentation": {}
    },
    {
        "label": "save_finished_experiment",
        "kind": 2,
        "importPath": "src.wandb.run-20240828_113055-sxozzcto.files.code.src.icps_eval",
        "description": "src.wandb.run-20240828_113055-sxozzcto.files.code.src.icps_eval",
        "peekOfCode": "def save_finished_experiment(file_path: Path, finished: tuple):\n    \"\"\"Append a new finished experiment to the file.\"\"\"\n    with file_path.open(\"a\") as file:\n        file.write(json.dumps(finished) + \"\\n\")\nif __name__ == \"__main__\":\n    file_path = Path(\"grip_o3d_finished_experiments.json\")\n    methods = [\n        # \"GICP\",\n        # \"PLANE_ICP\",\n        # \"COLORED_ICP\",",
        "detail": "src.wandb.run-20240828_113055-sxozzcto.files.code.src.icps_eval",
        "documentation": {}
    },
    {
        "label": "parse_arguments",
        "kind": 2,
        "importPath": "src.GsplatLoc_eval",
        "description": "src.GsplatLoc_eval",
        "peekOfCode": "def parse_arguments():\n    parser = argparse.ArgumentParser(\n        description=\"Run GSplat training on specified rooms for Replica or TUM datasets.\"\n    )\n    parser.add_argument(\n        \"--dataset\",\n        choices=[\"Replica\", \"TUM\"],\n        required=True,\n        help=\"Specify the dataset to use (Replica or TUM)\",\n    )",
        "detail": "src.GsplatLoc_eval",
        "documentation": {}
    },
    {
        "label": "get_rooms",
        "kind": 2,
        "importPath": "src.GsplatLoc_eval",
        "description": "src.GsplatLoc_eval",
        "peekOfCode": "def get_rooms(args):\n    if args.dataset == \"Replica\":\n        if args.all:\n            return [\"room\" + str(i) for i in range(3)] + [\n                \"office\" + str(i) for i in range(5)\n            ]\n        elif args.rooms:\n            return args.rooms\n        elif args.room_range:\n            return [",
        "detail": "src.GsplatLoc_eval",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.GsplatLoc_eval",
        "description": "src.GsplatLoc_eval",
        "peekOfCode": "def main():\n    args = parse_arguments()\n    rooms = get_rooms(args)\n    for room in rooms:\n        config = WandbConfig(\n            dataset=args.dataset,\n            sub_set=room,\n            algorithm=\"gsplat_v4_filter_knn10-10_test\",\n            implementation=\"pytorch\",\n            num_iters=args.num_iters,",
        "detail": "src.GsplatLoc_eval",
        "documentation": {}
    },
    {
        "label": "load_finished_experiments",
        "kind": 2,
        "importPath": "src.icps_eval",
        "description": "src.icps_eval",
        "peekOfCode": "def load_finished_experiments(file_path: Path):\n    \"\"\"Load the list of finished experiments from the file.\"\"\"\n    if not file_path.exists():\n        return []\n    with file_path.open(\"r\") as file:\n        return [tuple(json.loads(line)) for line in file]\ndef save_finished_experiment(file_path: Path, finished: tuple):\n    \"\"\"Append a new finished experiment to the file.\"\"\"\n    with file_path.open(\"a\") as file:\n        file.write(json.dumps(finished) + \"\\n\")",
        "detail": "src.icps_eval",
        "documentation": {}
    },
    {
        "label": "save_finished_experiment",
        "kind": 2,
        "importPath": "src.icps_eval",
        "description": "src.icps_eval",
        "peekOfCode": "def save_finished_experiment(file_path: Path, finished: tuple):\n    \"\"\"Append a new finished experiment to the file.\"\"\"\n    with file_path.open(\"a\") as file:\n        file.write(json.dumps(finished) + \"\\n\")\nif __name__ == \"__main__\":\n    file_path = Path(\"grip_o3d_finished_experiments.json\")\n    methods = [\n        # \"GICP\",\n        # \"PLANE_ICP\",\n        # \"COLORED_ICP\",",
        "detail": "src.icps_eval",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "kind": 5,
        "importPath": "src.plot_rmse",
        "description": "src.plot_rmse",
        "peekOfCode": "ROOT = Path(__file__).parents[1].as_posix()\nsys.path.append(ROOT)\nfrom src.eval.logger import WandbLogger\nif __name__ == \"__main__\":\n    baseline = \"\"\n    # baseline = \"tum\"\n    log = WandbLogger(\n        run_name=\"plot_RMSE\", config={\"description\": f\"baseline_{baseline}\"}\n    )\n    # log.plot_RMSE(f\"baseline_{baseline}\")",
        "detail": "src.plot_rmse",
        "documentation": {}
    },
    {
        "label": "fixture",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def fixture() -> None:\n    pass",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "sample_replica",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def sample_replica():\n    return Replica()\ndef test_replica_str(sample_replica):\n    assert \"Replica dataset: room0\" in str(sample_replica)\ndef test_replica_length(sample_replica):\n    assert isinstance(len(sample_replica), int)\ndef test_replica_getitem(sample_replica):\n    result = sample_replica[0]\n    assert isinstance(result, RGBDImage)\ndef test_replica_getslice(sample_replica):",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_replica_str",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_replica_str(sample_replica):\n    assert \"Replica dataset: room0\" in str(sample_replica)\ndef test_replica_length(sample_replica):\n    assert isinstance(len(sample_replica), int)\ndef test_replica_getitem(sample_replica):\n    result = sample_replica[0]\n    assert isinstance(result, RGBDImage)\ndef test_replica_getslice(sample_replica):\n    results = sample_replica[0:2]\n    assert len(results) == 2",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_replica_length",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_replica_length(sample_replica):\n    assert isinstance(len(sample_replica), int)\ndef test_replica_getitem(sample_replica):\n    result = sample_replica[0]\n    assert isinstance(result, RGBDImage)\ndef test_replica_getslice(sample_replica):\n    results = sample_replica[0:2]\n    assert len(results) == 2\n    assert all(isinstance(item, RGBDImage) for item in results)\ndef test_replica_index_out_of_bounds(sample_replica):",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_replica_getitem",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_replica_getitem(sample_replica):\n    result = sample_replica[0]\n    assert isinstance(result, RGBDImage)\ndef test_replica_getslice(sample_replica):\n    results = sample_replica[0:2]\n    assert len(results) == 2\n    assert all(isinstance(item, RGBDImage) for item in results)\ndef test_replica_index_out_of_bounds(sample_replica):\n    with pytest.raises(ValueError):\n        sample_replica[len(sample_replica)]",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_replica_getslice",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_replica_getslice(sample_replica):\n    results = sample_replica[0:2]\n    assert len(results) == 2\n    assert all(isinstance(item, RGBDImage) for item in results)\ndef test_replica_index_out_of_bounds(sample_replica):\n    with pytest.raises(ValueError):\n        sample_replica[len(sample_replica)]\ndef test_replica_index_wrong_type(sample_replica):\n    with pytest.raises(TypeError):\n        sample_replica[\"invalid\"]  # 非整数和切片类型的索引",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_replica_index_out_of_bounds",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_replica_index_out_of_bounds(sample_replica):\n    with pytest.raises(ValueError):\n        sample_replica[len(sample_replica)]\ndef test_replica_index_wrong_type(sample_replica):\n    with pytest.raises(TypeError):\n        sample_replica[\"invalid\"]  # 非整数和切片类型的索引\ndef test_replica_pose():\n    rooms = [\"room\" + str(i) for i in range(3)] + [\"office\" + str(i) for i in range(5)]\n    for room in rooms:\n        data = Replica(room)",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_replica_index_wrong_type",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_replica_index_wrong_type(sample_replica):\n    with pytest.raises(TypeError):\n        sample_replica[\"invalid\"]  # 非整数和切片类型的索引\ndef test_replica_pose():\n    rooms = [\"room\" + str(i) for i in range(3)] + [\"office\" + str(i) for i in range(5)]\n    for room in rooms:\n        data = Replica(room)\n        visualize_dataset(data)\ndef test_TUM_show_image():\n    rooms = [",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_replica_pose",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_replica_pose():\n    rooms = [\"room\" + str(i) for i in range(3)] + [\"office\" + str(i) for i in range(5)]\n    for room in rooms:\n        data = Replica(room)\n        visualize_dataset(data)\ndef test_TUM_show_image():\n    rooms = [\n        \"freiburg1_desk\",\n        \"freiburg1_desk2\",\n        \"freiburg1_room\",",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_TUM_show_image",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_TUM_show_image():\n    rooms = [\n        \"freiburg1_desk\",\n        \"freiburg1_desk2\",\n        \"freiburg1_room\",\n        \"freiburg2_xyz\",\n        \"freiburg3_long_office_household\",\n    ]\n    for room in rooms:\n        data = TUM(room)",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "test_TUM_pose",
        "kind": 2,
        "importPath": "tests.test_dataset",
        "description": "tests.test_dataset",
        "peekOfCode": "def test_TUM_pose():\n    rooms = [\n        \"freiburg1_desk\",\n        \"freiburg1_desk2\",\n        \"freiburg1_room\",\n        \"freiburg2_xyz\",\n        \"freiburg3_long_office_household\",\n    ]\n    for room in rooms:\n        data = TUM(room)",
        "detail": "tests.test_dataset",
        "documentation": {}
    },
    {
        "label": "GroupParams",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "description": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "peekOfCode": "class GroupParams:\n    pass\nclass ParamGroup:\n    def __init__(self, parser: ArgumentParser, name: str, fill_none=False):\n        group = parser.add_argument_group(name)\n        for key, value in vars(self).items():\n            shorthand = False\n            if key.startswith(\"_\"):\n                shorthand = True\n                key = key[1:]",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "ParamGroup",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "description": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "peekOfCode": "class ParamGroup:\n    def __init__(self, parser: ArgumentParser, name: str, fill_none=False):\n        group = parser.add_argument_group(name)\n        for key, value in vars(self).items():\n            shorthand = False\n            if key.startswith(\"_\"):\n                shorthand = True\n                key = key[1:]\n            t = type(value)\n            value = value if not fill_none else None",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "OptimizationParams",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "description": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "peekOfCode": "class OptimizationParams(ParamGroup):\n    def __init__(self, parser):\n        self.iterations = 30_000\n        self.position_lr_init = 0.0001\n        self.position_lr_final = 0.0000016\n        self.position_lr_delay_mult = 0.01\n        self.position_lr_max_steps = 30_000\n        self.feature_lr = 0.0025\n        self.opacity_lr = 0.05\n        self.scaling_lr = 0.005  # before 0.005",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "get_combined_args",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "description": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "peekOfCode": "def get_combined_args(parser: ArgumentParser):\n    cmdlne_string = sys.argv[1:]\n    cfgfile_string = \"Namespace()\"\n    args_cmdline = parser.parse_args(cmdlne_string)\n    try:\n        cfgfilepath = os.path.join(args_cmdline.model_path, \"cfg_args\")\n        print(\"Looking for config file in\", cfgfilepath)\n        with open(cfgfilepath) as cfg_file:\n            print(\"Config file found: {}\".format(cfgfilepath))\n            cfgfile_string = cfg_file.read()",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.arguments",
        "documentation": {}
    },
    {
        "label": "BaseDataset",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "description": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "peekOfCode": "class BaseDataset(torch.utils.data.Dataset):\n    def __init__(self, dataset_config: dict):\n        self.dataset_path = Path(dataset_config[\"input_path\"])\n        self.frame_limit = dataset_config.get(\"frame_limit\", -1)\n        self.dataset_config = dataset_config\n        self.height = dataset_config[\"H\"]\n        self.width = dataset_config[\"W\"]\n        self.fx = dataset_config[\"fx\"]\n        self.fy = dataset_config[\"fy\"]\n        self.cx = dataset_config[\"cx\"]",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "Replica",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "description": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "peekOfCode": "class Replica(BaseDataset):\n    def __init__(self, dataset_config: dict):\n        super().__init__(dataset_config)\n        self.color_paths = sorted(\n            list((self.dataset_path / \"results\").glob(\"frame*.jpg\"))\n        )\n        self.depth_paths = sorted(\n            list((self.dataset_path / \"results\").glob(\"depth*.png\"))\n        )\n        self.load_poses(self.dataset_path / \"traj.txt\")",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "TUM_RGBD",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "description": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "peekOfCode": "class TUM_RGBD(BaseDataset):\n    def __init__(self, dataset_config: dict):\n        super().__init__(dataset_config)\n        self.color_paths, self.depth_paths, self.poses = self.loadtum(\n            self.dataset_path, frame_rate=32\n        )\n    def _parse_list(self, filepath, skiprows=0):\n        \"\"\"read list data\"\"\"\n        return np.loadtxt(filepath, delimiter=\" \", dtype=np.unicode_, skiprows=skiprows)\n    def _associate_frames(self, tstamp_image, tstamp_depth, tstamp_pose, max_dt=0.08):",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "ScanNet",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "description": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "peekOfCode": "class ScanNet(BaseDataset):\n    def __init__(self, dataset_config: dict):\n        super().__init__(dataset_config)\n        self.color_paths = sorted(\n            list((self.dataset_path / \"color\").glob(\"*.jpg\")),\n            key=lambda x: int(os.path.basename(x)[:-4]),\n        )\n        self.depth_paths = sorted(\n            list((self.dataset_path / \"depth\").glob(\"*.png\")),\n            key=lambda x: int(os.path.basename(x)[:-4]),",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "ScanNetPP",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "description": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "peekOfCode": "class ScanNetPP(BaseDataset):\n    def __init__(self, dataset_config: dict):\n        super().__init__(dataset_config)\n        self.use_train_split = dataset_config[\"use_train_split\"]\n        self.train_test_split = json.load(\n            open(f\"{self.dataset_path}/dslr/train_test_lists.json\", \"r\")\n        )\n        if self.use_train_split:\n            self.image_names = self.train_test_split[\"train\"]\n        else:",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "description": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "peekOfCode": "def get_dataset(dataset_name: str):\n    if dataset_name == \"replica\":\n        return Replica\n    elif dataset_name == \"tum_rgbd\":\n        return TUM_RGBD\n    elif dataset_name == \"scan_net\":\n        return ScanNet\n    elif dataset_name == \"scannetpp\":\n        return ScanNetPP\n    raise NotImplementedError(f\"Dataset {dataset_name} not implemented\")",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.datasets",
        "documentation": {}
    },
    {
        "label": "GaussianModel",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.gaussian_model",
        "description": "thirdparty.Gaussian-SLAM.src.entities.gaussian_model",
        "peekOfCode": "class GaussianModel:\n    def __init__(self, sh_degree: int = 3, isotropic=False):\n        self.gaussian_param_names = [\n            \"active_sh_degree\",\n            \"xyz\",\n            \"features_dc\",\n            \"features_rest\",\n            \"scaling\",\n            \"rotation\",\n            \"opacity\",",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.gaussian_model",
        "documentation": {}
    },
    {
        "label": "GaussianSLAM",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.gaussian_slam",
        "description": "thirdparty.Gaussian-SLAM.src.entities.gaussian_slam",
        "peekOfCode": "class GaussianSLAM(object):\n    def __init__(self, config: dict) -> None:\n        self._setup_output_path(config)\n        self.device = \"cuda\"\n        self.config = config\n        self.scene_name = config[\"data\"][\"scene_name\"]\n        self.dataset_name = config[\"dataset_name\"]\n        self.dataset = get_dataset(config[\"dataset_name\"])({**config[\"data\"], **config[\"cam\"]})\n        n_frames = len(self.dataset)\n        frame_ids = list(range(n_frames))",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.gaussian_slam",
        "documentation": {}
    },
    {
        "label": "Logger",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.logger",
        "description": "thirdparty.Gaussian-SLAM.src.entities.logger",
        "peekOfCode": "class Logger(object):\n    def __init__(self, output_path: Union[Path, str], use_wandb=False) -> None:\n        self.output_path = Path(output_path)\n        (self.output_path / \"mapping_vis\").mkdir(exist_ok=True, parents=True)\n        self.use_wandb = use_wandb\n    def log_tracking_iteration(self, frame_id, cur_pose, gt_quat, gt_trans, total_loss,\n                               color_loss, depth_loss, iter, num_iters,\n                               wandb_output=False, print_output=False) -> None:\n        \"\"\" Logs tracking iteration metrics including pose error, losses, and optionally reports to Weights & Biases.\n        Logs the error between the current pose estimate and ground truth quaternion and translation,",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.logger",
        "documentation": {}
    },
    {
        "label": "l1_loss",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "description": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "peekOfCode": "def l1_loss(network_output: torch.Tensor, gt: torch.Tensor, agg=\"mean\") -> torch.Tensor:\n    \"\"\"\n    Computes the L1 loss, which is the mean absolute error between the network output and the ground truth.\n    Args:\n        network_output: The output from the network.\n        gt: The ground truth tensor.\n        agg: The aggregation method to be used. Defaults to \"mean\".\n    Returns:\n        The computed L1 loss.\n    \"\"\"",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "documentation": {}
    },
    {
        "label": "gaussian",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "description": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "peekOfCode": "def gaussian(window_size: int, sigma: float) -> torch.Tensor:\n    \"\"\"\n    Creates a 1D Gaussian kernel.\n    Args:\n        window_size: The size of the window for the Gaussian kernel.\n        sigma: The standard deviation of the Gaussian kernel.\n    Returns:\n        The 1D Gaussian kernel.\n    \"\"\"\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 /",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "documentation": {}
    },
    {
        "label": "create_window",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "description": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "peekOfCode": "def create_window(window_size: int, channel: int) -> Variable:\n    \"\"\"\n    Creates a 2D Gaussian window/kernel for SSIM computation.\n    Args:\n        window_size: The size of the window to be created.\n        channel: The number of channels in the image.\n    Returns:\n        A 2D Gaussian window expanded to match the number of channels.\n    \"\"\"\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "documentation": {}
    },
    {
        "label": "ssim",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "description": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "peekOfCode": "def ssim(img1: torch.Tensor, img2: torch.Tensor, window_size: int = 11, size_average: bool = True) -> torch.Tensor:\n    \"\"\"\n    Computes the Structural Similarity Index (SSIM) between two images.\n    Args:\n        img1: The first image.\n        img2: The second image.\n        window_size: The size of the window to be used in SSIM computation. Defaults to 11.\n        size_average: If True, averages the SSIM over all pixels. Defaults to True.\n    Returns:\n        The computed SSIM value.",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "documentation": {}
    },
    {
        "label": "isotropic_loss",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "description": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "peekOfCode": "def isotropic_loss(scaling: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Computes loss enforcing isotropic scaling for the 3D Gaussians\n    Args:\n        scaling: scaling tensor of 3D Gaussians of shape (n, 3)\n    Returns:\n        The computed isotropic loss\n    \"\"\"\n    mean_scaling = scaling.mean(dim=1, keepdim=True)\n    isotropic_diff = torch.abs(scaling - mean_scaling * torch.ones_like(scaling))",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.losses",
        "documentation": {}
    },
    {
        "label": "Mapper",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.mapper",
        "description": "thirdparty.Gaussian-SLAM.src.entities.mapper",
        "peekOfCode": "class Mapper(object):\n    def __init__(self, config: dict, dataset: BaseDataset, logger: Logger) -> None:\n        \"\"\" Sets up the mapper parameters\n        Args:\n            config: configuration of the mapper\n            dataset: The dataset object used for extracting camera parameters and reading the data\n            logger: The logger object used for logging the mapping process and saving visualizations\n        \"\"\"\n        self.config = config\n        self.logger = logger",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.mapper",
        "documentation": {}
    },
    {
        "label": "Tracker",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.tracker",
        "description": "thirdparty.Gaussian-SLAM.src.entities.tracker",
        "peekOfCode": "class Tracker(object):\n    def __init__(self, config: dict, dataset: BaseDataset, logger: Logger) -> None:\n        \"\"\" Initializes the Tracker with a given configuration, dataset, and logger.\n        Args:\n            config: Configuration dictionary specifying hyperparameters and operational settings.\n            dataset: The dataset object providing access to the sequence of frames.\n            logger: Logger object for logging the tracking process.\n        \"\"\"\n        self.dataset = dataset\n        self.logger = logger",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.tracker",
        "documentation": {}
    },
    {
        "label": "VisualOdometer",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.entities.visual_odometer",
        "description": "thirdparty.Gaussian-SLAM.src.entities.visual_odometer",
        "peekOfCode": "class VisualOdometer(object):\n    def __init__(self, intrinsics: np.ndarray, method_name=\"hybrid\", device=\"cuda\"):\n        \"\"\" Initializes the visual odometry system with specified intrinsics, method, and device.\n        Args:\n            intrinsics: Camera intrinsic parameters.\n            method_name: The name of the odometry computation method to use ('hybrid' or 'point_to_plane').\n            device: The computation device ('cuda' or 'cpu').\n        \"\"\"\n        device = \"CUDA:0\" if device == \"cuda\" else \"CPU:0\"\n        self.device = o3c.Device(device)",
        "detail": "thirdparty.Gaussian-SLAM.src.entities.visual_odometer",
        "documentation": {}
    },
    {
        "label": "RenderFrames",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "peekOfCode": "class RenderFrames(Dataset):\n    \"\"\"A dataset class for loading keyframes along with their estimated camera poses and render settings.\"\"\"\n    def __init__(self, dataset, render_poses: np.ndarray, height: int, width: int, fx: float, fy: float):\n        self.dataset = dataset\n        self.render_poses = render_poses\n        self.height = height\n        self.width = width\n        self.fx = fx\n        self.fy = fy\n        self.device = \"cuda\"",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "documentation": {}
    },
    {
        "label": "merge_submaps",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "peekOfCode": "def merge_submaps(submaps_paths: list, radius: float = 0.0001, device: str = \"cuda\") -> o3d.geometry.PointCloud:\n    \"\"\" Merge submaps into a single point cloud, which is then used for global map refinement.\n    Args:\n        segments_paths (list): Folder path of the submaps.\n        radius (float, optional): Nearest neighbor distance threshold for adding a point. Defaults to 0.0001.\n        device (str, optional): Defaults to \"cuda\".\n    Returns:\n        o3d.geometry.PointCloud: merged point cloud\n    \"\"\"\n    pts_index = faiss.IndexFlatL2(3)",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "documentation": {}
    },
    {
        "label": "refine_global_map",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "peekOfCode": "def refine_global_map(pt_cloud: o3d.geometry.PointCloud, training_frames: list, max_iterations: int) -> GaussianModel:\n    \"\"\"Refines a global map based on the merged point cloud and training keyframes frames.\n    Args:\n        pt_cloud (o3d.geometry.PointCloud): The merged point cloud used for refinement.\n        training_frames (list): A list of training frames for map refinement.\n        max_iterations (int): The maximum number of iterations to perform for refinement.\n    Returns:\n        GaussianModel: The refined global map as a Gaussian model.\n    \"\"\"\n    opt_params = OptimizationParams(ArgumentParser(description=\"Training script parameters\"))",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_merged_map",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def normalize(x):\n    return x / np.linalg.norm(x)\ndef get_align_transformation(rec_meshfile, gt_meshfile):\n    \"\"\"\n    Get the transformation matrix to align the reconstructed mesh to the ground truth mesh.\n    \"\"\"\n    o3d_rec_mesh = o3d.io.read_triangle_mesh(rec_meshfile)\n    o3d_gt_mesh = o3d.io.read_triangle_mesh(gt_meshfile)\n    o3d_rec_pc = o3d.geometry.PointCloud(points=o3d_rec_mesh.vertices)\n    o3d_gt_pc = o3d.geometry.PointCloud(points=o3d_gt_mesh.vertices)",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "get_align_transformation",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def get_align_transformation(rec_meshfile, gt_meshfile):\n    \"\"\"\n    Get the transformation matrix to align the reconstructed mesh to the ground truth mesh.\n    \"\"\"\n    o3d_rec_mesh = o3d.io.read_triangle_mesh(rec_meshfile)\n    o3d_gt_mesh = o3d.io.read_triangle_mesh(gt_meshfile)\n    o3d_rec_pc = o3d.geometry.PointCloud(points=o3d_rec_mesh.vertices)\n    o3d_gt_pc = o3d.geometry.PointCloud(points=o3d_gt_mesh.vertices)\n    trans_init = np.eye(4)\n    threshold = 0.1",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "check_proj",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def check_proj(points, W, H, fx, fy, cx, cy, c2w):\n    \"\"\"\n    Check if points can be projected into the camera view.\n    Returns:\n        bool: True if there are points can be projected\n    \"\"\"\n    c2w = c2w.copy()\n    c2w[:3, 1] *= -1.0\n    c2w[:3, 2] *= -1.0\n    points = torch.from_numpy(points).cuda().clone()",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "get_cam_position",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def get_cam_position(gt_meshfile):\n    mesh_gt = trimesh.load(gt_meshfile)\n    to_origin, extents = trimesh.bounds.oriented_bounds(mesh_gt)\n    extents[2] *= 0.7\n    extents[1] *= 0.7\n    extents[0] *= 0.3\n    transform = np.linalg.inv(to_origin)\n    transform[2, 3] += 0.4\n    return extents, transform\ndef viewmatrix(z, up, pos):",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "viewmatrix",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def viewmatrix(z, up, pos):\n    vec2 = normalize(z)\n    vec1_avg = up\n    vec0 = normalize(np.cross(vec1_avg, vec2))\n    vec1 = normalize(np.cross(vec2, vec0))\n    m = np.stack([vec0, vec1, vec2, pos], 1)\n    return m\ndef calc_2d_metric(\n    rec_meshfile, gt_meshfile, unseen_gt_pointcloud_file, align=True, n_imgs=1000\n):",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "calc_2d_metric",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def calc_2d_metric(\n    rec_meshfile, gt_meshfile, unseen_gt_pointcloud_file, align=True, n_imgs=1000\n):\n    \"\"\"\n    2D reconstruction metric, depth L1 loss.\n    \"\"\"\n    H = 500\n    W = 500\n    focal = 300\n    fx = focal",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "clean_mesh",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def clean_mesh(mesh):\n    mesh_tri = trimesh.Trimesh(\n        vertices=np.asarray(mesh.vertices),\n        faces=np.asarray(mesh.triangles),\n        vertex_colors=np.asarray(mesh.vertex_colors),\n    )\n    components = trimesh.graph.connected_components(\n        edges=mesh_tri.edges_sorted)\n    min_len = 200\n    components_to_keep = [c for c in components if len(c) >= min_len]",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "evaluate_reconstruction",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "peekOfCode": "def evaluate_reconstruction(\n    mesh_path: Path,\n    gt_mesh_path: Path,\n    unseen_pc_path: Path,\n    output_path: Path,\n    to_clean=True,\n):\n    if to_clean:\n        mesh = o3d.io.read_triangle_mesh(str(mesh_path))\n        print(mesh)",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_reconstruction",
        "documentation": {}
    },
    {
        "label": "NumpyFloatValuesEncoder",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "peekOfCode": "class NumpyFloatValuesEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.float32):\n            return float(obj)\n        return JSONEncoder.default(self, obj)\ndef align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Input:\n    model -- first trajectory (3xn)\n    data -- second trajectory (3xn)",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "documentation": {}
    },
    {
        "label": "align",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "peekOfCode": "def align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Input:\n    model -- first trajectory (3xn)\n    data -- second trajectory (3xn)\n    Output:\n    rot -- rotation matrix (3x3)\n    trans -- translation vector (3x1)\n    trans_error -- translational error per point (1xn)\n    \"\"\"",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "documentation": {}
    },
    {
        "label": "align_trajectories",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "peekOfCode": "def align_trajectories(t_pred: np.ndarray, t_gt: np.ndarray):\n    \"\"\"\n    Args:\n        t_pred: (n, 3) translations\n        t_gt: (n, 3) translations\n    Returns:\n        t_align: (n, 3) aligned translations\n    \"\"\"\n    t_align = np.matrix(t_pred).transpose()\n    R, t, _ = align(t_align, np.matrix(t_gt).transpose())",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "documentation": {}
    },
    {
        "label": "pose_error",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "peekOfCode": "def pose_error(t_pred: np.ndarray, t_gt: np.ndarray, align=False):\n    \"\"\"\n    Args:\n        t_pred: (n, 3) translations\n        t_gt: (n, 3) translations\n    Returns:\n        dict: error dict\n    \"\"\"\n    n = t_pred.shape[0]\n    trans_error = np.linalg.norm(t_pred - t_gt, axis=1)",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "documentation": {}
    },
    {
        "label": "plot_2d",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "peekOfCode": "def plot_2d(pts, ax=None, color=\"green\", label=\"None\", title=\"3D Trajectory in 2D\"):\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.scatter(pts[:, 0], pts[:, 1], color=color, label=label, s=0.7)\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_title(title)\n    return ax\ndef evaluate_trajectory(estimated_poses: np.ndarray, gt_poses: np.ndarray, output_path: Path):\n    output_path.mkdir(exist_ok=True, parents=True)",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "documentation": {}
    },
    {
        "label": "evaluate_trajectory",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "peekOfCode": "def evaluate_trajectory(estimated_poses: np.ndarray, gt_poses: np.ndarray, output_path: Path):\n    output_path.mkdir(exist_ok=True, parents=True)\n    # Truncate the ground truth trajectory if needed\n    if gt_poses.shape[0] > estimated_poses.shape[0]:\n        gt_poses = gt_poses[:estimated_poses.shape[0]]\n    valid = ~np.any(np.isnan(gt_poses) |\n                    np.isinf(gt_poses), axis=(1, 2))\n    gt_poses = gt_poses[valid]\n    estimated_poses = estimated_poses[valid]\n    gt_t = gt_poses[:, :3, 3]",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluate_trajectory",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluator",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluator",
        "peekOfCode": "class Evaluator(object):\n    def __init__(self, checkpoint_path, config_path, config=None, save_render=False) -> None:\n        if config is None:\n            self.config = load_config(config_path)\n        else:\n            self.config = config\n        setup_seed(self.config[\"seed\"])\n        self.checkpoint_path = Path(checkpoint_path)\n        self.device = \"cuda\"\n        self.dataset = get_dataset(self.config[\"dataset_name\"])({**self.config[\"data\"], **self.config[\"cam\"]})",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluator",
        "documentation": {}
    },
    {
        "label": "filter_depth_outliers",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.evaluation.evaluator",
        "description": "thirdparty.Gaussian-SLAM.src.evaluation.evaluator",
        "peekOfCode": "def filter_depth_outliers(depth_map, kernel_size=3, threshold=1.0):\n    median_filtered = median_filter(depth_map, size=kernel_size)\n    abs_diff = np.abs(depth_map - median_filtered)\n    outlier_mask = abs_diff > threshold\n    depth_map_filtered = np.where(outlier_mask, median_filtered, depth_map)\n    return depth_map_filtered\nclass Evaluator(object):\n    def __init__(self, checkpoint_path, config_path, config=None, save_render=False) -> None:\n        if config is None:\n            self.config = load_config(config_path)",
        "detail": "thirdparty.Gaussian-SLAM.src.evaluation.evaluator",
        "documentation": {}
    },
    {
        "label": "eval_sh",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def eval_sh(deg, sh, dirs):\n    \"\"\"\n    Evaluate spherical harmonics at unit directions\n    using hardcoded SH polynomials.\n    Works with torch/np/jnp.\n    ... Can be 0 or more batch dimensions.\n    Args:\n        deg: int SH deg. Currently, 0-3 supported\n        sh: jnp.ndarray SH coeffs [..., C, (deg + 1) ** 2]\n        dirs: jnp.ndarray unit directions [..., 3]",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "RGB2SH",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def RGB2SH(rgb):\n    return (rgb - 0.5) / C0\ndef SH2RGB(sh):\n    return sh * C0 + 0.5\ndef inverse_sigmoid(x):\n    return torch.log(x/(1-x))\ndef get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):\n    \"\"\"",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "SH2RGB",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def SH2RGB(sh):\n    return sh * C0 + 0.5\ndef inverse_sigmoid(x):\n    return torch.log(x/(1-x))\ndef get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):\n    \"\"\"\n    Copied from Plenoxels\n    Continuous learning rate decay function. Adapted from JaxNeRF",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def inverse_sigmoid(x):\n    return torch.log(x/(1-x))\ndef get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):\n    \"\"\"\n    Copied from Plenoxels\n    Continuous learning rate decay function. Adapted from JaxNeRF\n    The returned rate is lr_init when step=0 and lr_final when step=max_steps, and\n    is log-linearly interpolated elsewhere (equivalent to exponential decay).",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "get_expon_lr_func",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):\n    \"\"\"\n    Copied from Plenoxels\n    Continuous learning rate decay function. Adapted from JaxNeRF\n    The returned rate is lr_init when step=0 and lr_final when step=max_steps, and\n    is log-linearly interpolated elsewhere (equivalent to exponential decay).\n    If lr_delay_steps>0 then the learning rate will be scaled by some smooth\n    function of lr_delay_mult, such that the initial learning rate is",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "strip_lowerdiag",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def strip_lowerdiag(L):\n    uncertainty = torch.zeros(\n        (L.shape[0], 6), dtype=torch.float, device=\"cuda\")\n    uncertainty[:, 0] = L[:, 0, 0]\n    uncertainty[:, 1] = L[:, 0, 1]\n    uncertainty[:, 2] = L[:, 0, 2]\n    uncertainty[:, 3] = L[:, 1, 1]\n    uncertainty[:, 4] = L[:, 1, 2]\n    uncertainty[:, 5] = L[:, 2, 2]\n    return uncertainty",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "strip_symmetric",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def strip_symmetric(sym):\n    return strip_lowerdiag(sym)\ndef build_rotation(r):\n    q = F.normalize(r, p=2, dim=1)\n    R = torch.zeros((q.size(0), 3, 3), device='cuda')\n    r = q[:, 0]\n    x = q[:, 1]\n    y = q[:, 2]\n    z = q[:, 3]\n    R[:, 0, 0] = 1 - 2 * (y*y + z*z)",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def build_rotation(r):\n    q = F.normalize(r, p=2, dim=1)\n    R = torch.zeros((q.size(0), 3, 3), device='cuda')\n    r = q[:, 0]\n    x = q[:, 1]\n    y = q[:, 2]\n    z = q[:, 3]\n    R[:, 0, 0] = 1 - 2 * (y*y + z*z)\n    R[:, 0, 1] = 2 * (x*y - r*z)\n    R[:, 0, 2] = 2 * (x*z + r*y)",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "build_scaling_rotation",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "def build_scaling_rotation(s, r):\n    L = torch.zeros((s.shape[0], 3, 3), dtype=torch.float, device=\"cuda\")\n    R = build_rotation(r)\n    L[:, 0, 0] = s[:, 0]\n    L[:, 1, 1] = s[:, 1]\n    L[:, 2, 2] = s[:, 2]\n    L = R @ L\n    return L",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "C0",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "C0 = 0.28209479177387814\nC1 = 0.4886025119029199\nC2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396\n]\nC3 = [",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "C1",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "C1 = 0.4886025119029199\nC2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396\n]\nC3 = [\n    -0.5900435899266435,",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "C2",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "C2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396\n]\nC3 = [\n    -0.5900435899266435,\n    2.890611442640554,",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "C3",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "C3 = [\n    -0.5900435899266435,\n    2.890611442640554,\n    -0.4570457994644658,\n    0.3731763325901154,\n    -0.4570457994644658,\n    1.445305721320277,\n    -0.5900435899266435\n]\nC4 = [",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "C4",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "peekOfCode": "C4 = [\n    2.5033429417967046,\n    -1.7701307697799304,\n    0.9461746957575601,\n    -0.6690465435572892,\n    0.10578554691520431,\n    -0.6690465435572892,\n    0.47308734787878004,\n    -1.7701307697799304,\n    0.6258357354491761,",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.gaussian_model_utils",
        "documentation": {}
    },
    {
        "label": "mkdir_decorator",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def mkdir_decorator(func):\n    \"\"\"A decorator that creates the directory specified in the function's 'directory' keyword\n       argument before calling the function.\n    Args:\n        func: The function to be decorated.\n    Returns:\n        The wrapper function.\n    \"\"\"\n    def wrapper(*args, **kwargs):\n        output_path = Path(kwargs[\"directory\"])",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "save_clouds",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def save_clouds(clouds: list, cloud_names: list, *, directory: Union[str, Path]) -> None:\n    \"\"\" Saves a list of point clouds to the specified directory, creating the directory if it does not exist.\n    Args:\n        clouds: A list of point cloud objects to be saved.\n        cloud_names: A list of filenames for the point clouds, corresponding by index to the clouds.\n        directory: The directory where the point clouds will be saved.\n    \"\"\"\n    for cld_name, cloud in zip(cloud_names, clouds):\n        o3d.io.write_point_cloud(str(directory / cld_name), cloud)\n@mkdir_decorator",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "save_dict_to_ckpt",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def save_dict_to_ckpt(dictionary, file_name: str, *, directory: Union[str, Path]) -> None:\n    \"\"\" Saves a dictionary to a checkpoint file in the specified directory, creating the directory if it does not exist.\n    Args:\n        dictionary: The dictionary to be saved.\n        file_name: The name of the checkpoint file.\n        directory: The directory where the checkpoint file will be saved.\n    \"\"\"\n    torch.save(dictionary, directory / file_name,\n               _use_new_zipfile_serialization=False)\n@mkdir_decorator",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "save_dict_to_yaml",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def save_dict_to_yaml(dictionary, file_name: str, *, directory: Union[str, Path]) -> None:\n    \"\"\" Saves a dictionary to a YAML file in the specified directory, creating the directory if it does not exist.\n    Args:\n        dictionary: The dictionary to be saved.\n        file_name: The name of the YAML file.\n        directory: The directory where the YAML file will be saved.\n    \"\"\"\n    with open(directory / file_name, \"w\") as f:\n        yaml.dump(dictionary, f)\n@mkdir_decorator",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "save_dict_to_json",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def save_dict_to_json(dictionary, file_name: str, *, directory: Union[str, Path]) -> None:\n    \"\"\" Saves a dictionary to a JSON file in the specified directory, creating the directory if it does not exist.\n    Args:\n        dictionary: The dictionary to be saved.\n        file_name: The name of the JSON file.\n        directory: The directory where the JSON file will be saved.\n    \"\"\"\n    with open(directory / file_name, \"w\") as f:\n        json.dump(dictionary, f)\ndef load_config(path: str, default_path: str = None) -> dict:",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "load_config",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def load_config(path: str, default_path: str = None) -> dict:\n    \"\"\"\n    Loads a configuration file and optionally merges it with a default configuration file.\n    This function loads a configuration from the given path. If the configuration specifies an inheritance\n    path (`inherit_from`), or if a `default_path` is provided, it loads the base configuration and updates it\n    with the specific configuration.\n    Args:\n        path: The path to the specific configuration file.\n        default_path: An optional path to a default configuration file that is loaded if the specific configuration\n                      does not specify an inheritance or as a base for the inheritance.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "update_recursive",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def update_recursive(dict1: dict, dict2: dict) -> None:\n    \"\"\" Recursively updates the first dictionary with the contents of the second dictionary.\n    This function iterates through `dict2` and updates `dict1` with its contents. If a key from `dict2`\n    exists in `dict1` and its value is also a dictionary, the function updates the value recursively.\n    Otherwise, it overwrites the value in `dict1` with the value from `dict2`.\n    Args:\n        dict1: The dictionary to be updated.\n        dict2: The dictionary whose entries are used to update `dict1`.\n    Returns:\n        None: The function modifies `dict1` in place.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "log_metrics_to_wandb",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "peekOfCode": "def log_metrics_to_wandb(json_files: list, output_path: str, section: str = \"Evaluation\") -> None:\n    \"\"\" Logs metrics from JSON files to Weights & Biases under a specified section.\n    This function reads metrics from a list of JSON files and logs them to Weights & Biases (wandb).\n    Each metric is prefixed with a specified section name for organized logging.\n    Args:\n        json_files: A list of filenames for JSON files containing metrics to be logged.\n        output_path: The directory path where the JSON files are located.\n        section: The section under which to log the metrics in wandb. Defaults to \"Evaluation\".\n    Returns:\n        None: Metrics are logged to wandb and the function does not return a value.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.io_utils",
        "documentation": {}
    },
    {
        "label": "compute_opt_views_distribution",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def compute_opt_views_distribution(keyframes_num, iterations_num, current_frame_iter) -> np.ndarray:\n    \"\"\" Computes the probability distribution for selecting views based on the current iteration.\n    Args:\n        keyframes_num: The total number of keyframes.\n        iterations_num: The total number of iterations planned.\n        current_frame_iter: The current iteration number.\n    Returns:\n        An array representing the probability distribution of keyframes.\n    \"\"\"\n    if keyframes_num == 1:",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_camera_frustum_corners",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def compute_camera_frustum_corners(depth_map: np.ndarray, pose: np.ndarray, intrinsics: np.ndarray) -> np.ndarray:\n    \"\"\" Computes the 3D coordinates of the camera frustum corners based on the depth map, pose, and intrinsics.\n    Args:\n        depth_map: The depth map of the scene.\n        pose: The camera pose matrix.\n        intrinsics: The camera intrinsic matrix.\n    Returns:\n        An array of 3D coordinates for the frustum corners.\n    \"\"\"\n    height, width = depth_map.shape",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_camera_frustum_planes",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def compute_camera_frustum_planes(frustum_corners: np.ndarray) -> torch.Tensor:\n    \"\"\" Computes the planes of the camera frustum from its corners.\n    Args:\n        frustum_corners: An array of 3D coordinates representing the corners of the frustum.\n    Returns:\n        A tensor of frustum planes.\n    \"\"\"\n    # near, far, left, right, top, bottom\n    planes = torch.stack(\n        [",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_frustum_aabb",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def compute_frustum_aabb(frustum_corners: torch.Tensor):\n    \"\"\" Computes a mask indicating which points lie inside a given axis-aligned bounding box (AABB).\n    Args:\n        points: An array of 3D points.\n        min_corner: The minimum corner of the AABB.\n        max_corner: The maximum corner of the AABB.\n    Returns:\n        A boolean array indicating whether each point lies inside the AABB.\n    \"\"\"\n    return torch.min(frustum_corners, axis=0).values, torch.max(frustum_corners, axis=0).values",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "points_inside_aabb_mask",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def points_inside_aabb_mask(points: np.ndarray, min_corner: np.ndarray, max_corner: np.ndarray) -> np.ndarray:\n    \"\"\" Computes a mask indicating which points lie inside the camera frustum.\n    Args:\n        points: A tensor of 3D points.\n        frustum_planes: A tensor representing the planes of the frustum.\n    Returns:\n        A boolean tensor indicating whether each point lies inside the frustum.\n    \"\"\"\n    return (\n        (points[:, 0] >= min_corner[0])",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "points_inside_frustum_mask",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def points_inside_frustum_mask(points: torch.Tensor, frustum_planes: torch.Tensor) -> torch.Tensor:\n    \"\"\" Computes a mask indicating which points lie inside the camera frustum.\n    Args:\n        points: A tensor of 3D points.\n        frustum_planes: A tensor representing the planes of the frustum.\n    Returns:\n        A boolean tensor indicating whether each point lies inside the frustum.\n    \"\"\"\n    num_pts = points.shape[0]\n    ones = torch.ones(num_pts, 1).to(points.device)",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_frustum_point_ids",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def compute_frustum_point_ids(pts: torch.Tensor, frustum_corners: torch.Tensor, device: str = \"cuda\"):\n    \"\"\" Identifies points within the camera frustum, optimizing for computation on a specified device.\n    Args:\n        pts: A tensor of 3D points.\n        frustum_corners: A tensor of 3D coordinates representing the corners of the frustum.\n        device: The computation device (\"cuda\" or \"cpu\").\n    Returns:\n        Indices of points lying inside the frustum.\n    \"\"\"\n    if pts.shape[0] == 0:",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "sample_pixels_based_on_gradient",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def sample_pixels_based_on_gradient(image: np.ndarray, num_samples: int) -> np.ndarray:\n    \"\"\" Samples pixel indices based on the gradient magnitude of an image.\n    Args:\n        image: The image from which to sample pixels.\n        num_samples: The number of pixels to sample.\n    Returns:\n        Indices of the sampled pixels.\n    \"\"\"\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "compute_new_points_ids",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def compute_new_points_ids(frustum_points: torch.Tensor, new_pts: torch.Tensor,\n                           radius: float = 0.03, device: str = \"cpu\") -> torch.Tensor:\n    \"\"\" Having newly initialized points, decides which of them should be added to the submap.\n        For every new point, if there are no neighbors within the radius in the frustum points,\n        it is added to the submap.\n    Args:\n        frustum_points: Point within a current frustum of the active submap of shape (N, 3)\n        new_pts: New 3D Gaussian means which are about to be added to the submap of shape (N, 3)\n        radius: Radius whithin which the points are considered to be neighbors\n        device: Execution device",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "rotation_to_euler",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def rotation_to_euler(R: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Converts a rotation matrix to Euler angles.\n    Args:\n        R: A rotation matrix.\n    Returns:\n        Euler angles corresponding to the rotation matrix.\n    \"\"\"\n    sy = torch.sqrt(R[0, 0] ** 2 + R[1, 0] ** 2)\n    singular = sy < 1e-6",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "exceeds_motion_thresholds",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def exceeds_motion_thresholds(current_c2w: torch.Tensor, last_submap_c2w: torch.Tensor,\n                              rot_thre: float = 50, trans_thre: float = 0.5) -> bool:\n    \"\"\"  Checks if a camera motion exceeds certain rotation and translation thresholds\n    Args:\n        current_c2w: The current camera-to-world transformation matrix.\n        last_submap_c2w: The last submap's camera-to-world transformation matrix.\n        rot_thre: The rotation threshold for triggering a new submap.\n        trans_thre: The translation threshold for triggering a new submap.\n    Returns:\n        A boolean indicating whether a new submap is required.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "geometric_edge_mask",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def geometric_edge_mask(rgb_image: np.ndarray, dilate: bool = True, RGB: bool = False) -> np.ndarray:\n    \"\"\" Computes an edge mask for an RGB image using geometric edges.\n    Args:\n        rgb_image: The RGB image.\n        dilate: Whether to dilate the edges.\n        RGB: Indicates if the image format is RGB (True) or BGR (False).\n    Returns:\n        An edge mask of the input image.\n    \"\"\"\n    # Convert the image to grayscale as Canny edge detection requires a single channel image",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "calc_psnr",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def calc_psnr(img1: torch.Tensor, img2: torch.Tensor) -> torch.Tensor:\n    \"\"\" Calculates the Peak Signal-to-Noise Ratio (PSNR) between two images.\n    Args:\n        img1: The first image.\n        img2: The second image.\n    Returns:\n        The PSNR value.\n    \"\"\"\n    mse = ((img1 - img2) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\n    return 20 * torch.log10(1.0 / torch.sqrt(mse))",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "create_point_cloud",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "peekOfCode": "def create_point_cloud(image: np.ndarray, depth: np.ndarray, intrinsics: np.ndarray, pose: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Creates a point cloud from an image, depth map, camera intrinsics, and pose.\n    Args:\n        image: The RGB image of shape (H, W, 3)\n        depth: The depth map of shape (H, W)\n        intrinsics: The camera intrinsic parameters of shape (3, 3)\n        pose: The camera pose of shape (4, 4)\n    Returns:\n        A point cloud of shape (N, 6) with last dimension representing (x, y, z, r, g, b)",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.mapper_utils",
        "documentation": {}
    },
    {
        "label": "multiply_quaternions",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "peekOfCode": "def multiply_quaternions(q: torch.Tensor, r: torch.Tensor) -> torch.Tensor:\n    \"\"\"Performs batch-wise quaternion multiplication.\n    Given two quaternions, this function computes their product. The operation is\n    vectorized and can be performed on batches of quaternions.\n    Args:\n        q: A tensor representing the first quaternion or a batch of quaternions. \n           Expected shape is (... , 4), where the last dimension contains quaternion components (w, x, y, z).\n        r: A tensor representing the second quaternion or a batch of quaternions with the same shape as q.\n    Returns:\n        A tensor of the same shape as the input tensors, representing the product of the input quaternions.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "transformation_to_quaternion",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "peekOfCode": "def transformation_to_quaternion(RT: Union[torch.Tensor, np.ndarray]):\n    \"\"\" Converts a rotation-translation matrix to a tensor representing quaternion and translation.\n    This function takes a 3x4 transformation matrix (rotation and translation) and converts it\n    into a tensor that combines the quaternion representation of the rotation and the translation vector.\n    Args:\n        RT: A 3x4 matrix representing the rotation and translation. This can be a NumPy array\n            or a torch.Tensor. If it's a torch.Tensor and resides on a GPU, it will be moved to CPU.\n    Returns:\n        A tensor combining the quaternion (in w, x, y, z order) and translation vector. The tensor\n        will be moved to the original device if the input was a GPU tensor.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "extrapolate_poses",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "peekOfCode": "def extrapolate_poses(poses: np.ndarray) -> np.ndarray:\n    \"\"\" Generates an interpolated pose based on the first two poses in the given array.\n    Args:\n        poses: An array of poses, where each pose is represented by a 4x4 transformation matrix.\n    Returns:\n        A 4x4 numpy ndarray representing the interpolated transformation matrix.\n    \"\"\"\n    return poses[1, :] @ np.linalg.inv(poses[0, :]) @ poses[1, :]\ndef compute_camera_opt_params(estimate_rel_w2c: np.ndarray) -> tuple:\n    \"\"\" Computes the camera's rotation and translation parameters from an world-to-camera transformation matrix.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "compute_camera_opt_params",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "peekOfCode": "def compute_camera_opt_params(estimate_rel_w2c: np.ndarray) -> tuple:\n    \"\"\" Computes the camera's rotation and translation parameters from an world-to-camera transformation matrix.\n    This function extracts the rotation component of the transformation matrix, converts it to a quaternion,\n    and reorders it to match a specific convention. Both rotation and translation parameters are converted\n    to torch Parameters and intended to be optimized in a PyTorch model.\n    Args:\n        estimate_rel_w2c: A 4x4 numpy ndarray representing the estimated world-to-camera transformation matrix.\n    Returns:\n        A tuple containing two torch.nn.Parameters: camera's rotation and camera's translation.\n    \"\"\"",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.tracker_utils",
        "documentation": {}
    },
    {
        "label": "setup_seed",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def setup_seed(seed: int) -> None:\n    \"\"\" Sets the seed for generating random numbers to ensure reproducibility across multiple runs.\n    Args:\n        seed: The seed value to set for random number generators in torch, numpy, and random.\n    \"\"\"\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "torch2np",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def torch2np(tensor: torch.Tensor) -> np.ndarray:\n    \"\"\" Converts a PyTorch tensor to a NumPy ndarray.\n    Args:\n        tensor: The PyTorch tensor to convert.\n    Returns:\n        A NumPy ndarray with the same data and dtype as the input tensor.\n    \"\"\"\n    return tensor.detach().cpu().numpy()\ndef np2torch(array: np.ndarray, device: str = \"cpu\") -> torch.Tensor:\n    \"\"\"Converts a NumPy ndarray to a PyTorch tensor.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2torch",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def np2torch(array: np.ndarray, device: str = \"cpu\") -> torch.Tensor:\n    \"\"\"Converts a NumPy ndarray to a PyTorch tensor.\n    Args:\n        array: The NumPy ndarray to convert.\n        device: The device to which the tensor is sent. Defaults to 'cpu'.\n    Returns:\n        A PyTorch tensor with the same data as the input array.\n    \"\"\"\n    return torch.from_numpy(array).float().to(device)\ndef np2ptcloud(pts: np.ndarray, rgb=None) -> o3d.geometry.PointCloud:",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "np2ptcloud",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def np2ptcloud(pts: np.ndarray, rgb=None) -> o3d.geometry.PointCloud:\n    \"\"\"converts numpy array to point cloud\n    Args:\n        pts (ndarray): point cloud\n    Returns:\n        (PointCloud): resulting point cloud\n    \"\"\"\n    cloud = o3d.geometry.PointCloud()\n    cloud.points = o3d.utility.Vector3dVector(pts)\n    if rgb is not None:",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "dict2device",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def dict2device(dict: dict, device: str = \"cpu\") -> dict:\n    \"\"\"Sends all tensors in a dictionary to a specified device.\n    Args:\n        dict: The dictionary containing tensors.\n        device: The device to send the tensors to. Defaults to 'cpu'.\n    Returns:\n        The dictionary with all tensors sent to the specified device.\n    \"\"\"\n    for k, v in dict.items():\n        if isinstance(v, torch.Tensor):",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "get_render_settings",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def get_render_settings(w, h, intrinsics, w2c, near=0.01, far=100, sh_degree=0):\n    \"\"\"\n    Constructs and returns a GaussianRasterizationSettings object for rendering,\n    configured with given camera parameters.\n    Args:\n        width (int): The width of the image.\n        height (int): The height of the image.\n        intrinsic (array): 3*3, Intrinsic camera matrix.\n        w2c (array): World to camera transformation matrix.\n        near (float, optional): The near plane for the camera. Defaults to 0.01.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "render_gaussian_model",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def render_gaussian_model(gaussian_model, render_settings,\n                          override_means_3d=None, override_means_2d=None,\n                          override_scales=None, override_rotations=None,\n                          override_opacities=None, override_colors=None):\n    \"\"\"\n    Renders a Gaussian model with specified rendering settings, allowing for\n    optional overrides of various model parameters.\n    Args:\n        gaussian_model: A Gaussian model object that provides methods to get\n            various properties like xyz coordinates, opacity, features, etc.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "batch_search_faiss",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "peekOfCode": "def batch_search_faiss(indexer, query_points, k):\n    \"\"\"\n    Perform a batch search on a IndexIVFFlat indexer to circumvent the search size limit of 65535.\n    Args:\n        indexer: The FAISS indexer object.\n        query_points: A tensor of query points.\n        k (int): The number of nearest neighbors to find.\n    Returns:\n        distances (torch.Tensor): The distances of the nearest neighbors.\n        ids (torch.Tensor): The indices of the nearest neighbors.",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.utils",
        "documentation": {}
    },
    {
        "label": "get_color",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "peekOfCode": "def get_color(color_name: str):\n    \"\"\" Returns the RGB values of a given color name as a normalized numpy array.\n    Args:\n        color_name: The name of the color. Can be any color name from CSS4_COLORS.\n    Returns:\n        A numpy array representing the RGB values of the specified color, normalized to the range [0, 1].\n    \"\"\"\n    if color_name == \"custom_yellow\":\n        return np.asarray([255.0, 204.0, 102.0]) / 255.0\n    if color_name == \"custom_blue\":",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "plot_ptcloud",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "peekOfCode": "def plot_ptcloud(point_clouds: Union[List, o3d.geometry.PointCloud], show_frame: bool = True):\n    \"\"\" Visualizes one or more point clouds, optionally showing the coordinate frame.\n    Args:\n        point_clouds: A single point cloud or a list of point clouds to be visualized.\n        show_frame: If True, displays the coordinate frame in the visualization. Defaults to True.\n    \"\"\"\n    # rotate down up\n    if not isinstance(point_clouds, list):\n        point_clouds = [point_clouds]\n    if show_frame:",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "draw_registration_result_original_color",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "peekOfCode": "def draw_registration_result_original_color(source: o3d.geometry.PointCloud, target: o3d.geometry.PointCloud,\n                                            transformation: np.ndarray):\n    \"\"\" Visualizes the result of a point cloud registration, keeping the original color of the source point cloud.\n    Args:\n        source: The source point cloud.\n        target: The target point cloud.\n        transformation: The transformation matrix applied to the source point cloud.\n    \"\"\"\n    source_temp = deepcopy(source)\n    source_temp.transform(transformation)",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "draw_registration_result",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "peekOfCode": "def draw_registration_result(source: o3d.geometry.PointCloud, target: o3d.geometry.PointCloud,\n                             transformation: np.ndarray, source_color: str = \"blue\", target_color: str = \"orange\"):\n    \"\"\" Visualizes the result of a point cloud registration, coloring the source and target point clouds.\n    Args:\n        source: The source point cloud.\n        target: The target point cloud.\n        transformation: The transformation matrix applied to the source point cloud.\n        source_color: The color to apply to the source point cloud. Defaults to \"blue\".\n        target_color: The color to apply to the target point cloud. Defaults to \"orange\".\n    \"\"\"",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "COLORS_ANSI",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "peekOfCode": "COLORS_ANSI = OrderedDict({\n    \"blue\": \"\\033[94m\",\n    \"orange\": \"\\033[93m\",\n    \"green\": \"\\033[92m\",\n    \"red\": \"\\033[91m\",\n    \"purple\": \"\\033[95m\",\n    \"brown\": \"\\033[93m\",  # No exact match, using yellow\n    \"pink\": \"\\033[95m\",\n    \"gray\": \"\\033[90m\",\n    \"olive\": \"\\033[93m\",  # No exact match, using yellow",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "COLORS_MATPLOTLIB",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "peekOfCode": "COLORS_MATPLOTLIB = OrderedDict({\n    'blue': '#1f77b4',\n    'orange': '#ff7f0e',\n    'green': '#2ca02c',\n    'red': '#d62728',\n    'purple': '#9467bd',\n    'brown': '#8c564b',\n    'pink': '#e377c2',\n    'gray': '#7f7f7f',\n    'yellow-green': '#bcbd22',",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "COLORS_MATPLOTLIB_RGB",
        "kind": 5,
        "importPath": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "description": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "peekOfCode": "COLORS_MATPLOTLIB_RGB = OrderedDict({\n    'blue': np.array([31, 119, 180]) / 255.0,\n    'orange': np.array([255, 127,  14]) / 255.0,\n    'green': np.array([44, 160,  44]) / 255.0,\n    'red': np.array([214,  39,  40]) / 255.0,\n    'purple': np.array([148, 103, 189]) / 255.0,\n    'brown': np.array([140,  86,  75]) / 255.0,\n    'pink': np.array([227, 119, 194]) / 255.0,\n    'gray': np.array([127, 127, 127]) / 255.0,\n    'yellow-green': np.array([188, 189,  34]) / 255.0,",
        "detail": "thirdparty.Gaussian-SLAM.src.utils.vis_utils",
        "documentation": {}
    },
    {
        "label": "get_args",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.run_evaluation",
        "description": "thirdparty.Gaussian-SLAM.run_evaluation",
        "peekOfCode": "def get_args():\n    parser = argparse.ArgumentParser(description='Arguments to compute the mesh')\n    parser.add_argument('--checkpoint_path', type=str, help='SLAM checkpoint path', default=\"output/slam/full_experiment/\")\n    parser.add_argument('--config_path', type=str, help='Config path', default=\"\")\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = get_args()\n    if args.config_path == \"\":\n        args.config_path = Path(args.checkpoint_path) / \"config.yaml\"\n    evaluator = Evaluator(Path(args.checkpoint_path), Path(args.config_path))",
        "detail": "thirdparty.Gaussian-SLAM.run_evaluation",
        "documentation": {}
    },
    {
        "label": "get_args",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.run_slam",
        "description": "thirdparty.Gaussian-SLAM.run_slam",
        "peekOfCode": "def get_args():\n    parser = argparse.ArgumentParser(\n        description='Arguments to compute the mesh')\n    parser.add_argument('config_path', type=str,\n                        help='Path to the configuration yaml file')\n    parser.add_argument('--input_path', default=\"\")\n    parser.add_argument('--output_path', default=\"\")\n    parser.add_argument('--track_w_color_loss', type=float)\n    parser.add_argument('--track_alpha_thre', type=float)\n    parser.add_argument('--track_iters', type=int)",
        "detail": "thirdparty.Gaussian-SLAM.run_slam",
        "documentation": {}
    },
    {
        "label": "update_config_with_args",
        "kind": 2,
        "importPath": "thirdparty.Gaussian-SLAM.run_slam",
        "description": "thirdparty.Gaussian-SLAM.run_slam",
        "peekOfCode": "def update_config_with_args(config, args):\n    if args.input_path:\n        config[\"data\"][\"input_path\"] = args.input_path\n    if args.output_path:\n        config[\"data\"][\"output_path\"] = args.output_path\n    if args.track_w_color_loss is not None:\n        config[\"tracking\"][\"w_color_loss\"] = args.track_w_color_loss\n    if args.track_iters is not None:\n        config[\"tracking\"][\"iterations\"] = args.track_iters\n    if args.track_filter_alpha:",
        "detail": "thirdparty.Gaussian-SLAM.run_slam",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "primary_device = \"cuda:0\"\nseed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"dataset_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "seed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"dataset_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "base_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"dataset_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "scene_name = \"dataset_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n)",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "num_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n)",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "depth_scale",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "depth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n)",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "overwrite",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "overwrite = False # Rewrite over dataset if it exists\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n)",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.dataset",
        "description": "thirdparty.SplaTAM.configs.iphone.dataset",
        "peekOfCode": "config = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n)",
        "detail": "thirdparty.SplaTAM.configs.iphone.dataset",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "primary_device = \"cuda:0\"\nseed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "seed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "base_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "scene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "num_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "depth_scale",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "depth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "overwrite",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "overwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "full_res_width",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "full_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "full_res_height",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "full_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "downscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "densify_downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "densify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "map_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "mapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "tracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "mapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "peekOfCode": "config = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "primary_device = \"cuda:0\"\nseed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "seed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "base_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "scene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "num_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "depth_scale",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "depth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "overwrite",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "overwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "full_res_width",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "full_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "full_res_height",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "full_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "downscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "densify_downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "densify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "map_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "mapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "tracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "mapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "description": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "peekOfCode": "config = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.nerfcapture",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "primary_device = \"cuda:0\"\nseed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"splatam_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = True # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "seed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"splatam_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = True # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "base_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"splatam_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = True # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "scene_name = \"splatam_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = True # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "num_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = True # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "depth_scale",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "depth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = True # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "overwrite",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "overwrite = True # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "full_res_width",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "full_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "full_res_height",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "full_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "downscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "densify_downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "densify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "map_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "mapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "tracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "mapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "description": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "peekOfCode": "config = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.online_demo",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "primary_device = \"cuda:0\"\nbase_dir = \"./experiments/iPhone_Captures\"\nscene_name = \"splatam_demo\"\nparams_path = f\"{base_dir}/{scene_name}/params.npz\"\ngroup_name = \"iPhone_Captures\"\nrun_name = f\"{scene_name}_post_splatam_opt\"\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "base_dir = \"./experiments/iPhone_Captures\"\nscene_name = \"splatam_demo\"\nparams_path = f\"{base_dir}/{scene_name}/params.npz\"\ngroup_name = \"iPhone_Captures\"\nrun_name = f\"{scene_name}_post_splatam_opt\"\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "scene_name = \"splatam_demo\"\nparams_path = f\"{base_dir}/{scene_name}/params.npz\"\ngroup_name = \"iPhone_Captures\"\nrun_name = f\"{scene_name}_post_splatam_opt\"\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "params_path",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "params_path = f\"{base_dir}/{scene_name}/params.npz\"\ngroup_name = \"iPhone_Captures\"\nrun_name = f\"{scene_name}_post_splatam_opt\"\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "group_name = \"iPhone_Captures\"\nrun_name = f\"{scene_name}_post_splatam_opt\"\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "run_name = f\"{scene_name}_post_splatam_opt\"\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "full_res_width",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "full_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "full_res_height",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "full_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "downscale_factor = 2.0\ndensify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "densify_downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "densify_downscale_factor = 4.0\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,\n    use_wandb=False,",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,\n    use_wandb=False,\n    wandb=dict(",
        "detail": "thirdparty.SplaTAM.configs.iphone.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "primary_device = \"cuda:0\"\nseed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "seed = 0\nbase_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "base_dir",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "base_dir = \"./experiments/iPhone_Captures\" # Root Directory to Save iPhone Dataset\nscene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "scene_name = \"offline_demo\" # Scan Name\nnum_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "num_frames = 10 # Desired number of frames to capture\ndepth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "depth_scale",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "depth_scale = 10.0 # Depth Scale used when saving depth\noverwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "overwrite",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "overwrite = False # Rewrite over dataset if it exists\nfull_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "full_res_width",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "full_res_width = 1920\nfull_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "full_res_height",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "full_res_height = 1440\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "downscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "densify_downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "densify_downscale_factor = 4.0\nmap_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "map_every = 1\nif num_frames < 25:\n    keyframe_every = int(num_frames//5)\nelse:\n    keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "mapping_window_size = 32\ntracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "tracking_iters = 60\nmapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "mapping_iters = 60\nconfig = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam",
        "peekOfCode": "config = dict(\n    workdir=f\"./{base_dir}/{scene_name}\",\n    run_name=\"SplaTAM_iPhone\",\n    overwrite=overwrite,\n    depth_scale=depth_scale,\n    num_frames=num_frames,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam_viz",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam_viz",
        "peekOfCode": "seed = 0\nconfig = dict(\n    scene_path='./experiments/iPhone_Captures/splatam_demo/params.npz',\n    seed=seed,\n    viz=dict(\n        render_mode='color', # ['color', 'depth' or 'centers']\n        offset_first_viz_cam=True, # Offsets the view camera back by 0.5 units along the view direction (For Final Recon Viz)\n        show_sil=False, # Show Silhouette instead of RGB\n        visualize_cams=True, # Visualize Camera Frustums and Trajectory\n        viz_w=600, viz_h=340,",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam_viz",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.iphone.splatam_viz",
        "description": "thirdparty.SplaTAM.configs.iphone.splatam_viz",
        "peekOfCode": "config = dict(\n    scene_path='./experiments/iPhone_Captures/splatam_demo/params.npz',\n    seed=seed,\n    viz=dict(\n        render_mode='color', # ['color', 'depth' or 'centers']\n        offset_first_viz_cam=True, # Offsets the view camera back by 0.5 units along the view direction (For Final Recon Viz)\n        show_sil=False, # Show Silhouette instead of RGB\n        visualize_cams=True, # Visualize Camera Frustums and Trajectory\n        viz_w=600, viz_h=340,\n        viz_near=0.01, viz_far=100.0,",
        "detail": "thirdparty.SplaTAM.configs.iphone.splatam_viz",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "scenes = [\"room0\", \"room1\", \"room2\",\n          \"office0\", \"office1\", \"office2\",\n          \"office_\", \"office4\"]\nprimary_device = \"cuda:0\"\nseed = 0\nscene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "primary_device = \"cuda:0\"\nseed = 0\nscene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "seed = 0\nscene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "scene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "tracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "group_name = \"Replica_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame\n    eval_every=5, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.replica.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "peekOfCode": "primary_device = \"cuda:0\"\ngroup_name = \"Replica\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)",
        "detail": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "peekOfCode": "group_name = \"Replica\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,",
        "detail": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "peekOfCode": "run_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,\n    use_wandb=False,",
        "detail": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,\n    use_wandb=False,\n    wandb=dict(",
        "detail": "thirdparty.SplaTAM.configs.replica.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "scenes = [\"room0\", \"room1\", \"room2\",\n          \"office0\", \"office1\", \"office2\",\n          \"office_\", \"office4\"]\nprimary_device=\"cuda:0\"\nseed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "seed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "tracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "group_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "description": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=5, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.replica.replica_eval",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "scenes = [\"room0\", \"room1\", \"room2\",\n          \"office0\", \"office1\", \"office2\",\n          \"office_\", \"office4\"]\nprimary_device=\"cuda:0\"\nseed = 0\nscene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "seed = 0\nscene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "scene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "tracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "group_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam",
        "description": "thirdparty.SplaTAM.configs.replica.splatam",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=5, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "scenes = [\"room0\", \"room1\", \"room2\",\n          \"office0\", \"office1\", \"office2\",\n          \"office_\", \"office4\"]\nprimary_device=\"cuda:0\"\nseed = 0\nscene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 10",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "seed = 0\nscene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 10\nmapping_iters = 15\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "scene_name = scenes[0]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 10\nmapping_iters = 15\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 10\nmapping_iters = 15\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 32\ntracking_iters = 10\nmapping_iters = 15\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "mapping_window_size = 32\ntracking_iters = 10\nmapping_iters = 15\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "tracking_iters = 10\nmapping_iters = 15\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "mapping_iters = 15\ngroup_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "group_name = \"Replica\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "description": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=5, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.replica.splatam_s",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "scenes = [\"room_0\", \"room_1\", \"room_2\",\n          \"office_0\", \"office_1\", \"office_2\",\n          \"office_3\", \"office_4\"]\nprimary_device=\"cuda:0\"\nseed = 0\nscene_name = scenes[0]\n# # SLAM\n# use_train_split = True\n# Novel View Synthesis\nuse_train_split = False",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "seed = 0\nscene_name = scenes[0]\n# # SLAM\n# use_train_split = True\n# Novel View Synthesis\nuse_train_split = False\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "scene_name = scenes[0]\n# # SLAM\n# use_train_split = True\n# Novel View Synthesis\nuse_train_split = False\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "use_train_split",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "use_train_split = False\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "tracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "group_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=5, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "scenes = [\"room_0\", \"room_1\", \"room_2\",\n          \"office_0\", \"office_1\", \"office_2\",\n          \"office_3\", \"office_4\"]\nprimary_device=\"cuda:0\"\nseed = 0\nscene_name = scenes[0]\n# SplaTAM\nuse_train_split = True\n# # Novel View Synthesis\n# use_train_split = False",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "seed = 0\nscene_name = scenes[0]\n# SplaTAM\nuse_train_split = True\n# # Novel View Synthesis\n# use_train_split = False\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "scene_name = scenes[0]\n# SplaTAM\nuse_train_split = True\n# # Novel View Synthesis\n# use_train_split = False\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "use_train_split",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "use_train_split = True\n# # Novel View Synthesis\n# use_train_split = False\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "tracking_iters = 40\nmapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "group_name = \"Replica_V2\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "description": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=5, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.replica_v2.splatam",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"scene0000_00\", \"scene0059_00\", \"scene0106_00\", \n          \"scene0169_00\", \"scene0181_00\", \"scene0207_00\"]\nseed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "scenes = [\"scene0000_00\", \"scene0059_00\", \"scene0106_00\", \n          \"scene0169_00\", \"scene0181_00\", \"scene0207_00\"]\nseed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "seed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "mapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "tracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "mapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "scene_radius_depth_ratio",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "scene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "group_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "run_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "description": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=500, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.scannet.scannet_eval",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"scene0000_00\", \"scene0059_00\", \"scene0106_00\", \n          \"scene0169_00\", \"scene0181_00\", \"scene0207_00\"]\nseed = int(6)\nscene_name = scenes[int(6)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "scenes = [\"scene0000_00\", \"scene0059_00\", \"scene0106_00\", \n          \"scene0169_00\", \"scene0181_00\", \"scene0207_00\"]\nseed = int(6)\nscene_name = scenes[int(6)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "seed = int(6)\nscene_name = scenes[int(6)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "scene_name = scenes[int(6)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "mapping_window_size = 10\ntracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "tracking_iters = 100\nmapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "mapping_iters = 30\nscene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "scene_radius_depth_ratio",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "scene_radius_depth_ratio = 3\ngroup_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "group_name = \"ScanNet\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "run_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannet.splatam",
        "description": "thirdparty.SplaTAM.configs.scannet.splatam",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=500, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.scannet.splatam",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# # Train Split Eval\n# use_train_split = True\n# Novel View Synthesis Eval\nuse_train_split = False\nif use_train_split:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "scenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# # Train Split Eval\n# use_train_split = True\n# Novel View Synthesis Eval\nuse_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "seed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# # Train Split Eval\n# use_train_split = True\n# Novel View Synthesis Eval\nuse_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "os.environ[\"SCENE\"]",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "os.environ[\"SCENE\"] = \"0\"\n# # Train Split Eval\n# use_train_split = True\n# Novel View Synthesis Eval\nuse_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "use_train_split",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "num_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "tracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "group_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "description": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "peekOfCode": "config = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "scenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "seed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "os.environ[\"SCENE\"]",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "os.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nfull_res_width = 1168",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "use_train_split",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "use_train_split = True\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nfull_res_width = 1168\nfull_res_height = 1752\ndownscale_factor = 2.0",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nfull_res_width = 1168\nfull_res_height = 1752\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "num_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nfull_res_width = 1168\nfull_res_height = 1752\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "full_res_width",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "full_res_width = 1168\nfull_res_height = 1752\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "full_res_height",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "full_res_height = 1752\ndownscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "downscale_factor = 2.0\ndensify_downscale_factor = 4.0\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "densify_downscale_factor",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "densify_downscale_factor = 4.0\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "tracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "group_name = \"ScanNet++_3DGS\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "description": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame\n    eval_every=5, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "scenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "seed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "os.environ[\"SCENE\"]",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "os.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "use_train_split",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "use_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "num_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "tracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "group_name = \"ScanNet++\"\nrun_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "run_name = \"Post_SplaTAM_Opt\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,\n    use_wandb=True,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "description": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=0,\n    primary_device=primary_device,\n    mean_sq_dist_method=\"projective\", # [\"projective\", \"knn\"] (Type of Mean Squared Distance Calculation for Scale of Gaussians)\n    gaussian_distribution=\"isotropic\", # [\"isotropic\", \"anisotropic\"] (Isotropic -> Spherical Covariance, Anisotropic -> Ellipsoidal Covariance)\n    report_iter_progress=False,\n    use_wandb=True,\n    wandb=dict(",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "scenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "seed = 0\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "use_train_split",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "use_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "num_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "tracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "group_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "description": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "peekOfCode": "config = dict(\n    scene_path=p_join(f\"./experiments/{group_name}\", run_name, 'params.npz'),\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.scannetpp_eval",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "scenes = [\"8b5caf3398\", \"b20a261fdf\"]\nseed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "seed = 0\n# Export SCENE env variable before running\nos.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "os.environ[\"SCENE\"]",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "os.environ[\"SCENE\"] = \"0\"\n# Train Split Eval\nuse_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "use_train_split",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "use_train_split = True\n# # Novel View Synthesis Eval\n# use_train_split = False\nif use_train_split:\n    scene_num_frames = [-1, 360]\nelse:\n    scene_num_frames = [-1, -1]\nscene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE\"])]\nnum_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "num_frames",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "num_frames = scene_num_frames[int(os.environ[\"SCENE\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "mapping_window_size = 24\ntracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "tracking_iters = 200\nmapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "mapping_iters = 60\ngroup_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "group_name = \"ScanNet++\"\nrun_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "run_name = f\"{scene_name}_{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "description": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=5, # Report Global Progress every nth frame\n    eval_every=1, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.scannetpp.splatam",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"freiburg1_desk\", \"freiburg1_desk2\", \"freiburg1_room\", \"freiburg2_xyz\", \"freiburg3_long_office_household\"]\nseed = int(0)\nscene_name = scenes[int(0)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "scenes = [\"freiburg1_desk\", \"freiburg1_desk2\", \"freiburg1_room\", \"freiburg2_xyz\", \"freiburg3_long_office_household\"]\nseed = int(0)\nscene_name = scenes[int(0)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "seed = int(0)\nscene_name = scenes[int(0)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "scene_name = scenes[int(0)]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "mapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "tracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "mapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "scene_radius_depth_ratio",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "scene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "group_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "run_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.splatam",
        "description": "thirdparty.SplaTAM.configs.tum.splatam",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=500, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.tum.splatam",
        "documentation": {}
    },
    {
        "label": "primary_device",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "primary_device = \"cuda:0\"\nscenes = [\"freiburg1_desk\", \"freiburg1_desk2\", \"freiburg1_room\", \"freiburg2_xyz\", \"freiburg3_long_office_household\"]\nseed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "scenes",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "scenes = [\"freiburg1_desk\", \"freiburg1_desk2\", \"freiburg1_room\", \"freiburg2_xyz\", \"freiburg3_long_office_household\"]\nseed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "seed",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "seed = int(os.environ[\"SEED\"])\nscene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "scene_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "scene_name = scenes[int(os.environ[\"SCENE_NUM\"])]\nmap_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "map_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "map_every = 1\nkeyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "keyframe_every",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "keyframe_every = 5\nmapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "mapping_window_size",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "mapping_window_size = 20\ntracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "tracking_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "tracking_iters = 200\nmapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "mapping_iters",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "mapping_iters = 30\nscene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "scene_radius_depth_ratio",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "scene_radius_depth_ratio = 2\ngroup_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "group_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "group_name = \"TUM\"\nrun_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "run_name",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "run_name = f\"{scene_name}_seed{seed}\"\nconfig = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "description": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "peekOfCode": "config = dict(\n    workdir=f\"./experiments/{group_name}\",\n    run_name=run_name,\n    seed=seed,\n    primary_device=primary_device,\n    map_every=map_every, # Mapping every nth frame\n    keyframe_every=keyframe_every, # Keyframe every nth frame\n    mapping_window_size=mapping_window_size, # Mapping window size\n    report_global_progress_every=500, # Report Global Progress every nth frame\n    eval_every=500, # Evaluate every nth frame (at end of SLAM)",
        "detail": "thirdparty.SplaTAM.configs.tum.tum_eval",
        "documentation": {}
    },
    {
        "label": "Ai2thorDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.ai2thor",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.ai2thor",
        "peekOfCode": "class Ai2thorDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: Optional[int] = 968,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.ai2thor",
        "documentation": {}
    },
    {
        "label": "AzureKinectDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.azure",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.azure",
        "peekOfCode": "class AzureKinectDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: Optional[int] = 480,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.azure",
        "documentation": {}
    },
    {
        "label": "GradSLAMDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "peekOfCode": "class GradSLAMDataset(torch.utils.data.Dataset):\n    def __init__(\n        self,\n        config_dict,\n        stride: Optional[int] = 1,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: int = 480,\n        desired_width: int = 640,\n        channels_first: bool = False,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "documentation": {}
    },
    {
        "label": "to_scalar",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "peekOfCode": "def to_scalar(inp: Union[np.ndarray, torch.Tensor, float]) -> Union[int, float]:\n    \"\"\"\n    Convert the input to a scalar\n    \"\"\"\n    if isinstance(inp, float):\n        return inp\n    if isinstance(inp, np.ndarray):\n        assert inp.size == 1\n        return inp.item()\n    if isinstance(inp, torch.Tensor):",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "documentation": {}
    },
    {
        "label": "as_intrinsics_matrix",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "peekOfCode": "def as_intrinsics_matrix(intrinsics):\n    \"\"\"\n    Get matrix representation of intrinsics.\n    \"\"\"\n    K = np.eye(3)\n    K[0, 0] = intrinsics[0]\n    K[1, 1] = intrinsics[1]\n    K[0, 2] = intrinsics[2]\n    K[1, 2] = intrinsics[3]\n    return K",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "documentation": {}
    },
    {
        "label": "from_intrinsics_matrix",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "peekOfCode": "def from_intrinsics_matrix(K):\n    \"\"\"\n    Get fx, fy, cx, cy from the intrinsics matrix\n    return 4 scalars\n    \"\"\"\n    fx = to_scalar(K[0, 0])\n    fy = to_scalar(K[1, 1])\n    cx = to_scalar(K[0, 2])\n    cy = to_scalar(K[1, 2])\n    return fx, fy, cx, cy",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "documentation": {}
    },
    {
        "label": "readEXR_onlydepth",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "peekOfCode": "def readEXR_onlydepth(filename):\n    \"\"\"\n    Read depth data from EXR image file.\n    Args:\n        filename (str): File path.\n    Returns:\n        Y (numpy.array): Depth buffer in float32 format.\n    \"\"\"\n    # move the import here since only CoFusion needs these package\n    # sometimes installation of openexr is hard, you can run all other datasets",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.basedataset",
        "documentation": {}
    },
    {
        "label": "load_dataset_config",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "peekOfCode": "def load_dataset_config(path, default_path=None):\n    \"\"\"\n    Loads config file.\n    Args:\n        path (str): path to config file.\n        default_path (str, optional): whether to use default path. Defaults to None.\n    Returns:\n        cfg (dict): config dict.\n    \"\"\"\n    # load configuration from file itself",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "documentation": {}
    },
    {
        "label": "update_recursive",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "peekOfCode": "def update_recursive(dict1, dict2):\n    \"\"\"\n    Update two config dictionaries recursively.\n    Args:\n        dict1 (dict): first dictionary to be updated.\n        dict2 (dict): second dictionary which entries should be used.\n    \"\"\"\n    for k, v in dict2.items():\n        if k not in dict1:\n            dict1[k] = dict()",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "documentation": {}
    },
    {
        "label": "common_dataset_to_batch",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "peekOfCode": "def common_dataset_to_batch(dataset):\n    colors, depths, poses = [], [], []\n    intrinsics, embeddings = None, None\n    for idx in range(len(dataset)):\n        _color, _depth, intrinsics, _pose, _embedding = dataset[idx]\n        colors.append(_color)\n        depths.append(_depth)\n        poses.append(_pose)\n        if _embedding is not None:\n            if embeddings is None:",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.dataconfig",
        "documentation": {}
    },
    {
        "label": "normalize_image",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "peekOfCode": "def normalize_image(rgb: Union[torch.Tensor, np.ndarray]):\n    r\"\"\"Normalizes RGB image values from :math:`[0, 255]` range to :math:`[0, 1]` range.\n    Args:\n        rgb (torch.Tensor or numpy.ndarray): RGB image in range :math:`[0, 255]`\n    Returns:\n        torch.Tensor or numpy.ndarray: Normalized RGB image in range :math:`[0, 1]`\n    Shape:\n        - rgb: :math:`(*)` (any shape)\n        - Output: Same shape as input :math:`(*)`\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "documentation": {}
    },
    {
        "label": "channels_first",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "peekOfCode": "def channels_first(rgb: Union[torch.Tensor, np.ndarray]):\n    r\"\"\"Converts from channels last representation :math:`(*, H, W, C)` to channels first representation\n    :math:`(*, C, H, W)`\n    Args:\n        rgb (torch.Tensor or numpy.ndarray): :math:`(*, H, W, C)` ordering `(*, height, width, channels)`\n    Returns:\n        torch.Tensor or numpy.ndarray: :math:`(*, C, H, W)` ordering\n    Shape:\n        - rgb: :math:`(*, H, W, C)`\n        - Output: :math:`(*, C, H, W)`",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "documentation": {}
    },
    {
        "label": "scale_intrinsics",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "peekOfCode": "def scale_intrinsics(\n    intrinsics: Union[np.ndarray, torch.Tensor],\n    h_ratio: Union[float, int],\n    w_ratio: Union[float, int],\n):\n    r\"\"\"Scales the intrinsics appropriately for resized frames where\n    :math:`h_\\text{ratio} = h_\\text{new} / h_\\text{old}` and :math:`w_\\text{ratio} = w_\\text{new} / w_\\text{old}`\n    Args:\n        intrinsics (numpy.ndarray or torch.Tensor): Intrinsics matrix of original frame\n        h_ratio (float or int): Ratio of new frame's height to old frame's height",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "documentation": {}
    },
    {
        "label": "pointquaternion_to_homogeneous",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "peekOfCode": "def pointquaternion_to_homogeneous(\n    pointquaternions: Union[np.ndarray, torch.Tensor], eps: float = 1e-12\n):\n    r\"\"\"Converts 3D point and unit quaternions :math:`(t_x, t_y, t_z, q_x, q_y, q_z, q_w)` to\n    homogeneous transformations [R | t] where :math:`R` denotes the :math:`(3, 3)` rotation matrix and :math:`T`\n    denotes the :math:`(3, 1)` translation matrix:\n    .. math::\n        \\left[\\begin{array}{@{}c:c@{}}\n        R & T \\\\ \\hdashline\n        \\begin{array}{@{}ccc@{}}",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "documentation": {}
    },
    {
        "label": "poses_to_transforms",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "peekOfCode": "def poses_to_transforms(poses: Union[np.ndarray, List[np.ndarray]]):\n    r\"\"\"Converts poses to transformations w.r.t. the first frame in the sequence having identity pose\n    Args:\n        poses (numpy.ndarray or list of numpy.ndarray): Sequence of poses in `numpy.ndarray` format.\n    Returns:\n        numpy.ndarray or list of numpy.ndarray: Sequence of frame to frame transformations where initial\n            frame is transformed to have identity pose.\n    Shape:\n        - poses: Could be `numpy.ndarray` of shape :math:`(N, 4, 4)`, or list of `numpy.ndarray`s of shape\n          :math:`(4, 4)`",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "documentation": {}
    },
    {
        "label": "create_label_image",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "peekOfCode": "def create_label_image(prediction: np.ndarray, color_palette: OrderedDict):\n    r\"\"\"Creates a label image, given a network prediction (each pixel contains class index) and a color palette.\n    Args:\n        prediction (numpy.ndarray): Predicted image where each pixel contains an integer,\n            corresponding to its class label.\n        color_palette (OrderedDict): Contains RGB colors (`uint8`) for each class.\n    Returns:\n        numpy.ndarray: Label image with the given color palette\n    Shape:\n        - prediction: :math:`(H, W)`",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "peekOfCode": "__all__ = [\n    \"normalize_image\",\n    \"channels_first\",\n    \"scale_intrinsics\",\n    \"pointquaternion_to_homogeneous\",\n    \"poses_to_transforms\",\n    \"create_label_image\",\n]\ndef normalize_image(rgb: Union[torch.Tensor, np.ndarray]):\n    r\"\"\"Normalizes RGB image values from :math:`[0, 255]` range to :math:`[0, 1]` range.",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.datautils",
        "documentation": {}
    },
    {
        "label": "homogenize_points",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def homogenize_points(pts: torch.Tensor):\n    r\"\"\"Convert a set of points to homogeneous coordinates.\n    Args:\n        pts (torch.Tensor): Tensor containing points to be homogenized.\n    Shape:\n        pts: N x 3 (N-points, and (usually) 3 dimensions)\n        (returns): N x 4\n    Returns:\n        (torch.Tensor): Homogeneous coordinates of pts\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "unhomogenize_points",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def unhomogenize_points(pts: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n    r\"\"\"Convert a set of points from homogeneous coordinates to Euclidean\n    coordinates.\n    This is usually done by taking each point (x, y, z, w) and dividing it by\n    the last coordinate (w).\n    Args:\n        pts (torch.Tensor): Tensor containing points to be unhomogenized.\n    Shape:\n        pts: N x 4 (N-points, and usually 4 dimensions per point)\n        (returns): N x 3",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "quaternion_to_axisangle",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def quaternion_to_axisangle(quat: torch.Tensor) -> torch.Tensor:\n    r\"\"\"Converts a quaternion to an axis angle.\n    Args:\n        quat (torch.Tensor): Quaternion (qx, qy, qz, qw) (shape:\n            :math:`* \\times 4`)\n    Return:\n        axisangle (torch.Tensor): Axis-angle representation. (shape:\n            :math:`* \\times 3`)\n    \"\"\"\n    if not torch.is_tensor(quat):",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "normalize_quaternion",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def normalize_quaternion(quaternion: torch.Tensor, eps: float = 1e-12):\n    r\"\"\"Normalize a quaternion. The quaternion should be in (x, y, z, w)\n    format.\n    Args:\n        quaternion (torch.Tensor): Quaternion to be normalized\n            (shape: (*, 4))\n        eps (Optional[bool]): Small value, to avoid division by zero\n            (default: 1e-12).\n    Returns:\n        (torch.Tensor): Normalized quaternion (shape: (*, 4))",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "quaternion_to_rotation_matrix",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def quaternion_to_rotation_matrix(quaternion: torch.Tensor) -> torch.Tensor:\n    r\"\"\"Converts a quaternion to a rotation matrix. The quaternion should\n    be in (x, y, z, w) format.\n    Args:\n        quaternion (torch.Tensor): Quaternion to be converted (shape: (*, 4))\n    Return:\n        (torch.Tensor): Rotation matrix (shape: (*, 3, 3))\n    \"\"\"\n    if not quaternion.shape[-1] == 4:\n        raise ValueError(",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "inverse_transfom_3d",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def inverse_transfom_3d(trans: torch.Tensor):\n    r\"\"\"Inverts a 4 x 4 3D transformation matrix.\n    Args:\n        trans (torch.Tensor): transformation matrix (shape:\n            :math:`* \\times 4 \\times 4`)\n    Returns:\n        trans_inv (torch.Tensor): inverse of `trans`\n    \"\"\"\n    if not torch.is_tensor(trans):\n        raise TypeError(",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "compose_transforms_3d",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def compose_transforms_3d(trans1: torch.Tensor, trans2: torch.Tensor) -> torch.Tensor:\n    r\"\"\"Compose two homogeneous 3D transforms.\n    Args:\n        trans1 (torch.Tensor): first transformation (shape:\n            :math:`* \\times 4 \\times 4`)\n        trans2 (torch.Tensor): second transformation (shape:\n            :math:`* \\times 4 \\times 4`)\n    Returns:\n        trans_cat (torch.Tensor): composed transformation matrix.\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "transform_pts_3d",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def transform_pts_3d(pts_b: torch.Tensor, t_ab: torch.Tensor) -> torch.Tensor:\n    r\"\"\"Transforms a set of points `pts_b` from frame `b` to frame `a`, given an SE(3)\n    transformation matrix `t_ab`\n    Args:\n        pts_b (torch.Tensor): points to be transformed (shape: :math:`N \\times 3`)\n        t_ab (torch.Tensor): homogenous 3D transformation matrix (shape: :math:`4 \\times 4`)\n    Returns:\n        pts_a (torch.Tensor): `pts_b` transformed to the coordinate frame `a`\n            (shape: :math:`N \\times 3`)\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "transform_pts_nd_KF",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def transform_pts_nd_KF(pts, tform):\n    r\"\"\"Applies a transform to a set of points.\n    Args:\n        pts (torch.Tensor): Points to be transformed (shape: B x N x D)\n            (N points, D dimensions per point; B -> batchsize)\n        tform (torch.Tensor): Transformation to be applied\n            (shape: B x D+1 x D+1)\n    Returns:\n        (torch.Tensor): Transformed points (B, N, D)\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "relative_transform_3d",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def relative_transform_3d(\n    trans_01: torch.Tensor, trans_02: torch.Tensor\n) -> torch.Tensor:\n    r\"\"\"Given two 3D homogeneous transforms `trans_01` and `trans_02`\n    in the global frame '0', this function returns a relative\n    transform `trans_12`.\n    Args:\n        trans_01 (torch.Tensor): first transformation (shape:\n            :math:`* \\times 4 \\times 4`)\n        trans_02 (torch.Tensor): second transformation (shape:",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "relative_transformation",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def relative_transformation(\n    trans_01: torch.Tensor, trans_02: torch.Tensor, orthogonal_rotations: bool = False\n) -> torch.Tensor:\n    r\"\"\"Function that computes the relative homogenous transformation from a\n    reference transformation :math:`T_1^{0} = \\begin{bmatrix} R_1 & t_1 \\\\\n    \\mathbf{0} & 1 \\end{bmatrix}` to destination :math:`T_2^{0} =\n    \\begin{bmatrix} R_2 & t_2 \\\\ \\mathbf{0} & 1 \\end{bmatrix}`.\n    .. note:: Works with imperfect (non-orthogonal) rotation matrices as well.\n    The relative transformation is computed as follows:\n    .. math::",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "normalize_pixel_coords",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def normalize_pixel_coords(\n    pixel_coords: torch.Tensor, height: int, width: int\n) -> torch.Tensor:\n    r\"\"\"Normalizes pixel coordinates, so that each dimension (x, y) is now\n    in the range [-1, 1].\n    x coordinates get mapped from [0, height-1] to [-1, 1]\n    y coordinates get mapped from [0, width-1] to [-1, 1]\n    Args:\n        pixel_coords (torch.Tensor): pixel coordinates of a grid\n            (shape: :math:`* \\times 2`)",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "unnormalize_pixel_coords",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def unnormalize_pixel_coords(\n    pixel_coords_norm: torch.Tensor, height: int, width: int\n) -> torch.Tensor:\n    r\"\"\"Unnormalizes pixel coordinates from the range [-1, 1], [-1, 1]\n    to [0, `height`-1] and [0, `width`-1] for x and y respectively.\n    Args:\n        pixel_coords_norm (torch.Tensor): Normalized pixel coordinates\n            (shape: :math:`* \\times 2`)\n        height (int): Height of the image\n        width (int): Width of the image",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "create_meshgrid",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def create_meshgrid(\n    height: int, width: int, normalized_coords: Optional[bool] = True\n) -> torch.Tensor:\n    r\"\"\"Generates a coordinate grid for an image.\n    When `normalized_coords` is set to True, the grid is normalized to\n    be in the range [-1, 1] (to be consistent with the pytorch function\n    `grid_sample`.)\n    https://kornia.readthedocs.io/en/latest/utils.html#kornia.utils.create_meshgrid\n    Args:\n        height (int): Height of the image (number of rows).",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "cam2pixel",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def cam2pixel(\n    cam_coords_src: torch.Tensor,\n    dst_proj_src: torch.Tensor,\n    eps: Optional[float] = 1e-6,\n) -> torch.Tensor:\n    r\"\"\"Transforms coordinates from the camera frame to the pixel frame.\n    # based on\n    # https://github.com/ClementPinard/SfmLearner-Pytorch/blob/master/inverse_warp.py#L43\n    Args:\n        cam_coords_src (torch.Tensor): pixel coordinates (defined in the",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "pixel2cam",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def pixel2cam(\n    depth: torch.Tensor, intrinsics_inv: torch.Tensor, pixel_coords: torch.Tensor\n) -> torch.Tensor:\n    r\"\"\"Transforms points from the pixel frame to the camera frame.\n    Args:\n        depth (torch.Tensor): the source depth maps (shape:\n            :math:`H \\times W`)\n        intrinsics_inv (torch.Tensor): the inverse of the intrinsics\n            (shape: :math:`4 \\times 4`)\n        pixel_coords (torch.Tensor): the grid of homogeneous camera",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "cam2pixel_KF",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def cam2pixel_KF(\n    cam_coords_src: torch.Tensor, P: torch.Tensor, eps: Optional[float] = 1e-6\n) -> torch.Tensor:\n    r\"\"\"Projects camera coordinates onto the image.\n    Args:\n        cam_coords_src (torch.Tensor): camera coordinates (defined in the\n            frame of the first camera). (shape: :math:`H \\times W \\times 3`)\n        P (torch.Tensor): projection matrix between the reference and the\n            non-reference camera frame. (shape: :math:`4 \\times 4`)\n    Returns:",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "transform_pointcloud",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def transform_pointcloud(pointcloud: torch.Tensor, transform: torch.Tensor):\n    r\"\"\"Applies a rigid-body transformation to a pointcloud.\n    Args:\n        pointcloud (torch.Tensor): Pointcloud to be transformed\n                                   (shape: numpts x 3)\n        transform (torch.Tensor): An SE(3) rigid-body transform matrix\n                                  (shape: 4 x 4)\n    Returns:\n        transformed_pointcloud (torch.Tensor): Rotated and translated cloud\n                                               (shape: numpts x 3)",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "transform_normals",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "peekOfCode": "def transform_normals(normals: torch.Tensor, transform: torch.Tensor):\n    r\"\"\"Applies a rotation to a tensor containing point normals.\n    Args:\n        normals (torch.Tensor): Normal vectors (shape: numpoints x 3)\n    \"\"\"\n    if not torch.is_tensor(normals):\n        raise TypeError(\"normals should be tensor, but was %r instead\" % type(normals))\n    if not torch.is_tensor(transform):\n        raise TypeError(\n            \"transform should be tensor, but was %r instead\" % type(transform)",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.geometryutils",
        "documentation": {}
    },
    {
        "label": "ICLDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.icl",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.icl",
        "peekOfCode": "class ICLDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        config_dict: Dict,\n        basedir: Union[Path, str],\n        sequence: Union[Path, str],\n        stride: Optional[int] = 1,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: Optional[int] = 480,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.icl",
        "documentation": {}
    },
    {
        "label": "NeRFCaptureDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.nerfcapture",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.nerfcapture",
        "peekOfCode": "class NeRFCaptureDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: Optional[int] = 1440,\n        desired_width: Optional[int] = 1920,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.nerfcapture",
        "documentation": {}
    },
    {
        "label": "create_filepath_index_mapping",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.nerfcapture",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.nerfcapture",
        "peekOfCode": "def create_filepath_index_mapping(frames):\n    return {frame[\"file_path\"]: index for index, frame in enumerate(frames)}\nclass NeRFCaptureDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.nerfcapture",
        "documentation": {}
    },
    {
        "label": "RealsenseDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.realsense",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.realsense",
        "peekOfCode": "class RealsenseDataset(GradSLAMDataset):\n    \"\"\"\n    Dataset class to process depth images captured by realsense camera on the tabletop manipulator\n    \"\"\"\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.realsense",
        "documentation": {}
    },
    {
        "label": "Record3DDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.record3d",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.record3d",
        "peekOfCode": "class Record3DDataset(GradSLAMDataset):\n    \"\"\"\n    Dataset class to read in saved files from the structure created by our\n    `save_record3d_stream.py` script\n    \"\"\"\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.record3d",
        "documentation": {}
    },
    {
        "label": "ReplicaDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.replica",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.replica",
        "peekOfCode": "class ReplicaDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: Optional[int] = 480,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.replica",
        "documentation": {}
    },
    {
        "label": "ReplicaV2Dataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.replica",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.replica",
        "peekOfCode": "class ReplicaV2Dataset(GradSLAMDataset):\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,\n        use_train_split: Optional[bool] = True,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.replica",
        "documentation": {}
    },
    {
        "label": "ScannetDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannet",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannet",
        "peekOfCode": "class ScannetDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: Optional[int] = 968,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannet",
        "documentation": {}
    },
    {
        "label": "ScannetPPDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannetpp",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannetpp",
        "peekOfCode": "class ScannetPPDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        basedir,\n        sequence,\n        ignore_bad: Optional[bool] = False,\n        use_train_split: Optional[bool] = True,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannetpp",
        "documentation": {}
    },
    {
        "label": "create_filepath_index_mapping",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannetpp",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannetpp",
        "peekOfCode": "def create_filepath_index_mapping(frames):\n    return {frame[\"file_path\"]: index for index, frame in enumerate(frames)}\nclass ScannetPPDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        basedir,\n        sequence,\n        ignore_bad: Optional[bool] = False,\n        use_train_split: Optional[bool] = True,\n        stride: Optional[int] = None,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.scannetpp",
        "documentation": {}
    },
    {
        "label": "TUMDataset",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.datasets.gradslam_datasets.tum",
        "description": "thirdparty.SplaTAM.datasets.gradslam_datasets.tum",
        "peekOfCode": "class TUMDataset(GradSLAMDataset):\n    def __init__(\n        self,\n        config_dict,\n        basedir,\n        sequence,\n        stride: Optional[int] = None,\n        start: Optional[int] = 0,\n        end: Optional[int] = -1,\n        desired_height: Optional[int] = 480,",
        "detail": "thirdparty.SplaTAM.datasets.gradslam_datasets.tum",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "description": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "peekOfCode": "def get_dataset(config_dict, basedir, sequence, **kwargs):\n    if config_dict[\"dataset_name\"].lower() in [\"icl\"]:\n        return ICLDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replica\"]:\n        return ReplicaDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replicav2\"]:\n        return ReplicaV2Dataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"azure\", \"azurekinect\"]:\n        return AzureKinectDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"scannet\"]:",
        "detail": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "load_scene_data",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "description": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "peekOfCode": "def load_scene_data(scene_path):\n    params = dict(np.load(scene_path, allow_pickle=True))\n    params = {k: torch.tensor(params[k]).cuda().float().requires_grad_(True) for k in params.keys()}\n    return params\nif __name__==\"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"experiment\", type=str, help=\"Path to experiment file\")\n    args = parser.parse_args()\n    experiment = SourceFileLoader(\n        os.path.basename(args.experiment), args.experiment",
        "detail": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "description": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nprint(\"System Paths:\")\nfor p in sys.path:\n    print(p)\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport torch\nfrom tqdm import tqdm",
        "detail": "thirdparty.SplaTAM.scripts.eval_novel_view",
        "documentation": {}
    },
    {
        "label": "rgb_to_spherical_harmonic",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.export_ply",
        "description": "thirdparty.SplaTAM.scripts.export_ply",
        "peekOfCode": "def rgb_to_spherical_harmonic(rgb):\n    return (rgb-0.5) / C0\ndef spherical_harmonic_to_rgb(sh):\n    return sh*C0 + 0.5\ndef save_ply(path, means, scales, rotations, rgbs, opacities, normals=None):\n    if normals is None:\n        normals = np.zeros_like(means)\n    colors = rgb_to_spherical_harmonic(rgbs)\n    if scales.shape[1] == 1:\n        scales = np.tile(scales, (1, 3))",
        "detail": "thirdparty.SplaTAM.scripts.export_ply",
        "documentation": {}
    },
    {
        "label": "spherical_harmonic_to_rgb",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.export_ply",
        "description": "thirdparty.SplaTAM.scripts.export_ply",
        "peekOfCode": "def spherical_harmonic_to_rgb(sh):\n    return sh*C0 + 0.5\ndef save_ply(path, means, scales, rotations, rgbs, opacities, normals=None):\n    if normals is None:\n        normals = np.zeros_like(means)\n    colors = rgb_to_spherical_harmonic(rgbs)\n    if scales.shape[1] == 1:\n        scales = np.tile(scales, (1, 3))\n    attrs = ['x', 'y', 'z',\n             'nx', 'ny', 'nz',",
        "detail": "thirdparty.SplaTAM.scripts.export_ply",
        "documentation": {}
    },
    {
        "label": "save_ply",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.export_ply",
        "description": "thirdparty.SplaTAM.scripts.export_ply",
        "peekOfCode": "def save_ply(path, means, scales, rotations, rgbs, opacities, normals=None):\n    if normals is None:\n        normals = np.zeros_like(means)\n    colors = rgb_to_spherical_harmonic(rgbs)\n    if scales.shape[1] == 1:\n        scales = np.tile(scales, (1, 3))\n    attrs = ['x', 'y', 'z',\n             'nx', 'ny', 'nz',\n             'f_dc_0', 'f_dc_1', 'f_dc_2',\n             'opacity',",
        "detail": "thirdparty.SplaTAM.scripts.export_ply",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.export_ply",
        "description": "thirdparty.SplaTAM.scripts.export_ply",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"config\", type=str, help=\"Path to config file.\")\n    return parser.parse_args()\nif __name__ == \"__main__\":\n    args = parse_args()\n    # Load SplaTAM config\n    experiment = SourceFileLoader(os.path.basename(args.config), args.config).load_module()\n    config = experiment.config\n    work_path = config['workdir']",
        "detail": "thirdparty.SplaTAM.scripts.export_ply",
        "documentation": {}
    },
    {
        "label": "C0",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.export_ply",
        "description": "thirdparty.SplaTAM.scripts.export_ply",
        "peekOfCode": "C0 = 0.28209479177387814\ndef rgb_to_spherical_harmonic(rgb):\n    return (rgb-0.5) / C0\ndef spherical_harmonic_to_rgb(sh):\n    return sh*C0 + 0.5\ndef save_ply(path, means, scales, rotations, rgbs, opacities, normals=None):\n    if normals is None:\n        normals = np.zeros_like(means)\n    colors = rgb_to_spherical_harmonic(rgbs)\n    if scales.shape[1] == 1:",
        "detail": "thirdparty.SplaTAM.scripts.export_ply",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def get_dataset(config_dict, basedir, sequence, **kwargs):\n    if config_dict[\"dataset_name\"].lower() in [\"icl\"]:\n        return ICLDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replica\"]:\n        return ReplicaDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replicav2\"]:\n        return ReplicaV2Dataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"azure\", \"azurekinect\"]:\n        return AzureKinectDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"scannet\"]:",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "get_pointcloud",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def get_pointcloud(color, depth, intrinsics, w2c, transform_pts=True, \n                   mask=None, compute_mean_sq_dist=False, mean_sq_dist_method=\"projective\"):\n    width, height = color.shape[2], color.shape[1]\n    CX = intrinsics[0][2]\n    CY = intrinsics[1][2]\n    FX = intrinsics[0][0]\n    FY = intrinsics[1][1]\n    # Compute indices of pixels\n    x_grid, y_grid = torch.meshgrid(torch.arange(width).cuda().float(), \n                                    torch.arange(height).cuda().float(),",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "initialize_params",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def initialize_params(init_pt_cld, num_frames, mean3_sq_dist, gaussian_distribution):\n    num_pts = init_pt_cld.shape[0]\n    means3D = init_pt_cld[:, :3] # [num_gaussians, 3]\n    unnorm_rots = np.tile([1, 0, 0, 0], (num_pts, 1)) # [num_gaussians, 4]\n    logit_opacities = torch.zeros((num_pts, 1), dtype=torch.float, device=\"cuda\")\n    if gaussian_distribution == \"isotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 1))\n    elif gaussian_distribution == \"anisotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 3))\n    else:",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "initialize_optimizer",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def initialize_optimizer(params, lrs_dict):\n    lrs = lrs_dict\n    param_groups = [{'params': [v], 'name': k, 'lr': lrs[k]} for k, v in params.items()]\n    return torch.optim.Adam(param_groups, lr=0.0, eps=1e-15)\ndef initialize_first_timestep(dataset, num_frames, lrs_dict, mean_sq_dist_method, gaussian_distribution):\n    # Get RGB-D Data & Camera Parameters\n    color, depth, intrinsics, pose = dataset[0]\n    # Process RGB-D Data\n    color = color.permute(2, 0, 1) / 255 # (H, W, C) -> (C, H, W)\n    depth = depth.permute(2, 0, 1) # (H, W, C) -> (C, H, W)",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "initialize_first_timestep",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def initialize_first_timestep(dataset, num_frames, lrs_dict, mean_sq_dist_method, gaussian_distribution):\n    # Get RGB-D Data & Camera Parameters\n    color, depth, intrinsics, pose = dataset[0]\n    # Process RGB-D Data\n    color = color.permute(2, 0, 1) / 255 # (H, W, C) -> (C, H, W)\n    depth = depth.permute(2, 0, 1) # (H, W, C) -> (C, H, W)\n    # Process Camera Parameters\n    intrinsics = intrinsics[:3, :3]\n    w2c = torch.linalg.inv(pose)\n    # Setup Camera",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "get_loss_gs",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def get_loss_gs(params, curr_data, variables, loss_weights):\n    # Initialize Loss Dictionary\n    losses = {}\n    # Initialize Render Variables\n    rendervar = params2rendervar(params)\n    depth_sil_rendervar = params2depthplussilhouette(params, curr_data['w2c'])\n    # RGB Rendering\n    rendervar['means2D'].retain_grad()\n    im, radius, _, = Renderer(raster_settings=curr_data['cam'])(**rendervar)\n    variables['means2D'] = rendervar['means2D']  # Gradient only accum from colour render for densification",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "initialize_new_params",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def initialize_new_params(new_pt_cld, mean3_sq_dist, gaussian_distribution):\n    num_pts = new_pt_cld.shape[0]\n    means3D = new_pt_cld[:, :3] # [num_gaussians, 3]\n    unnorm_rots = np.tile([1, 0, 0, 0], (num_pts, 1)) # [num_gaussians, 4]\n    logit_opacities = torch.zeros((num_pts, 1), dtype=torch.float, device=\"cuda\")\n    if gaussian_distribution == \"isotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 1))\n    elif gaussian_distribution == \"anisotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 3))\n    else:",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "add_new_gaussians",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def add_new_gaussians(params, variables, curr_data, sil_thres, \n                      time_idx, mean_sq_dist_method, gaussian_distribution):\n    # Silhouette Rendering\n    transformed_gaussians = transform_to_frame(params, time_idx, gaussians_grad=False, camera_grad=False)\n    depth_sil_rendervar = transformed_params2depthplussilhouette(params, curr_data['w2c'],\n                                                                 transformed_gaussians)\n    depth_sil, _, _, = Renderer(raster_settings=curr_data['cam'])(**depth_sil_rendervar)\n    silhouette = depth_sil[1, :, :]\n    non_presence_sil_mask = (silhouette < sil_thres)\n    # Check for new foreground objects by using GT depth",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "convert_params_to_store",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def convert_params_to_store(params):\n    params_to_store = {}\n    for k, v in params.items():\n        if isinstance(v, torch.Tensor):\n            params_to_store[k] = v.detach().clone()\n        else:\n            params_to_store[k] = v\n    return params_to_store\ndef offline_splatting(config: dict):\n    # Print Config",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "offline_splatting",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "def offline_splatting(config: dict):\n    # Print Config\n    print(\"Loaded Config:\")\n    if \"gaussian_distribution\" not in config:\n        config['gaussian_distribution'] = \"anisotropic\"\n    print(f\"{config}\")\n    # Init WandB\n    if config['use_wandb']:\n        wandb_step = 0\n        wandb_time_step = 0",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "description": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nprint(\"System Paths:\")\nfor p in sys.path:\n    print(p)\nimport cv2\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nimport wandb",
        "detail": "thirdparty.SplaTAM.scripts.gaussian_splatting",
        "documentation": {}
    },
    {
        "label": "SplatCaptureFrame",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.scripts.iphone_demo",
        "description": "thirdparty.SplaTAM.scripts.iphone_demo",
        "peekOfCode": "class SplatCaptureFrame(idl.IdlStruct, typename=\"SplatCaptureData.SplatCaptureFrame\"):\n    id: types.uint32\n    annotate.key(\"id\")\n    timestamp: types.float64\n    fl_x: types.float32\n    fl_y: types.float32\n    cx: types.float32\n    cy: types.float32\n    transform_matrix: types.array[types.float32, 16]\n    width: types.uint32",
        "detail": "thirdparty.SplaTAM.scripts.iphone_demo",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.iphone_demo",
        "description": "thirdparty.SplaTAM.scripts.iphone_demo",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--config\", default=\"./configs/iphone/online_demo.py\", type=str, help=\"Path to config file.\")\n    return parser.parse_args()\n# DDS\n# ==================================================================================================\n@dataclass\n@annotate.final\n@annotate.autoid(\"sequential\")\nclass SplatCaptureFrame(idl.IdlStruct, typename=\"SplatCaptureData.SplatCaptureFrame\"):",
        "detail": "thirdparty.SplaTAM.scripts.iphone_demo",
        "documentation": {}
    },
    {
        "label": "dataset_capture_loop",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.iphone_demo",
        "description": "thirdparty.SplaTAM.scripts.iphone_demo",
        "peekOfCode": "def dataset_capture_loop(reader: DataReader, save_path: Path, overwrite: bool, n_frames: int, depth_scale: float, config: dict):\n    rgb_path = save_path.joinpath(\"rgb\")\n    if rgb_path.exists():\n        if overwrite:\n            # Prompt user to confirm deletion\n            if (input(f\"warning! folder '{save_path}' will be deleted/replaced. continue? (Y/n)\").lower().strip()+\"y\")[:1] != \"y\":\n                sys.exit(1)\n            shutil.rmtree(save_path)\n        else:\n            print(f\"rgb_path {rgb_path} already exists. Please use overwrite=True in config if you want to overwrite.\")",
        "detail": "thirdparty.SplaTAM.scripts.iphone_demo",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.iphone_demo",
        "description": "thirdparty.SplaTAM.scripts.iphone_demo",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom datasets.gradslam_datasets.geometryutils import relative_transformation\nfrom utils.common_utils import seed_everything, save_params_ckpt, save_params",
        "detail": "thirdparty.SplaTAM.scripts.iphone_demo",
        "documentation": {}
    },
    {
        "label": "dds_config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.iphone_demo",
        "description": "thirdparty.SplaTAM.scripts.iphone_demo",
        "peekOfCode": "dds_config = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\" ?> \\\n<CycloneDDS xmlns=\"https://cdds.io/config\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://cdds.io/config https://raw.githubusercontent.com/eclipse-cyclonedds/cyclonedds/master/etc/cyclonedds.xsd\"> \\\n    <Domain id=\"any\"> \\\n        <Internal> \\\n            <MinimumSocketReceiveBufferSize>10MB</MinimumSocketReceiveBufferSize> \\\n        </Internal> \\\n        <Tracing> \\\n            <Verbosity>config</Verbosity> \\\n            <OutputFile>stdout</OutputFile> \\\n        </Tracing> \\",
        "detail": "thirdparty.SplaTAM.scripts.iphone_demo",
        "documentation": {}
    },
    {
        "label": "SplatCaptureFrame",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "description": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "peekOfCode": "class SplatCaptureFrame(idl.IdlStruct, typename=\"SplatCaptureData.SplatCaptureFrame\"):\n    id: types.uint32\n    annotate.key(\"id\")\n    timestamp: types.float64\n    fl_x: types.float32\n    fl_y: types.float32\n    cx: types.float32\n    cy: types.float32\n    transform_matrix: types.array[types.float32, 16]\n    width: types.uint32",
        "detail": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "description": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "peekOfCode": "def parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--config\", default=\"./configs/iphone/nerfcapture.py\", type=str, help=\"Path to config file.\")\n    return parser.parse_args()\n# DDS\n# ==================================================================================================\n@dataclass\n@annotate.final\n@annotate.autoid(\"sequential\")\nclass SplatCaptureFrame(idl.IdlStruct, typename=\"SplatCaptureData.SplatCaptureFrame\"):",
        "detail": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "documentation": {}
    },
    {
        "label": "dataset_capture_loop",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "description": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "peekOfCode": "def dataset_capture_loop(reader: DataReader, save_path: Path, overwrite: bool, n_frames: int, depth_scale: float):\n    if save_path.exists():\n        if overwrite:\n            # Prompt user to confirm deletion\n            if (input(f\"warning! folder '{save_path}' will be deleted/replaced. continue? (Y/n)\").lower().strip()+\"y\")[:1] != \"y\":\n                sys.exit(1)\n            shutil.rmtree(save_path)\n        else:\n            print(f\"save_path {save_path} already exists\")\n            sys.exit(1)",
        "detail": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "description": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nimport cv2\nimport numpy as np\nimport cyclonedds.idl as idl\nimport cyclonedds.idl.annotations as annotate\nimport cyclonedds.idl.types as types\nfrom dataclasses import dataclass\nfrom cyclonedds.domain import DomainParticipant, Domain\nfrom cyclonedds.core import Qos, Policy",
        "detail": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "documentation": {}
    },
    {
        "label": "dds_config",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "description": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "peekOfCode": "dds_config = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\" ?> \\\n<CycloneDDS xmlns=\"https://cdds.io/config\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://cdds.io/config https://raw.githubusercontent.com/eclipse-cyclonedds/cyclonedds/master/etc/cyclonedds.xsd\"> \\\n    <Domain id=\"any\"> \\\n        <Internal> \\\n            <MinimumSocketReceiveBufferSize>10MB</MinimumSocketReceiveBufferSize> \\\n        </Internal> \\\n        <Tracing> \\\n            <Verbosity>config</Verbosity> \\\n            <OutputFile>stdout</OutputFile> \\\n        </Tracing> \\",
        "detail": "thirdparty.SplaTAM.scripts.nerfcapture2dataset",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "description": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "peekOfCode": "def get_dataset(config_dict, basedir, sequence, **kwargs):\n    if config_dict[\"dataset_name\"].lower() in [\"icl\"]:\n        return ICLDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replica\"]:\n        return ReplicaDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replicav2\"]:\n        return ReplicaV2Dataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"azure\", \"azurekinect\"]:\n        return AzureKinectDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"scannet\"]:",
        "detail": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "initialize_optimizer",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "description": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "peekOfCode": "def initialize_optimizer(params, lrs_dict):\n    lrs = lrs_dict\n    param_groups = [{'params': [v], 'name': k, 'lr': lrs[k]} for k, v in params.items()]\n    return torch.optim.Adam(param_groups, lr=0.0, eps=1e-15)\ndef initialize_first_timestep_from_ckpt(ckpt_path,dataset, num_frames, lrs_dict, mean_sq_dist_method):\n    # Get RGB-D Data & Camera Parameters\n    color, depth, intrinsics, pose = dataset[0]\n    # Process RGB-D Data\n    color = color.permute(2, 0, 1) / 255 # (H, W, C) -> (C, H, W)\n    depth = depth.permute(2, 0, 1) # (H, W, C) -> (C, H, W)",
        "detail": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "initialize_first_timestep_from_ckpt",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "description": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "peekOfCode": "def initialize_first_timestep_from_ckpt(ckpt_path,dataset, num_frames, lrs_dict, mean_sq_dist_method):\n    # Get RGB-D Data & Camera Parameters\n    color, depth, intrinsics, pose = dataset[0]\n    # Process RGB-D Data\n    color = color.permute(2, 0, 1) / 255 # (H, W, C) -> (C, H, W)\n    depth = depth.permute(2, 0, 1) # (H, W, C) -> (C, H, W)\n    # Process Camera Parameters\n    intrinsics = intrinsics[:3, :3]\n    w2c = torch.linalg.inv(pose)\n    # Setup Camera",
        "detail": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "get_loss_gs",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "description": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "peekOfCode": "def get_loss_gs(params, curr_data, variables, loss_weights):\n    # Initialize Loss Dictionary\n    losses = {}\n    # Initialize Render Variables\n    rendervar = params2rendervar(params)\n    depth_sil_rendervar = params2depthplussilhouette(params, curr_data['w2c'])\n    # RGB Rendering\n    rendervar['means2D'].retain_grad()\n    im, radius, _, = Renderer(raster_settings=curr_data['cam'])(**rendervar)\n    variables['means2D'] = rendervar['means2D']  # Gradient only accum from colour render for densification",
        "detail": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "convert_params_to_store",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "description": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "peekOfCode": "def convert_params_to_store(params):\n    params_to_store = {}\n    for k, v in params.items():\n        if isinstance(v, torch.Tensor):\n            params_to_store[k] = v.detach().clone()\n        else:\n            params_to_store[k] = v\n    return params_to_store\ndef rgbd_slam(config: dict):\n    print(\"Loaded Config:\")",
        "detail": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "rgbd_slam",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "description": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "peekOfCode": "def rgbd_slam(config: dict):\n    print(\"Loaded Config:\")\n    print(f\"{config}\")\n    # Init WandB\n    if config['use_wandb']:\n        wandb_step = 0\n        wandb_time_step = 0\n        wandb_run = wandb.init(project=config['wandb']['project'],\n                               entity=config['wandb']['entity'],\n                               group=config['wandb']['group'],",
        "detail": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "description": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nprint(\"System Paths:\")\nfor p in sys.path:\n    print(p)\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport wandb",
        "detail": "thirdparty.SplaTAM.scripts.post_splatam_opt",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def get_dataset(config_dict, basedir, sequence, **kwargs):\n    if config_dict[\"dataset_name\"].lower() in [\"icl\"]:\n        return ICLDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replica\"]:\n        return ReplicaDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"replicav2\"]:\n        return ReplicaV2Dataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"azure\", \"azurekinect\"]:\n        return AzureKinectDataset(config_dict, basedir, sequence, **kwargs)\n    elif config_dict[\"dataset_name\"].lower() in [\"scannet\"]:",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "get_pointcloud",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def get_pointcloud(color, depth, intrinsics, w2c, transform_pts=True, \n                   mask=None, compute_mean_sq_dist=False, mean_sq_dist_method=\"projective\"):\n    width, height = color.shape[2], color.shape[1]\n    CX = intrinsics[0][2]\n    CY = intrinsics[1][2]\n    FX = intrinsics[0][0]\n    FY = intrinsics[1][1]\n    # Compute indices of pixels\n    x_grid, y_grid = torch.meshgrid(torch.arange(width).cuda().float(), \n                                    torch.arange(height).cuda().float(),",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_params",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def initialize_params(init_pt_cld, num_frames, mean3_sq_dist, gaussian_distribution):\n    num_pts = init_pt_cld.shape[0]\n    means3D = init_pt_cld[:, :3] # [num_gaussians, 3]\n    unnorm_rots = np.tile([1, 0, 0, 0], (num_pts, 1)) # [num_gaussians, 4]\n    logit_opacities = torch.zeros((num_pts, 1), dtype=torch.float, device=\"cuda\")\n    if gaussian_distribution == \"isotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 1))\n    elif gaussian_distribution == \"anisotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 3))\n    else:",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_optimizer",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def initialize_optimizer(params, lrs_dict, tracking):\n    lrs = lrs_dict\n    param_groups = [{'params': [v], 'name': k, 'lr': lrs[k]} for k, v in params.items()]\n    if tracking:\n        return torch.optim.Adam(param_groups)\n    else:\n        return torch.optim.Adam(param_groups, lr=0.0, eps=1e-15)\ndef initialize_first_timestep(dataset, num_frames, scene_radius_depth_ratio, \n                              mean_sq_dist_method, densify_dataset=None, gaussian_distribution=None):\n    # Get RGB-D Data & Camera Parameters",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_first_timestep",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def initialize_first_timestep(dataset, num_frames, scene_radius_depth_ratio, \n                              mean_sq_dist_method, densify_dataset=None, gaussian_distribution=None):\n    # Get RGB-D Data & Camera Parameters\n    color, depth, intrinsics, pose = dataset[0]\n    # Process RGB-D Data\n    color = color.permute(2, 0, 1) / 255 # (H, W, C) -> (C, H, W)\n    depth = depth.permute(2, 0, 1) # (H, W, C) -> (C, H, W)\n    # Process Camera Parameters\n    intrinsics = intrinsics[:3, :3]\n    w2c = torch.linalg.inv(pose)",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "get_loss",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def get_loss(params, curr_data, variables, iter_time_idx, loss_weights, use_sil_for_loss,\n             sil_thres, use_l1, ignore_outlier_depth_loss, tracking=False, \n             mapping=False, do_ba=False, plot_dir=None, visualize_tracking_loss=False, tracking_iteration=None):\n    # Initialize Loss Dictionary\n    losses = {}\n    if tracking:\n        # Get current frame Gaussians, where only the camera pose gets gradient\n        transformed_gaussians = transform_to_frame(params, iter_time_idx, \n                                             gaussians_grad=False,\n                                             camera_grad=True)",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_new_params",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def initialize_new_params(new_pt_cld, mean3_sq_dist, gaussian_distribution):\n    num_pts = new_pt_cld.shape[0]\n    means3D = new_pt_cld[:, :3] # [num_gaussians, 3]\n    unnorm_rots = np.tile([1, 0, 0, 0], (num_pts, 1)) # [num_gaussians, 4]\n    logit_opacities = torch.zeros((num_pts, 1), dtype=torch.float, device=\"cuda\")\n    if gaussian_distribution == \"isotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 1))\n    elif gaussian_distribution == \"anisotropic\":\n        log_scales = torch.tile(torch.log(torch.sqrt(mean3_sq_dist))[..., None], (1, 3))\n    else:",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "add_new_gaussians",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def add_new_gaussians(params, variables, curr_data, sil_thres, \n                      time_idx, mean_sq_dist_method, gaussian_distribution):\n    # Silhouette Rendering\n    transformed_gaussians = transform_to_frame(params, time_idx, gaussians_grad=False, camera_grad=False)\n    depth_sil_rendervar = transformed_params2depthplussilhouette(params, curr_data['w2c'],\n                                                                 transformed_gaussians)\n    depth_sil, _, _, = Renderer(raster_settings=curr_data['cam'])(**depth_sil_rendervar)\n    silhouette = depth_sil[1, :, :]\n    non_presence_sil_mask = (silhouette < sil_thres)\n    # Check for new foreground objects by using GT depth",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "initialize_camera_pose",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def initialize_camera_pose(params, curr_time_idx, forward_prop):\n    with torch.no_grad():\n        if curr_time_idx > 1 and forward_prop:\n            # Initialize the camera pose for the current frame based on a constant velocity model\n            # Rotation\n            prev_rot1 = F.normalize(params['cam_unnorm_rots'][..., curr_time_idx-1].detach())\n            prev_rot2 = F.normalize(params['cam_unnorm_rots'][..., curr_time_idx-2].detach())\n            new_rot = F.normalize(prev_rot1 + (prev_rot1 - prev_rot2))\n            params['cam_unnorm_rots'][..., curr_time_idx] = new_rot.detach()\n            # Translation",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "convert_params_to_store",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def convert_params_to_store(params):\n    params_to_store = {}\n    for k, v in params.items():\n        if isinstance(v, torch.Tensor):\n            params_to_store[k] = v.detach().clone()\n        else:\n            params_to_store[k] = v\n    return params_to_store\ndef rgbd_slam(config: dict):\n    # Print Config",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "rgbd_slam",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "def rgbd_slam(config: dict):\n    # Print Config\n    print(\"Loaded Config:\")\n    if \"use_depth_loss_thres\" not in config['tracking']:\n        config['tracking']['use_depth_loss_thres'] = False\n        config['tracking']['depth_loss_thres'] = 100000\n    if \"visualize_tracking_loss\" not in config['tracking']:\n        config['tracking']['visualize_tracking_loss'] = False\n    if \"gaussian_distribution\" not in config:\n        config['gaussian_distribution'] = \"isotropic\"",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.scripts.splatam",
        "description": "thirdparty.SplaTAM.scripts.splatam",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nprint(\"System Paths:\")\nfor p in sys.path:\n    print(p)\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F",
        "detail": "thirdparty.SplaTAM.scripts.splatam",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.common_utils",
        "description": "thirdparty.SplaTAM.utils.common_utils",
        "peekOfCode": "def seed_everything(seed=42):\n    \"\"\"\n        Set the `seed` value for torch and numpy seeds. Also turns on\n        deterministic execution for cudnn.\n        Parameters:\n        - seed:     A hashable seed value\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)",
        "detail": "thirdparty.SplaTAM.utils.common_utils",
        "documentation": {}
    },
    {
        "label": "params2cpu",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.common_utils",
        "description": "thirdparty.SplaTAM.utils.common_utils",
        "peekOfCode": "def params2cpu(params):\n    res = {}\n    for k, v in params.items():\n        if isinstance(v, torch.Tensor):\n            res[k] = v.detach().cpu().contiguous().numpy()\n        else:\n            res[k] = v\n    return res\ndef save_params(output_params, output_dir):\n    # Convert to CPU Numpy Arrays",
        "detail": "thirdparty.SplaTAM.utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.common_utils",
        "description": "thirdparty.SplaTAM.utils.common_utils",
        "peekOfCode": "def save_params(output_params, output_dir):\n    # Convert to CPU Numpy Arrays\n    to_save = params2cpu(output_params)\n    # Save the Parameters containing the Gaussian Trajectories\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"Saving parameters to: {output_dir}\")\n    save_path = os.path.join(output_dir, \"params.npz\")\n    np.savez(save_path, **to_save)\ndef save_params_ckpt(output_params, output_dir, time_idx):\n    # Convert to CPU Numpy Arrays",
        "detail": "thirdparty.SplaTAM.utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_params_ckpt",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.common_utils",
        "description": "thirdparty.SplaTAM.utils.common_utils",
        "peekOfCode": "def save_params_ckpt(output_params, output_dir, time_idx):\n    # Convert to CPU Numpy Arrays\n    to_save = params2cpu(output_params)\n    # Save the Parameters containing the Gaussian Trajectories\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"Saving parameters to: {output_dir}\")\n    save_path = os.path.join(output_dir, \"params\"+str(time_idx)+\".npz\")\n    np.savez(save_path, **to_save)\ndef save_seq_params(all_params, output_dir):\n    params_to_save = {}",
        "detail": "thirdparty.SplaTAM.utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_seq_params",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.common_utils",
        "description": "thirdparty.SplaTAM.utils.common_utils",
        "peekOfCode": "def save_seq_params(all_params, output_dir):\n    params_to_save = {}\n    for frame_idx, params in enumerate(all_params):\n        params_to_save[f\"frame_{frame_idx}\"] = params2cpu(params)\n    # Save the Parameters containing the Sequence of Gaussians\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"Saving parameters to: {output_dir}\")\n    save_path = os.path.join(output_dir, \"params.npz\")\n    np.savez(save_path, **params_to_save)\ndef save_seq_params_ckpt(all_params, output_dir,time_idx):",
        "detail": "thirdparty.SplaTAM.utils.common_utils",
        "documentation": {}
    },
    {
        "label": "save_seq_params_ckpt",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.common_utils",
        "description": "thirdparty.SplaTAM.utils.common_utils",
        "peekOfCode": "def save_seq_params_ckpt(all_params, output_dir,time_idx):\n    params_to_save = {}\n    for frame_idx, params in enumerate(all_params):\n        params_to_save[f\"frame_{frame_idx}\"] = params2cpu(params)\n    # Save the Parameters containing the Sequence of Gaussians\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"Saving parameters to: {output_dir}\")\n    save_path = os.path.join(output_dir, \"params\"+str(time_idx)+\".npz\")\n    np.savez(save_path, **params_to_save)",
        "detail": "thirdparty.SplaTAM.utils.common_utils",
        "documentation": {}
    },
    {
        "label": "align",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Args:\n        model -- first trajectory (3xn)\n        data -- second trajectory (3xn)\n    Returns:\n        rot -- rotation matrix (3x3)\n        trans -- translation vector (3x1)\n        trans_error -- translational error per point (1xn)\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "evaluate_ate",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def evaluate_ate(gt_traj, est_traj):\n    \"\"\"\n    Input : \n        gt_traj: list of 4x4 matrices \n        est_traj: list of 4x4 matrices\n        len(gt_traj) == len(est_traj)\n    \"\"\"\n    gt_traj_pts = [gt_traj[idx][:3,3] for idx in range(len(gt_traj))]\n    est_traj_pts = [est_traj[idx][:3,3] for idx in range(len(est_traj))]\n    gt_traj_pts  = torch.stack(gt_traj_pts).detach().cpu().numpy().T",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "report_loss",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def report_loss(losses, wandb_run, wandb_step, tracking=False, mapping=False):\n    # Update loss dict\n    loss_dict = {'Loss': losses['loss'].item(),\n                 'Image Loss': losses['im'].item(),\n                 'Depth Loss': losses['depth'].item(),}\n    if tracking:\n        tracking_loss_dict = {}\n        for k, v in loss_dict.items():\n            tracking_loss_dict[f\"Per Iteration Tracking/{k}\"] = v\n        tracking_loss_dict['Per Iteration Tracking/step'] = wandb_step",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "plot_rgbd_silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def plot_rgbd_silhouette(color, depth, rastered_color, rastered_depth, presence_sil_mask, diff_depth_l1,\n                         psnr, depth_l1, fig_title, plot_dir=None, plot_name=None, \n                         save_plot=False, wandb_run=None, wandb_step=None, wandb_title=None, diff_rgb=None):\n    # Determine Plot Aspect Ratio\n    aspect_ratio = color.shape[2] / color.shape[1]\n    fig_height = 8\n    fig_width = 14/1.55\n    fig_width = fig_width * aspect_ratio\n    # Plot the Ground Truth and Rasterized RGB & Depth, along with Diff Depth & Silhouette\n    fig, axs = plt.subplots(2, 3, figsize=(fig_width, fig_height))",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "report_progress",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def report_progress(params, data, i, progress_bar, iter_time_idx, sil_thres, every_i=1, qual_every_i=1, \n                    tracking=False, mapping=False, wandb_run=None, wandb_step=None, wandb_save_qual=False, online_time_idx=None,\n                    global_logging=True):\n    if i % every_i == 0 or i == 1:\n        if wandb_run is not None:\n            if tracking:\n                stage = \"Tracking\"\n            elif mapping:\n                stage = \"Mapping\"\n            else:",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "eval_online",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def eval_online(dataset, all_params, num_frames, eval_online_dir, sil_thres,\n                mapping_iters, add_new_gaussians, wandb_run=None, wandb_save_qual=False, eval_every=1):\n    print(\"Evaluating Online Final Parameters...\")\n    psnr_list = []\n    rmse_list = []\n    l1_list = []\n    plot_dir = os.path.join(eval_online_dir, \"plots\")\n    os.makedirs(plot_dir, exist_ok=True)\n    for time_idx in tqdm(range(num_frames)):\n        if time_idx != 0 and (time_idx+1) % eval_every != 0:",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "eval",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def eval(dataset, final_params, num_frames, eval_dir, sil_thres, \n         mapping_iters, add_new_gaussians, wandb_run=None, wandb_save_qual=False, eval_every=1, save_frames=False):\n    print(\"Evaluating Final Parameters ...\")\n    psnr_list = []\n    rmse_list = []\n    l1_list = []\n    lpips_list = []\n    ssim_list = []\n    plot_dir = os.path.join(eval_dir, \"plots\")\n    os.makedirs(plot_dir, exist_ok=True)",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "eval_nvs",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "def eval_nvs(dataset, final_params, num_frames, eval_dir, sil_thres, \n         mapping_iters, add_new_gaussians, wandb_run=None, wandb_save_qual=False, eval_every=1, save_frames=False):\n    print(\"Evaluating Final Parameters for Novel View Synthesis ...\")\n    psnr_list = []\n    rmse_list = []\n    l1_list = []\n    lpips_list = []\n    ssim_list = []\n    valid_nvs_frames = []\n    plot_dir = os.path.join(eval_dir, \"plots\")",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "loss_fn_alex",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.utils.eval_helpers",
        "description": "thirdparty.SplaTAM.utils.eval_helpers",
        "peekOfCode": "loss_fn_alex = LearnedPerceptualImagePatchSimilarity(net_type='alex', normalize=True).cuda()\ndef align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Args:\n        model -- first trajectory (3xn)\n        data -- second trajectory (3xn)\n    Returns:\n        rot -- rotation matrix (3x3)\n        trans -- translation vector (3x1)\n        trans_error -- translational error per point (1xn)",
        "detail": "thirdparty.SplaTAM.utils.eval_helpers",
        "documentation": {}
    },
    {
        "label": "BasicPointCloud",
        "kind": 6,
        "importPath": "thirdparty.SplaTAM.utils.graphics_utils",
        "description": "thirdparty.SplaTAM.utils.graphics_utils",
        "peekOfCode": "class BasicPointCloud(NamedTuple):\n    points : np.array\n    colors : np.array\n    normals : np.array\ndef geom_transform_points(points, transf_matrix):\n    P, _ = points.shape\n    ones = torch.ones(P, 1, dtype=points.dtype, device=points.device)\n    points_hom = torch.cat([points, ones], dim=1)\n    points_out = torch.matmul(points_hom, transf_matrix.unsqueeze(0))\n    denom = points_out[..., 3:] + 0.0000001",
        "detail": "thirdparty.SplaTAM.utils.graphics_utils",
        "documentation": {}
    },
    {
        "label": "geom_transform_points",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.graphics_utils",
        "description": "thirdparty.SplaTAM.utils.graphics_utils",
        "peekOfCode": "def geom_transform_points(points, transf_matrix):\n    P, _ = points.shape\n    ones = torch.ones(P, 1, dtype=points.dtype, device=points.device)\n    points_hom = torch.cat([points, ones], dim=1)\n    points_out = torch.matmul(points_hom, transf_matrix.unsqueeze(0))\n    denom = points_out[..., 3:] + 0.0000001\n    return (points_out[..., :3] / denom).squeeze(dim=0)\ndef getWorld2View(R, t):\n    Rt = np.zeros((4, 4))\n    Rt[:3, :3] = R.transpose()",
        "detail": "thirdparty.SplaTAM.utils.graphics_utils",
        "documentation": {}
    },
    {
        "label": "getWorld2View",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.graphics_utils",
        "description": "thirdparty.SplaTAM.utils.graphics_utils",
        "peekOfCode": "def getWorld2View(R, t):\n    Rt = np.zeros((4, 4))\n    Rt[:3, :3] = R.transpose()\n    Rt[:3, 3] = t\n    Rt[3, 3] = 1.0\n    return np.float32(Rt)\ndef getWorld2View2(R, t, translate=np.array([.0, .0, .0]), scale=1.0):\n    Rt = np.zeros((4, 4))\n    Rt[:3, :3] = R.transpose()\n    Rt[:3, 3] = t",
        "detail": "thirdparty.SplaTAM.utils.graphics_utils",
        "documentation": {}
    },
    {
        "label": "getWorld2View2",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.graphics_utils",
        "description": "thirdparty.SplaTAM.utils.graphics_utils",
        "peekOfCode": "def getWorld2View2(R, t, translate=np.array([.0, .0, .0]), scale=1.0):\n    Rt = np.zeros((4, 4))\n    Rt[:3, :3] = R.transpose()\n    Rt[:3, 3] = t\n    Rt[3, 3] = 1.0\n    C2W = np.linalg.inv(Rt)\n    cam_center = C2W[:3, 3]\n    cam_center = (cam_center + translate) * scale\n    C2W[:3, 3] = cam_center\n    Rt = np.linalg.inv(C2W)",
        "detail": "thirdparty.SplaTAM.utils.graphics_utils",
        "documentation": {}
    },
    {
        "label": "getProjectionMatrix",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.graphics_utils",
        "description": "thirdparty.SplaTAM.utils.graphics_utils",
        "peekOfCode": "def getProjectionMatrix(znear, zfar, fovX, fovY):\n    tanHalfFovY = math.tan((fovY / 2))\n    tanHalfFovX = math.tan((fovX / 2))\n    top = tanHalfFovY * znear\n    bottom = -top\n    right = tanHalfFovX * znear\n    left = -right\n    P = torch.zeros(4, 4)\n    z_sign = 1.0\n    P[0, 0] = 2.0 * znear / (right - left)",
        "detail": "thirdparty.SplaTAM.utils.graphics_utils",
        "documentation": {}
    },
    {
        "label": "fov2focal",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.graphics_utils",
        "description": "thirdparty.SplaTAM.utils.graphics_utils",
        "peekOfCode": "def fov2focal(fov, pixels):\n    return pixels / (2 * math.tan(fov / 2))\ndef focal2fov(focal, pixels):\n    return 2*math.atan(pixels/(2*focal))",
        "detail": "thirdparty.SplaTAM.utils.graphics_utils",
        "documentation": {}
    },
    {
        "label": "focal2fov",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.graphics_utils",
        "description": "thirdparty.SplaTAM.utils.graphics_utils",
        "peekOfCode": "def focal2fov(focal, pixels):\n    return 2*math.atan(pixels/(2*focal))",
        "detail": "thirdparty.SplaTAM.utils.graphics_utils",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def build_rotation(q):\n    norm = torch.sqrt(q[:, 0] * q[:, 0] + q[:, 1] * q[:, 1] + q[:, 2] * q[:, 2] + q[:, 3] * q[:, 3])\n    q = q / norm[:, None]\n    rot = torch.zeros((q.size(0), 3, 3), device='cuda')\n    r = q[:, 0]\n    x = q[:, 1]\n    y = q[:, 2]\n    z = q[:, 3]\n    rot[:, 0, 0] = 1 - 2 * (y * y + z * z)\n    rot[:, 0, 1] = 2 * (x * y - r * z)",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "calc_mse",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def calc_mse(img1, img2):\n    return ((img1 - img2) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\ndef calc_psnr(img1, img2):\n    mse = ((img1 - img2) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\n    return 20 * torch.log10(1.0 / torch.sqrt(mse))\ndef gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    return gauss / gauss.sum()\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "calc_psnr",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def calc_psnr(img1, img2):\n    mse = ((img1 - img2) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\n    return 20 * torch.log10(1.0 / torch.sqrt(mse))\ndef gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    return gauss / gauss.sum()\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "gaussian",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    return gauss / gauss.sum()\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n    return window\ndef calc_ssim(img1, img2, window_size=11, size_average=True):\n    channel = img1.size(-3)",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "create_window",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n    return window\ndef calc_ssim(img1, img2, window_size=11, size_average=True):\n    channel = img1.size(-3)\n    window = create_window(window_size, channel)\n    if img1.is_cuda:\n        window = window.cuda(img1.get_device())",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "calc_ssim",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def calc_ssim(img1, img2, window_size=11, size_average=True):\n    channel = img1.size(-3)\n    window = create_window(window_size, channel)\n    if img1.is_cuda:\n        window = window.cuda(img1.get_device())\n    window = window.type_as(img1)\n    return _ssim(img1, img2, window, window_size, channel, size_average)\ndef _ssim(img1, img2, window, window_size, channel, size_average=True):\n    mu1 = func.conv2d(img1, window, padding=window_size // 2, groups=channel)\n    mu2 = func.conv2d(img2, window, padding=window_size // 2, groups=channel)",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "accumulate_mean2d_gradient",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def accumulate_mean2d_gradient(variables):\n    variables['means2D_gradient_accum'][variables['seen']] += torch.norm(\n        variables['means2D'].grad[variables['seen'], :2], dim=-1)\n    variables['denom'][variables['seen']] += 1\n    return variables\ndef update_params_and_optimizer(new_params, params, optimizer):\n    for k, v in new_params.items():\n        group = [x for x in optimizer.param_groups if x[\"name\"] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        stored_state[\"exp_avg\"] = torch.zeros_like(v)",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "update_params_and_optimizer",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def update_params_and_optimizer(new_params, params, optimizer):\n    for k, v in new_params.items():\n        group = [x for x in optimizer.param_groups if x[\"name\"] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        stored_state[\"exp_avg\"] = torch.zeros_like(v)\n        stored_state[\"exp_avg_sq\"] = torch.zeros_like(v)\n        del optimizer.state[group['params'][0]]\n        group[\"params\"][0] = torch.nn.Parameter(v.requires_grad_(True))\n        optimizer.state[group['params'][0]] = stored_state\n        params[k] = group[\"params\"][0]",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "cat_params_to_optimizer",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def cat_params_to_optimizer(new_params, params, optimizer):\n    for k, v in new_params.items():\n        group = [g for g in optimizer.param_groups if g['name'] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        if stored_state is not None:\n            stored_state[\"exp_avg\"] = torch.cat((stored_state[\"exp_avg\"], torch.zeros_like(v)), dim=0)\n            stored_state[\"exp_avg_sq\"] = torch.cat((stored_state[\"exp_avg_sq\"], torch.zeros_like(v)), dim=0)\n            del optimizer.state[group['params'][0]]\n            group[\"params\"][0] = torch.nn.Parameter(torch.cat((group[\"params\"][0], v), dim=0).requires_grad_(True))\n            optimizer.state[group['params'][0]] = stored_state",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "remove_points",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def remove_points(to_remove, params, variables, optimizer):\n    to_keep = ~to_remove\n    keys = [k for k in params.keys() if k not in ['cam_unnorm_rots', 'cam_trans']]\n    for k in keys:\n        group = [g for g in optimizer.param_groups if g['name'] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        if stored_state is not None:\n            stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][to_keep]\n            stored_state[\"exp_avg_sq\"] = stored_state[\"exp_avg_sq\"][to_keep]\n            del optimizer.state[group['params'][0]]",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def inverse_sigmoid(x):\n    return torch.log(x / (1 - x))\ndef prune_gaussians(params, variables, optimizer, iter, prune_dict):\n    if iter <= prune_dict['stop_after']:\n        if (iter >= prune_dict['start_after']) and (iter % prune_dict['prune_every'] == 0):\n            if iter == prune_dict['stop_after']:\n                remove_threshold = prune_dict['final_removal_opacity_threshold']\n            else:\n                remove_threshold = prune_dict['removal_opacity_threshold']\n            # Remove Gaussians with low opacity",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "prune_gaussians",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def prune_gaussians(params, variables, optimizer, iter, prune_dict):\n    if iter <= prune_dict['stop_after']:\n        if (iter >= prune_dict['start_after']) and (iter % prune_dict['prune_every'] == 0):\n            if iter == prune_dict['stop_after']:\n                remove_threshold = prune_dict['final_removal_opacity_threshold']\n            else:\n                remove_threshold = prune_dict['removal_opacity_threshold']\n            # Remove Gaussians with low opacity\n            to_remove = (torch.sigmoid(params['logit_opacities']) < remove_threshold).squeeze()\n            # Remove Gaussians that are too big",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "densify",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def densify(params, variables, optimizer, iter, densify_dict):\n    if iter <= densify_dict['stop_after']:\n        variables = accumulate_mean2d_gradient(variables)\n        grad_thresh = densify_dict['grad_thresh']\n        if (iter >= densify_dict['start_after']) and (iter % densify_dict['densify_every'] == 0):\n            grads = variables['means2D_gradient_accum'] / variables['denom']\n            grads[grads.isnan()] = 0.0\n            to_clone = torch.logical_and(grads >= grad_thresh, (\n                        torch.max(torch.exp(params['log_scales']), dim=1).values <= 0.01 * variables['scene_radius']))\n            new_params = {k: v[to_clone] for k, v in params.items() if k not in ['cam_unnorm_rots', 'cam_trans']}",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "update_learning_rate",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def update_learning_rate(optimizer, means3D_scheduler, iteration):\n        ''' Learning rate scheduling per step '''\n        for param_group in optimizer.param_groups:\n            if param_group[\"name\"] == \"means3D\":\n                lr = means3D_scheduler(iteration)\n                param_group['lr'] = lr\n                return lr\ndef get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "get_expon_lr_func",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_external",
        "description": "thirdparty.SplaTAM.utils.gs_external",
        "peekOfCode": "def get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):\n    \"\"\"\n    Copied from Plenoxels\n    Continuous learning rate decay function. Adapted from JaxNeRF\n    The returned rate is lr_init when step=0 and lr_final when step=max_steps, and\n    is log-linearly interpolated elsewhere (equivalent to exponential decay).\n    If lr_delay_steps>0 then the learning rate will be scaled by some smooth\n    function of lr_delay_mult, such that the initial learning rate is",
        "detail": "thirdparty.SplaTAM.utils.gs_external",
        "documentation": {}
    },
    {
        "label": "l1_loss_v1",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def l1_loss_v1(x, y):\n    return torch.abs((x - y)).mean()\ndef l1_loss_v2(x, y):\n    return (torch.abs(x - y).sum(-1)).mean()\ndef weighted_l2_loss_v1(x, y, w):\n    return torch.sqrt(((x - y) ** 2) * w + 1e-20).mean()\ndef weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "l1_loss_v2",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def l1_loss_v2(x, y):\n    return (torch.abs(x - y).sum(-1)).mean()\ndef weighted_l2_loss_v1(x, y, w):\n    return torch.sqrt(((x - y) ** 2) * w + 1e-20).mean()\ndef weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Args:\n        model -- first trajectory (3xn)",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "weighted_l2_loss_v1",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def weighted_l2_loss_v1(x, y, w):\n    return torch.sqrt(((x - y) ** 2) * w + 1e-20).mean()\ndef weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Args:\n        model -- first trajectory (3xn)\n        data -- second trajectory (3xn)\n    Returns:",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "weighted_l2_loss_v2",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Args:\n        model -- first trajectory (3xn)\n        data -- second trajectory (3xn)\n    Returns:\n        rot -- rotation matrix (3x3)\n        trans -- translation vector (3x1)",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "align",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def align(model, data):\n    \"\"\"Align two trajectories using the method of Horn (closed-form).\n    Args:\n        model -- first trajectory (3xn)\n        data -- second trajectory (3xn)\n    Returns:\n        rot -- rotation matrix (3x3)\n        trans -- translation vector (3x1)\n        trans_error -- translational error per point (1xn)\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "evaluate_ate",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def evaluate_ate(gt_traj, est_traj):\n    \"\"\"\n    Input : \n        gt_traj: list of 4x4 matrices \n        est_traj: list of 4x4 matrices\n        len(gt_traj) == len(est_traj)\n    \"\"\"\n    gt_traj_pts = [gt_traj[idx][:3,3] for idx in range(len(gt_traj))]\n    est_traj_pts = [est_traj[idx][:3,3] for idx in range(len(est_traj))]\n    gt_traj_pts  = torch.stack(gt_traj_pts).detach().cpu().numpy().T",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "quat_mult",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def quat_mult(q1, q2):\n    w1, x1, y1, z1 = q1.T\n    w2, x2, y2, z2 = q2.T\n    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n    y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2\n    z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2\n    return torch.stack([w, x, y, z]).T\ndef _sqrt_positive_part(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "matrix_to_quaternion",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def matrix_to_quaternion(matrix: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Convert rotations given as rotation matrices to quaternions.\n    Args:\n        matrix: Rotation matrices as tensor of shape (..., 3, 3).\n    Returns:\n        quaternions with real part first, as tensor of shape (..., 4).\n    Source: https://pytorch3d.readthedocs.io/en/latest/_modules/pytorch3d/transforms/rotation_conversions.html#matrix_to_quaternion\n    \"\"\"\n    if matrix.size(-1) != 3 or matrix.size(-2) != 3:",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "o3d_knn",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def o3d_knn(pts, num_knn):\n    indices = []\n    sq_dists = []\n    pcd = o3d.geometry.PointCloud()\n    pcd.points = o3d.utility.Vector3dVector(np.ascontiguousarray(pts, np.float64))\n    pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n    for p in pcd.points:\n        [_, i, d] = pcd_tree.search_knn_vector_3d(p, num_knn + 1)\n        indices.append(i[1:])\n        sq_dists.append(d[1:])",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "params2rendervar",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def params2rendervar(params):\n    rendervar = {\n        'means3D': params['means3D'],\n        'colors_precomp': params['rgb_colors'],\n        'rotations': F.normalize(params['unnorm_rotations']),\n        'opacities': torch.sigmoid(params['logit_opacities']),\n        'scales': torch.exp(torch.tile(params['log_scales'], (1, 3))),\n        'means2D': torch.zeros_like(params['means3D'], requires_grad=True, device=\"cuda\") + 0\n    }\n    return rendervar",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2rendervar",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def transformed_params2rendervar(params, transformed_pts):\n    rendervar = {\n        'means3D': transformed_pts,\n        'colors_precomp': params['rgb_colors'],\n        'rotations': F.normalize(params['unnorm_rotations']),\n        'opacities': torch.sigmoid(params['logit_opacities']),\n        'scales': torch.exp(torch.tile(params['log_scales'], (1, 3))),\n        'means2D': torch.zeros_like(params['means3D'], requires_grad=True, device=\"cuda\") + 0\n    }\n    return rendervar",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "project_points",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def project_points(points_3d, intrinsics):\n    \"\"\"\n    Function to project 3D points to image plane.\n    params:\n    points_3d: [num_gaussians, 3]\n    intrinsics: [3, 3]\n    out: [num_gaussians, 2]\n    \"\"\"\n    points_2d = torch.matmul(intrinsics, points_3d.transpose(0, 1))\n    points_2d = points_2d.transpose(0, 1)",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "params2silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def params2silhouette(params):\n    sil_color = torch.zeros_like(params['rgb_colors'])\n    sil_color[:, 0] = 1.0\n    rendervar = {\n        'means3D': params['means3D'],\n        'colors_precomp': sil_color,\n        'rotations': F.normalize(params['unnorm_rotations']),\n        'opacities': torch.sigmoid(params['logit_opacities']),\n        'scales': torch.exp(torch.tile(params['log_scales'], (1, 3))),\n        'means2D': torch.zeros_like(params['means3D'], requires_grad=True, device=\"cuda\") + 0",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def transformed_params2silhouette(params, transformed_pts):\n    sil_color = torch.zeros_like(params['rgb_colors'])\n    sil_color[:, 0] = 1.0\n    rendervar = {\n        'means3D': transformed_pts,\n        'colors_precomp': sil_color,\n        'rotations': F.normalize(params['unnorm_rotations']),\n        'opacities': torch.sigmoid(params['logit_opacities']),\n        'scales': torch.exp(torch.tile(params['log_scales'], (1, 3))),\n        'means2D': torch.zeros_like(params['means3D'], requires_grad=True, device=\"cuda\") + 0",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "get_depth_and_silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def get_depth_and_silhouette(pts_3D, w2c):\n    \"\"\"\n    Function to compute depth and silhouette for each gaussian.\n    These are evaluated at gaussian center.\n    \"\"\"\n    # Depth of each gaussian center in camera frame\n    pts4 = torch.cat((pts_3D, torch.ones_like(pts_3D[:, :1])), dim=-1)\n    pts_in_cam = (w2c @ pts4.transpose(0, 1)).transpose(0, 1)\n    depth_z = pts_in_cam[:, 2].unsqueeze(-1) # [num_gaussians, 1]\n    depth_z_sq = torch.square(depth_z) # [num_gaussians, 1]",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "params2depthplussilhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def params2depthplussilhouette(params, w2c):\n    rendervar = {\n        'means3D': params['means3D'],\n        'colors_precomp': get_depth_and_silhouette(params['means3D'], w2c),\n        'rotations': F.normalize(params['unnorm_rotations']),\n        'opacities': torch.sigmoid(params['logit_opacities']),\n        'scales': torch.exp(torch.tile(params['log_scales'], (1, 3))),\n        'means2D': torch.zeros_like(params['means3D'], requires_grad=True, device=\"cuda\") + 0\n    }\n    return rendervar",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2depthplussilhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def transformed_params2depthplussilhouette(params, w2c, transformed_pts):\n    rendervar = {\n        'means3D': transformed_pts,\n        'colors_precomp': get_depth_and_silhouette(transformed_pts, w2c),\n        'rotations': F.normalize(params['unnorm_rotations']),\n        'opacities': torch.sigmoid(params['logit_opacities']),\n        'scales': torch.exp(torch.tile(params['log_scales'], (1, 3))),\n        'means2D': torch.zeros_like(params['means3D'], requires_grad=True, device=\"cuda\") + 0\n    }\n    return rendervar",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "transform_to_frame",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def transform_to_frame(params, time_idx, gaussians_grad, camera_grad):\n    \"\"\"\n    Function to transform Isotropic Gaussians from world frame to camera frame.\n    Args:\n        params: dict of parameters\n        time_idx: time index to transform to\n        gaussians_grad: enable gradients for Gaussians\n        camera_grad: enable gradients for camera pose\n    Returns:\n        transformed_pts: Transformed Centers of Gaussians",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "report_loss",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def report_loss(losses, wandb_run, wandb_step, tracking=False, mapping=False):\n    # Update loss dict\n    loss_dict = {'Loss': losses['loss'].item(),\n                 'Image Loss': losses['im'].item(),\n                 'Depth Loss': losses['depth'].item(),}\n    if tracking:\n        tracking_loss_dict = {}\n        for k, v in loss_dict.items():\n            tracking_loss_dict[f\"Tracking {k}\"] = v\n        wandb_run.log(tracking_loss_dict, step=wandb_step)",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "plot_rgbd_silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def plot_rgbd_silhouette(color, depth, rastered_color, rastered_depth, presence_sil_mask, diff_depth_rmse,\n                         psnr, rmse, fig_title, plot_dir=None, plot_name=None, \n                         save_plot=False, wandb_run=None, wandb_step=None, wandb_title=None):\n    # Determine Plot Aspect Ratio\n    aspect_ratio = color.shape[2] / color.shape[1]\n    fig_height = 8\n    fig_width = 14/1.55\n    fig_width = fig_width * aspect_ratio\n    # Plot the Ground Truth and Rasterized RGB & Depth, along with Diff Depth & Silhouette\n    fig, axs = plt.subplots(2, 3, figsize=(fig_width, fig_height))",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "report_progress",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def report_progress(params, data, i, progress_bar, iter_time_idx, sil_thres, every_i=1, qual_every_i=1, \n                    tracking=False, mapping=False, wandb_run=None, wandb_step=None, wandb_save_qual=False, online_time_idx=None):\n    if i % every_i == 0 or i == 1:\n        if wandb_run is not None:\n            if tracking:\n                stage = \"Tracking\"\n            elif mapping:\n                stage = \"Mapping\"\n            else:\n                stage = \"Current Frame Optimization\"",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "eval",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "def eval(dataset, final_params, num_frames, eval_dir, sil_thres, mapping_iters, add_new_gaussians, wandb_run=None, wandb_save_qual=False):\n    print(\"Evaluating Final Parameters ...\")\n    psnr_list = []\n    rmse_list = []\n    lpips_list = []\n    ssim_list = []\n    plot_dir = os.path.join(eval_dir, \"plots\")\n    os.makedirs(plot_dir, exist_ok=True)\n    gt_w2c_list = []\n    for time_idx in tqdm(range(num_frames)):",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "loss_fn_alex",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.utils.gs_helpers",
        "description": "thirdparty.SplaTAM.utils.gs_helpers",
        "peekOfCode": "loss_fn_alex = LearnedPerceptualImagePatchSimilarity(net_type='alex', normalize=True).cuda()\ndef l1_loss_v1(x, y):\n    return torch.abs((x - y)).mean()\ndef l1_loss_v2(x, y):\n    return (torch.abs(x - y).sum(-1)).mean()\ndef weighted_l2_loss_v1(x, y, w):\n    return torch.sqrt(((x - y) ** 2) * w + 1e-20).mean()\ndef weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef align(model, data):",
        "detail": "thirdparty.SplaTAM.utils.gs_helpers",
        "documentation": {}
    },
    {
        "label": "get_pointcloud",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.keyframe_selection",
        "description": "thirdparty.SplaTAM.utils.keyframe_selection",
        "peekOfCode": "def get_pointcloud(depth, intrinsics, w2c, sampled_indices):\n    CX = intrinsics[0][2]\n    CY = intrinsics[1][2]\n    FX = intrinsics[0][0]\n    FY = intrinsics[1][1]\n    # Compute indices of sampled pixels\n    xx = (sampled_indices[:, 1] - CX)/FX\n    yy = (sampled_indices[:, 0] - CY)/FY\n    depth_z = depth[0, sampled_indices[:, 0], sampled_indices[:, 1]]\n    # Initialize point cloud",
        "detail": "thirdparty.SplaTAM.utils.keyframe_selection",
        "documentation": {}
    },
    {
        "label": "keyframe_selection_overlap",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.keyframe_selection",
        "description": "thirdparty.SplaTAM.utils.keyframe_selection",
        "peekOfCode": "def keyframe_selection_overlap(gt_depth, w2c, intrinsics, keyframe_list, k, pixels=1600):\n        \"\"\"\n        Select overlapping keyframes to the current camera observation.\n        Args:\n            gt_depth (tensor): ground truth depth image of the current frame.\n            w2c (tensor): world to camera matrix (4 x 4).\n            keyframe_list (list): a list containing info for each keyframe.\n            k (int): number of overlapping keyframes to select.\n            pixels (int, optional): number of pixels to sparsely sample \n                from the image of the current camera. Defaults to 1600.",
        "detail": "thirdparty.SplaTAM.utils.keyframe_selection",
        "documentation": {}
    },
    {
        "label": "torch_3d_knn",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.neighbor_search",
        "description": "thirdparty.SplaTAM.utils.neighbor_search",
        "peekOfCode": "def torch_3d_knn(pts, num_knn, method=\"l2\"):\n    # Initialize FAISS index\n    if method == \"l2\":\n        index = faiss.IndexFlatL2(pts.shape[1])\n    elif method == \"cosine\":\n        index = faiss.IndexFlatIP(pts.shape[1])\n    else:\n        raise NotImplementedError(f\"Method: {method}\")\n    # Convert FAISS index to GPU\n    if pts.get_device() != -1:",
        "detail": "thirdparty.SplaTAM.utils.neighbor_search",
        "documentation": {}
    },
    {
        "label": "calculate_neighbors",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.neighbor_search",
        "description": "thirdparty.SplaTAM.utils.neighbor_search",
        "peekOfCode": "def calculate_neighbors(params, variables, time_idx, num_knn=20):\n    if time_idx is None:\n        pts = params['means3D'].detach()\n    else:\n        pts = params['means3D'][:, :, time_idx].detach()\n    neighbor_dist, neighbor_indices = torch_3d_knn(pts.contiguous(), num_knn)\n    neighbor_weight = torch.exp(-2000 * torch.square(neighbor_dist))\n    variables[\"neighbor_indices\"] = neighbor_indices.long().contiguous()\n    variables[\"neighbor_weight\"] = neighbor_weight.float().contiguous()\n    variables[\"neighbor_dist\"] = neighbor_dist.float().contiguous()",
        "detail": "thirdparty.SplaTAM.utils.neighbor_search",
        "documentation": {}
    },
    {
        "label": "setup_camera",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.recon_helpers",
        "description": "thirdparty.SplaTAM.utils.recon_helpers",
        "peekOfCode": "def setup_camera(w, h, k, w2c, near=0.01, far=100):\n    fx, fy, cx, cy = k[0][0], k[1][1], k[0][2], k[1][2]\n    w2c = torch.tensor(w2c).cuda().float()\n    cam_center = torch.inverse(w2c)[:3, 3]\n    w2c = w2c.unsqueeze(0).transpose(1, 2)\n    opengl_proj = torch.tensor([[2 * fx / w, 0.0, -(w - 2 * cx) / w, 0.0],\n                                [0.0, 2 * fy / h, -(h - 2 * cy) / h, 0.0],\n                                [0.0, 0.0, far / (far - near), -(far * near) / (far - near)],\n                                [0.0, 0.0, 1.0, 0.0]]).cuda().float().unsqueeze(0).transpose(1, 2)\n    full_proj = w2c.bmm(opengl_proj)",
        "detail": "thirdparty.SplaTAM.utils.recon_helpers",
        "documentation": {}
    },
    {
        "label": "build_rotation",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def build_rotation(q):\n    norm = torch.sqrt(q[:, 0] * q[:, 0] + q[:, 1] * q[:, 1] + q[:, 2] * q[:, 2] + q[:, 3] * q[:, 3])\n    q = q / norm[:, None]\n    rot = torch.zeros((q.size(0), 3, 3), device='cuda')\n    r = q[:, 0]\n    x = q[:, 1]\n    y = q[:, 2]\n    z = q[:, 3]\n    rot[:, 0, 0] = 1 - 2 * (y * y + z * z)\n    rot[:, 0, 1] = 2 * (x * y - r * z)",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "calc_mse",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def calc_mse(img1, img2):\n    return ((img1 - img2) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\ndef calc_psnr(img1, img2):\n    mse = ((img1 - img2) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\n    return 20 * torch.log10(1.0 / torch.sqrt(mse))\ndef gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    return gauss / gauss.sum()\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "calc_psnr",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def calc_psnr(img1, img2):\n    mse = ((img1 - img2) ** 2).view(img1.shape[0], -1).mean(1, keepdim=True)\n    return 20 * torch.log10(1.0 / torch.sqrt(mse))\ndef gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    return gauss / gauss.sum()\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "gaussian",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def gaussian(window_size, sigma):\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n    return gauss / gauss.sum()\ndef create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n    return window\ndef calc_ssim(img1, img2, window_size=11, size_average=True):\n    channel = img1.size(-3)",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "create_window",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def create_window(window_size, channel):\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n    return window\ndef calc_ssim(img1, img2, window_size=11, size_average=True):\n    channel = img1.size(-3)\n    window = create_window(window_size, channel)\n    if img1.is_cuda:\n        window = window.cuda(img1.get_device())",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "calc_ssim",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def calc_ssim(img1, img2, window_size=11, size_average=True):\n    channel = img1.size(-3)\n    window = create_window(window_size, channel)\n    if img1.is_cuda:\n        window = window.cuda(img1.get_device())\n    window = window.type_as(img1)\n    return _ssim(img1, img2, window, window_size, channel, size_average)\ndef _ssim(img1, img2, window, window_size, channel, size_average=True):\n    mu1 = func.conv2d(img1, window, padding=window_size // 2, groups=channel)\n    mu2 = func.conv2d(img2, window, padding=window_size // 2, groups=channel)",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "accumulate_mean2d_gradient",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def accumulate_mean2d_gradient(variables):\n    variables['means2D_gradient_accum'][variables['seen']] += torch.norm(\n        variables['means2D'].grad[variables['seen'], :2], dim=-1)\n    variables['denom'][variables['seen']] += 1\n    return variables\ndef update_params_and_optimizer(new_params, params, optimizer):\n    for k, v in new_params.items():\n        group = [x for x in optimizer.param_groups if x[\"name\"] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        stored_state[\"exp_avg\"] = torch.zeros_like(v)",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "update_params_and_optimizer",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def update_params_and_optimizer(new_params, params, optimizer):\n    for k, v in new_params.items():\n        group = [x for x in optimizer.param_groups if x[\"name\"] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        stored_state[\"exp_avg\"] = torch.zeros_like(v)\n        stored_state[\"exp_avg_sq\"] = torch.zeros_like(v)\n        del optimizer.state[group['params'][0]]\n        group[\"params\"][0] = torch.nn.Parameter(v.requires_grad_(True))\n        optimizer.state[group['params'][0]] = stored_state\n        params[k] = group[\"params\"][0]",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "cat_params_to_optimizer",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def cat_params_to_optimizer(new_params, params, optimizer):\n    for k, v in new_params.items():\n        group = [g for g in optimizer.param_groups if g['name'] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        if stored_state is not None:\n            stored_state[\"exp_avg\"] = torch.cat((stored_state[\"exp_avg\"], torch.zeros_like(v)), dim=0)\n            stored_state[\"exp_avg_sq\"] = torch.cat((stored_state[\"exp_avg_sq\"], torch.zeros_like(v)), dim=0)\n            del optimizer.state[group['params'][0]]\n            group[\"params\"][0] = torch.nn.Parameter(torch.cat((group[\"params\"][0], v), dim=0).requires_grad_(True))\n            optimizer.state[group['params'][0]] = stored_state",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "remove_points",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def remove_points(to_remove, params, variables, optimizer):\n    to_keep = ~to_remove\n    keys = [k for k in params.keys() if k not in ['cam_unnorm_rots', 'cam_trans']]\n    for k in keys:\n        group = [g for g in optimizer.param_groups if g['name'] == k][0]\n        stored_state = optimizer.state.get(group['params'][0], None)\n        if stored_state is not None:\n            stored_state[\"exp_avg\"] = stored_state[\"exp_avg\"][to_keep]\n            stored_state[\"exp_avg_sq\"] = stored_state[\"exp_avg_sq\"][to_keep]\n            del optimizer.state[group['params'][0]]",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "inverse_sigmoid",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def inverse_sigmoid(x):\n    return torch.log(x / (1 - x))\ndef prune_gaussians(params, variables, optimizer, iter, prune_dict):\n    if iter <= prune_dict['stop_after']:\n        if (iter >= prune_dict['start_after']) and (iter % prune_dict['prune_every'] == 0):\n            if iter == prune_dict['stop_after']:\n                remove_threshold = prune_dict['final_removal_opacity_threshold']\n            else:\n                remove_threshold = prune_dict['removal_opacity_threshold']\n            # Remove Gaussians with low opacity",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "prune_gaussians",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def prune_gaussians(params, variables, optimizer, iter, prune_dict):\n    if iter <= prune_dict['stop_after']:\n        if (iter >= prune_dict['start_after']) and (iter % prune_dict['prune_every'] == 0):\n            if iter == prune_dict['stop_after']:\n                remove_threshold = prune_dict['final_removal_opacity_threshold']\n            else:\n                remove_threshold = prune_dict['removal_opacity_threshold']\n            # Remove Gaussians with low opacity\n            to_remove = (torch.sigmoid(params['logit_opacities']) < remove_threshold).squeeze()\n            # Remove Gaussians that are too big",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "densify",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def densify(params, variables, optimizer, iter, densify_dict):\n    if iter <= densify_dict['stop_after']:\n        variables = accumulate_mean2d_gradient(variables)\n        grad_thresh = densify_dict['grad_thresh']\n        if (iter >= densify_dict['start_after']) and (iter % densify_dict['densify_every'] == 0):\n            grads = variables['means2D_gradient_accum'] / variables['denom']\n            grads[grads.isnan()] = 0.0\n            to_clone = torch.logical_and(grads >= grad_thresh, (\n                        torch.max(torch.exp(params['log_scales']), dim=1).values <= 0.01 * variables['scene_radius']))\n            new_params = {k: v[to_clone] for k, v in params.items() if k not in ['cam_unnorm_rots', 'cam_trans']}",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "update_learning_rate",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def update_learning_rate(optimizer, means3D_scheduler, iteration):\n        ''' Learning rate scheduling per step '''\n        for param_group in optimizer.param_groups:\n            if param_group[\"name\"] == \"means3D\":\n                lr = means3D_scheduler(iteration)\n                param_group['lr'] = lr\n                return lr\ndef get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "get_expon_lr_func",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_external",
        "description": "thirdparty.SplaTAM.utils.slam_external",
        "peekOfCode": "def get_expon_lr_func(\n    lr_init, lr_final, lr_delay_steps=0, lr_delay_mult=1.0, max_steps=1000000\n):\n    \"\"\"\n    Copied from Plenoxels\n    Continuous learning rate decay function. Adapted from JaxNeRF\n    The returned rate is lr_init when step=0 and lr_final when step=max_steps, and\n    is log-linearly interpolated elsewhere (equivalent to exponential decay).\n    If lr_delay_steps>0 then the learning rate will be scaled by some smooth\n    function of lr_delay_mult, such that the initial learning rate is",
        "detail": "thirdparty.SplaTAM.utils.slam_external",
        "documentation": {}
    },
    {
        "label": "l1_loss_v1",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def l1_loss_v1(x, y):\n    return torch.abs((x - y)).mean()\ndef l1_loss_v2(x, y):\n    return (torch.abs(x - y).sum(-1)).mean()\ndef weighted_l2_loss_v1(x, y, w):\n    return torch.sqrt(((x - y) ** 2) * w + 1e-20).mean()\ndef weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef quat_mult(q1, q2):\n    w1, x1, y1, z1 = q1.T",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "l1_loss_v2",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def l1_loss_v2(x, y):\n    return (torch.abs(x - y).sum(-1)).mean()\ndef weighted_l2_loss_v1(x, y, w):\n    return torch.sqrt(((x - y) ** 2) * w + 1e-20).mean()\ndef weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef quat_mult(q1, q2):\n    w1, x1, y1, z1 = q1.T\n    w2, x2, y2, z2 = q2.T\n    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "weighted_l2_loss_v1",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def weighted_l2_loss_v1(x, y, w):\n    return torch.sqrt(((x - y) ** 2) * w + 1e-20).mean()\ndef weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef quat_mult(q1, q2):\n    w1, x1, y1, z1 = q1.T\n    w2, x2, y2, z2 = q2.T\n    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n    y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "weighted_l2_loss_v2",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def weighted_l2_loss_v2(x, y, w):\n    return torch.sqrt(((x - y) ** 2).sum(-1) * w + 1e-20).mean()\ndef quat_mult(q1, q2):\n    w1, x1, y1, z1 = q1.T\n    w2, x2, y2, z2 = q2.T\n    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n    y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2\n    z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2\n    return torch.stack([w, x, y, z]).T",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "quat_mult",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def quat_mult(q1, q2):\n    w1, x1, y1, z1 = q1.T\n    w2, x2, y2, z2 = q2.T\n    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n    y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2\n    z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2\n    return torch.stack([w, x, y, z]).T\ndef _sqrt_positive_part(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "matrix_to_quaternion",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def matrix_to_quaternion(matrix: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Convert rotations given as rotation matrices to quaternions.\n    Args:\n        matrix: Rotation matrices as tensor of shape (..., 3, 3).\n    Returns:\n        quaternions with real part first, as tensor of shape (..., 4).\n    Source: https://pytorch3d.readthedocs.io/en/latest/_modules/pytorch3d/transforms/rotation_conversions.html#matrix_to_quaternion\n    \"\"\"\n    if matrix.size(-1) != 3 or matrix.size(-2) != 3:",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "params2rendervar",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def params2rendervar(params):\n    # Check if Gaussians are Isotropic\n    if params['log_scales'].shape[1] == 1:\n        log_scales = torch.tile(params['log_scales'], (1, 3))\n    else:\n        log_scales = params['log_scales']\n    # Initialize Render Variables\n    rendervar = {\n        'means3D': params['means3D'],\n        'colors_precomp': params['rgb_colors'],",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2rendervar",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def transformed_params2rendervar(params, transformed_gaussians):\n    # Check if Gaussians are Isotropic\n    if params['log_scales'].shape[1] == 1:\n        log_scales = torch.tile(params['log_scales'], (1, 3))\n    else:\n        log_scales = params['log_scales']\n    # Initialize Render Variables\n    rendervar = {\n        'means3D': transformed_gaussians['means3D'],\n        'colors_precomp': params['rgb_colors'],",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "project_points",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def project_points(points_3d, intrinsics):\n    \"\"\"\n    Function to project 3D points to image plane.\n    params:\n    points_3d: [num_gaussians, 3]\n    intrinsics: [3, 3]\n    out: [num_gaussians, 2]\n    \"\"\"\n    points_2d = torch.matmul(intrinsics, points_3d.transpose(0, 1))\n    points_2d = points_2d.transpose(0, 1)",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "params2silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def params2silhouette(params):\n    # Check if Gaussians are Isotropic\n    if params['log_scales'].shape[1] == 1:\n        log_scales = torch.tile(params['log_scales'], (1, 3))\n    else:\n        log_scales = params['log_scales']\n    # Initialize Render Variables\n    sil_color = torch.zeros_like(params['rgb_colors'])\n    sil_color[:, 0] = 1.0\n    rendervar = {",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def transformed_params2silhouette(params, transformed_gaussians):\n    # Check if Gaussians are Isotropic\n    if params['log_scales'].shape[1] == 1:\n        log_scales = torch.tile(params['log_scales'], (1, 3))\n    else:\n        log_scales = params['log_scales']\n    # Initialize Render Variables\n    sil_color = torch.zeros_like(params['rgb_colors'])\n    sil_color[:, 0] = 1.0\n    rendervar = {",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "get_depth_and_silhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def get_depth_and_silhouette(pts_3D, w2c):\n    \"\"\"\n    Function to compute depth and silhouette for each gaussian.\n    These are evaluated at gaussian center.\n    \"\"\"\n    # Depth of each gaussian center in camera frame\n    pts4 = torch.cat((pts_3D, torch.ones_like(pts_3D[:, :1])), dim=-1)\n    pts_in_cam = (w2c @ pts4.transpose(0, 1)).transpose(0, 1)\n    depth_z = pts_in_cam[:, 2].unsqueeze(-1) # [num_gaussians, 1]\n    depth_z_sq = torch.square(depth_z) # [num_gaussians, 1]",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "params2depthplussilhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def params2depthplussilhouette(params, w2c):\n    # Check if Gaussians are Isotropic\n    if params['log_scales'].shape[1] == 1:\n        log_scales = torch.tile(params['log_scales'], (1, 3))\n    else:\n        log_scales = params['log_scales']\n    # Initialize Render Variables\n    rendervar = {\n        'means3D': params['means3D'],\n        'colors_precomp': get_depth_and_silhouette(params['means3D'], w2c),",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transformed_params2depthplussilhouette",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def transformed_params2depthplussilhouette(params, w2c, transformed_gaussians):\n    # Check if Gaussians are Isotropic\n    if params['log_scales'].shape[1] == 1:\n        log_scales = torch.tile(params['log_scales'], (1, 3))\n    else:\n        log_scales = params['log_scales']\n    # Initialize Render Variables\n    rendervar = {\n        'means3D': transformed_gaussians['means3D'],\n        'colors_precomp': get_depth_and_silhouette(transformed_gaussians['means3D'], w2c),",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "transform_to_frame",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.utils.slam_helpers",
        "description": "thirdparty.SplaTAM.utils.slam_helpers",
        "peekOfCode": "def transform_to_frame(params, time_idx, gaussians_grad, camera_grad):\n    \"\"\"\n    Function to transform Isotropic or Anisotropic Gaussians from world frame to camera frame.\n    Args:\n        params: dict of parameters\n        time_idx: time index to transform to\n        gaussians_grad: enable gradients for Gaussians\n        camera_grad: enable gradients for camera pose\n    Returns:\n        transformed_gaussians: Transformed Gaussians (dict containing means3D & unnorm_rotations)",
        "detail": "thirdparty.SplaTAM.utils.slam_helpers",
        "documentation": {}
    },
    {
        "label": "load_camera",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "peekOfCode": "def load_camera(cfg, scene_path):\n    all_params = dict(np.load(scene_path, allow_pickle=True))\n    params = all_params\n    org_width = params['org_width']\n    org_height = params['org_height']\n    w2c = params['w2c']\n    intrinsics = params['intrinsics']\n    k = intrinsics[:3, :3]\n    # Scale intrinsics to match the visualization resolution\n    k[0, :] *= cfg['viz_w'] / org_width",
        "detail": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "documentation": {}
    },
    {
        "label": "load_scene_data",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "peekOfCode": "def load_scene_data(scene_path, first_frame_w2c, intrinsics):\n    # Load Scene Data\n    all_params = dict(np.load(scene_path, allow_pickle=True))\n    all_params = {k: torch.tensor(all_params[k]).cuda().float() for k in all_params.keys()}\n    intrinsics = torch.tensor(intrinsics).cuda().float()\n    first_frame_w2c = torch.tensor(first_frame_w2c).cuda().float()\n    keys = [k for k in all_params.keys() if\n            k not in ['org_width', 'org_height', 'w2c', 'intrinsics', \n                      'gt_w2c_all_frames', 'cam_unnorm_rots',\n                      'cam_trans', 'keyframe_time_indices']]",
        "detail": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "documentation": {}
    },
    {
        "label": "make_lineset",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "peekOfCode": "def make_lineset(all_pts, all_cols, num_lines):\n    linesets = []\n    for pts, cols, num_lines in zip(all_pts, all_cols, num_lines):\n        lineset = o3d.geometry.LineSet()\n        lineset.points = o3d.utility.Vector3dVector(np.ascontiguousarray(pts, np.float64))\n        lineset.colors = o3d.utility.Vector3dVector(np.ascontiguousarray(cols, np.float64))\n        pt_indices = np.arange(len(lineset.points))\n        line_indices = np.stack((pt_indices, pt_indices - num_lines), -1)[num_lines:]\n        lineset.lines = o3d.utility.Vector2iVector(np.ascontiguousarray(line_indices, np.int32))\n        linesets.append(lineset)",
        "detail": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "documentation": {}
    },
    {
        "label": "render",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "peekOfCode": "def render(w2c, k, timestep_data, timestep_depth_data, cfg):\n    with torch.no_grad():\n        cam = setup_camera(cfg['viz_w'], cfg['viz_h'], k, w2c, cfg['viz_near'], cfg['viz_far'])\n        white_bg_cam = Camera(\n            image_height=cam.image_height,\n            image_width=cam.image_width,\n            tanfovx=cam.tanfovx,\n            tanfovy=cam.tanfovy,\n            bg=torch.tensor([1, 1, 1], dtype=torch.float32, device=\"cuda\"),\n            scale_modifier=cam.scale_modifier,",
        "detail": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "documentation": {}
    },
    {
        "label": "rgbd2pcd",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "peekOfCode": "def rgbd2pcd(color, depth, w2c, intrinsics, cfg):\n    width, height = color.shape[2], color.shape[1]\n    CX = intrinsics[0][2]\n    CY = intrinsics[1][2]\n    FX = intrinsics[0][0]\n    FY = intrinsics[1][1]\n    # Compute indices\n    xx = torch.tile(torch.arange(width).cuda(), (height,))\n    yy = torch.repeat_interleave(torch.arange(height).cuda(), width)\n    xx = (xx - CX) / FX",
        "detail": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "documentation": {}
    },
    {
        "label": "visualize",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "peekOfCode": "def visualize(scene_path, cfg):\n    # Load Scene Data\n    w2c, k = load_camera(cfg, scene_path)\n    scene_data, scene_depth_data, all_w2cs = load_scene_data(scene_path, w2c, k)\n    # vis.create_window()\n    vis = o3d.visualization.Visualizer()\n    vis.create_window(width=int(cfg['viz_w'] * cfg['view_scale']), \n                      height=int(cfg['viz_h'] * cfg['view_scale']),\n                      visible=True)\n    im, depth, sil = render(w2c, k, scene_data, scene_depth_data, cfg)",
        "detail": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport open3d as o3d\nfrom diff_gaussian_rasterization import GaussianRasterizer as Renderer\nfrom diff_gaussian_rasterization import GaussianRasterizationSettings as Camera\nfrom utils.common_utils import seed_everything",
        "detail": "thirdparty.SplaTAM.viz_scripts.final_recon",
        "documentation": {}
    },
    {
        "label": "load_camera",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "def load_camera(cfg, scene_path):\n    all_params = dict(np.load(scene_path, allow_pickle=True))\n    params = all_params\n    org_width = params['org_width']\n    org_height = params['org_height']\n    w2c = params['w2c']\n    intrinsics = params['intrinsics']\n    k = intrinsics[:3, :3]\n    # Scale intrinsics to match the visualization resolution\n    k[0, :] *= cfg['viz_w'] / org_width",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "load_scene_data",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "def load_scene_data(scene_path):\n    # Load Scene Data\n    all_params = dict(np.load(scene_path, allow_pickle=True))\n    all_params = {k: torch.tensor(all_params[k]).cuda().float() for k in all_params.keys()}\n    params = all_params\n    all_w2cs = []\n    num_t = params['cam_unnorm_rots'].shape[-1]\n    for t_i in range(num_t):\n        cam_rot = F.normalize(params['cam_unnorm_rots'][..., t_i])\n        cam_tran = params['cam_trans'][..., t_i]",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "get_rendervars",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "def get_rendervars(params, w2c, curr_timestep):\n    params_timesteps = params['timestep']\n    selected_params_idx = params_timesteps <= curr_timestep\n    keys = [k for k in params.keys() if\n            k not in ['org_width', 'org_height', 'w2c', 'intrinsics', \n                      'gt_w2c_all_frames', 'cam_unnorm_rots',\n                      'cam_trans', 'keyframe_time_indices']]\n    selected_params = deepcopy(params)\n    for k in keys:\n        selected_params[k] = selected_params[k][selected_params_idx]",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "make_lineset",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "def make_lineset(all_pts, all_cols, num_lines):\n    linesets = []\n    for pts, cols, num_lines in zip(all_pts, all_cols, num_lines):\n        lineset = o3d.geometry.LineSet()\n        lineset.points = o3d.utility.Vector3dVector(np.ascontiguousarray(pts, np.float64))\n        lineset.colors = o3d.utility.Vector3dVector(np.ascontiguousarray(cols, np.float64))\n        pt_indices = np.arange(len(lineset.points))\n        line_indices = np.stack((pt_indices, pt_indices - num_lines), -1)[num_lines:]\n        lineset.lines = o3d.utility.Vector2iVector(np.ascontiguousarray(line_indices, np.int32))\n        linesets.append(lineset)",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "render",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "def render(w2c, k, timestep_data, timestep_depth_data, cfg):\n    with torch.no_grad():\n        cam = setup_camera(cfg['viz_w'], cfg['viz_h'], k, w2c, cfg['viz_near'], cfg['viz_far'])\n        white_bg_cam = Camera(\n            image_height=cam.image_height,\n            image_width=cam.image_width,\n            tanfovx=cam.tanfovx,\n            tanfovy=cam.tanfovy,\n            bg=torch.tensor([1, 1, 1], dtype=torch.float32, device=\"cuda\"),\n            scale_modifier=cam.scale_modifier,",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "rgbd2pcd",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "def rgbd2pcd(color, depth, w2c, intrinsics, cfg):\n    width, height = color.shape[2], color.shape[1]\n    CX = intrinsics[0][2]\n    CY = intrinsics[1][2]\n    FX = intrinsics[0][0]\n    FY = intrinsics[1][1]\n    # Compute indices\n    xx = torch.tile(torch.arange(width).cuda(), (height,))\n    yy = torch.repeat_interleave(torch.arange(height).cuda(), width)\n    xx = (xx - CX) / FX",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "visualize",
        "kind": 2,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "def visualize(scene_path, cfg):\n    # Load Scene Data\n    first_frame_w2c, k = load_camera(cfg, scene_path)\n    params, all_w2cs = load_scene_data(scene_path)\n    print(params['means3D'].shape)\n    vis = o3d.visualization.Visualizer()\n    vis.create_window(width=int(cfg['viz_w'] * cfg['view_scale']), \n                      height=int(cfg['viz_h'] * cfg['view_scale']),\n                      visible=True)\n    scene_data, scene_depth_data = get_rendervars(params, first_frame_w2c, curr_timestep=0)",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "_BASE_DIR",
        "kind": 5,
        "importPath": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "description": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "peekOfCode": "_BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.insert(0, _BASE_DIR)\nfrom copy import deepcopy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport open3d as o3d\nimport torch\nimport torch.nn.functional as F\nfrom diff_gaussian_rasterization import GaussianRasterizer as Renderer\nfrom diff_gaussian_rasterization import GaussianRasterizationSettings as Camera",
        "detail": "thirdparty.SplaTAM.viz_scripts.online_recon",
        "documentation": {}
    },
    {
        "label": "PngCompression",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.compression.png_compression",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.compression.png_compression",
        "peekOfCode": "class PngCompression:\n    \"\"\"Uses quantization and sorting to compress splats into PNG files and uses\n    K-means clustering to compress the spherical harmonic coefficents.\n    .. warning::\n        This class requires the `imageio <https://pypi.org/project/imageio/>`_,\n        `plas <https://github.com/DeMoriarty/TorchPQ?tab=readme-ov-file#install>`_\n        and `torchpq <https://github.com/fraunhoferhhi/PLAS.git>`_ packages to be installed.\n    .. warning::\n        This class might throw away a few lowest opacities splats if the number of\n        splats is not a square number.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.compression.png_compression",
        "documentation": {}
    },
    {
        "label": "sort_splats",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.compression.sort",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.compression.sort",
        "peekOfCode": "def sort_splats(splats: Dict[str, Tensor], verbose: bool = True) -> Dict[str, Tensor]:\n    \"\"\"Sort splats with Parallel Linear Assignment Sorting from the paper `Compact 3D Scene Representation via\n    Self-Organizing Gaussian Grids <https://arxiv.org/pdf/2312.13299>`_.\n    .. warning::\n        PLAS must installed to use sorting.\n    Args:\n        splats (Dict[str, Tensor]): splats\n        verbose (bool, optional): Whether to print verbose information. Default to True.\n    Returns:\n        Dict[str, Tensor]: sorted splats",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.compression.sort",
        "documentation": {}
    },
    {
        "label": "load_extension",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "def load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,\n    extra_include_paths=None,\n    build_directory=None,\n):\n    \"\"\"Load a JIT compiled extension.\"\"\"",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_available",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "def cuda_toolkit_available():\n    \"\"\"Check if the nvcc is avaiable on the machine.\"\"\"\n    try:\n        call([\"nvcc\"], stdout=DEVNULL, stderr=DEVNULL)\n        return True\n    except FileNotFoundError:\n        return False\ndef cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_version",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "def cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")\n    if os.path.exists(os.path.join(cuda_home, \"version.txt\")):\n        with open(os.path.join(cuda_home, \"version.txt\")) as f:\n            cuda_version = f.read().strip().split()[-1]\n    elif os.path.exists(os.path.join(cuda_home, \"version.json\")):\n        with open(os.path.join(cuda_home, \"version.json\")) as f:\n            cuda_version = json.load(f)[\"cuda\"][\"version\"]\n    else:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "PATH",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "PATH = os.path.dirname(os.path.abspath(__file__))\nNO_FAST_MATH = os.getenv(\"NO_FAST_MATH\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "NO_FAST_MATH",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "NO_FAST_MATH = os.getenv(\"NO_FAST_MATH\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "MAX_JOBS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "MAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "need_to_unset_max_jobs",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "need_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "_C",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "_C = None\ntry:\n    # try to import the compiled module (via setup.py)\n    from gsplat import csrc as _C\nexcept ImportError:\n    # if failed, try with JIT compilation\n    if cuda_toolkit_available():\n        name = \"gsplat_cuda\"\n        build_dir = _get_build_directory(name, verbose=False)\n        current_dir = os.path.dirname(os.path.abspath(__file__))",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "peekOfCode": "__all__ = [\"_C\"]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "accumulate",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._torch_impl",
        "peekOfCode": "def accumulate(\n    means2d: Tensor,  # [C, N, 2]\n    conics: Tensor,  # [C, N, 3]\n    opacities: Tensor,  # [C, N]\n    colors: Tensor,  # [C, N, channels]\n    gaussian_ids: Tensor,  # [M]\n    pixel_ids: Tensor,  # [M]\n    camera_ids: Tensor,  # [M]\n    image_width: int,\n    image_height: int,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._torch_impl",
        "documentation": {}
    },
    {
        "label": "_QuatScaleToCovarPreci",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "class _QuatScaleToCovarPreci(torch.autograd.Function):\n    \"\"\"Converts quaternions and scales to covariance and precision matrices.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        quats: Tensor,  # [N, 4],\n        scales: Tensor,  # [N, 3],\n        compute_covar: bool = True,\n        compute_preci: bool = True,\n        triu: bool = False,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_PerspProj",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "class _PerspProj(torch.autograd.Function):\n    \"\"\"Perspective fully_fused_projection on Gaussians.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [C, N, 3]\n        covars: Tensor,  # [C, N, 3, 3]\n        Ks: Tensor,  # [C, 3, 3]\n        width: int,\n        height: int,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_WorldToCam",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "class _WorldToCam(torch.autograd.Function):\n    \"\"\"Transforms Gaussians from world to camera space.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [N, 3]\n        covars: Tensor,  # [N, 3, 3]\n        viewmats: Tensor,  # [C, 4, 4]\n    ) -> Tuple[Tensor, Tensor]:\n        means_c, covars_c = _make_lazy_cuda_func(\"world_to_cam_fwd\")(",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_FullyFusedProjection",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "class _FullyFusedProjection(torch.autograd.Function):\n    \"\"\"Projects Gaussians to 2D.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [N, 3]\n        covars: Tensor,  # [N, 6] or None\n        quats: Tensor,  # [N, 4] or None\n        scales: Tensor,  # [N, 3] or None\n        viewmats: Tensor,  # [C, 4, 4]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_RasterizeToPixels",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "class _RasterizeToPixels(torch.autograd.Function):\n    \"\"\"Rasterize gaussians\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means2d: Tensor,  # [C, N, 2]\n        conics: Tensor,  # [C, N, 3]\n        colors: Tensor,  # [C, N, D]\n        opacities: Tensor,  # [C, N]\n        backgrounds: Tensor,  # [C, D], Optional",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_FullyFusedProjectionPacked",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "class _FullyFusedProjectionPacked(torch.autograd.Function):\n    \"\"\"Projects Gaussians to 2D. Return packed tensors.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [N, 3]\n        covars: Tensor,  # [N, 6] or None\n        quats: Tensor,  # [N, 4] or None\n        scales: Tensor,  # [N, 3] or None\n        viewmats: Tensor,  # [C, 4, 4]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_SphericalHarmonics",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "class _SphericalHarmonics(torch.autograd.Function):\n    \"\"\"Spherical Harmonics\"\"\"\n    @staticmethod\n    def forward(\n        ctx, sh_degree: int, dirs: Tensor, coeffs: Tensor, masks: Tensor\n    ) -> Tensor:\n        colors = _make_lazy_cuda_func(\"compute_sh_fwd\")(sh_degree, dirs, coeffs, masks)\n        ctx.save_for_backward(dirs, coeffs, masks)\n        ctx.sh_degree = sh_degree\n        ctx.num_bases = coeffs.shape[-2]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "spherical_harmonics",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def spherical_harmonics(\n    degrees_to_use: int,\n    dirs: Tensor,  # [..., 3]\n    coeffs: Tensor,  # [..., K, 3]\n    masks: Optional[Tensor] = None,\n) -> Tensor:\n    \"\"\"Computes spherical harmonics.\n    Args:\n        degrees_to_use: The degree to be used.\n        dirs: Directions. [..., 3]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "quat_scale_to_covar_preci",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def quat_scale_to_covar_preci(\n    quats: Tensor,  # [N, 4],\n    scales: Tensor,  # [N, 3],\n    compute_covar: bool = True,\n    compute_preci: bool = True,\n    triu: bool = False,\n) -> Tuple[Optional[Tensor], Optional[Tensor]]:\n    \"\"\"Converts quaternions and scales to covariance and precision matrices.\n    Args:\n        quats: Quaternions (No need to be normalized). [N, 4]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "persp_proj",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def persp_proj(\n    means: Tensor,  # [C, N, 3]\n    covars: Tensor,  # [C, N, 3, 3]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,\n) -> Tuple[Tensor, Tensor]:\n    \"\"\"Perspective projection on Gaussians.\n    Args:\n        means: Gaussian means. [C, N, 3]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "world_to_cam",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def world_to_cam(\n    means: Tensor,  # [N, 3]\n    covars: Tensor,  # [N, 3, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n) -> Tuple[Tensor, Tensor]:\n    \"\"\"Transforms Gaussians from world to camera coordinate system.\n    Args:\n        means: Gaussian means. [N, 3]\n        covars: Gaussian covariances. [N, 3, 3]\n        viewmats: World-to-camera transformation matrices. [C, 4, 4]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "fully_fused_projection",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def fully_fused_projection(\n    means: Tensor,  # [N, 3]\n    covars: Optional[Tensor],  # [N, 6] or None\n    quats: Optional[Tensor],  # [N, 4] or None\n    scales: Optional[Tensor],  # [N, 3] or None\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,\n    eps2d: float = 0.3,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "isect_tiles",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def isect_tiles(\n    means2d: Tensor,  # [C, N, 2] or [nnz, 2]\n    radii: Tensor,  # [C, N] or [nnz]\n    depths: Tensor,  # [C, N] or [nnz]\n    tile_size: int,\n    tile_width: int,\n    tile_height: int,\n    sort: bool = True,\n    packed: bool = False,\n    n_cameras: Optional[int] = None,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "isect_offset_encode",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def isect_offset_encode(\n    isect_ids: Tensor, n_cameras: int, tile_width: int, tile_height: int\n) -> Tensor:\n    \"\"\"Encodes intersection ids to offsets.\n    Args:\n        isect_ids: Intersection ids. [n_isects]\n        n_cameras: Number of cameras.\n        tile_width: Tile width.\n        tile_height: Tile height.\n    Returns:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "rasterize_to_pixels",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def rasterize_to_pixels(\n    means2d: Tensor,  # [C, N, 2] or [nnz, 2]\n    conics: Tensor,  # [C, N, 3] or [nnz, 3]\n    colors: Tensor,  # [C, N, channels] or [nnz, channels]\n    opacities: Tensor,  # [C, N] or [nnz]\n    image_width: int,\n    image_height: int,\n    tile_size: int,\n    isect_offsets: Tensor,  # [C, tile_height, tile_width]\n    flatten_ids: Tensor,  # [n_isects]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "rasterize_to_indices_in_range",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "peekOfCode": "def rasterize_to_indices_in_range(\n    range_start: int,\n    range_end: int,\n    transmittances: Tensor,  # [C, image_height, image_width]\n    means2d: Tensor,  # [C, N, 2]\n    conics: Tensor,  # [C, N, 3]\n    opacities: Tensor,  # [C, N]\n    image_width: int,\n    image_height: int,\n    tile_size: int,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "load_extension",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "def load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,\n    extra_include_paths=None,\n    build_directory=None,\n):\n    \"\"\"Load a JIT compiled extension.\"\"\"",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_available",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "def cuda_toolkit_available():\n    \"\"\"Check if the nvcc is avaiable on the machine.\"\"\"\n    try:\n        call([\"nvcc\"], stdout=DEVNULL, stderr=DEVNULL)\n        return True\n    except FileNotFoundError:\n        return False\ndef cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_version",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "def cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")\n    if os.path.exists(os.path.join(cuda_home, \"version.txt\")):\n        with open(os.path.join(cuda_home, \"version.txt\")) as f:\n            cuda_version = f.read().strip().split()[-1]\n    elif os.path.exists(os.path.join(cuda_home, \"version.json\")):\n        with open(os.path.join(cuda_home, \"version.json\")) as f:\n            cuda_version = json.load(f)[\"cuda\"][\"version\"]\n    else:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "PATH",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "PATH = os.path.dirname(os.path.abspath(__file__))\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "MAX_JOBS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "MAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "need_to_unset_max_jobs",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "need_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "_C",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "_C = None\ntry:\n    # try to import the compiled module (via setup.py)\n    from gsplat import csrc_legacy as _C\nexcept ImportError:\n    # if failed, try with JIT compilation\n    if cuda_toolkit_available():\n        name = \"gsplat_cuda_legacy\"\n        build_dir = _get_build_directory(name, verbose=False)\n        current_dir = os.path.dirname(os.path.abspath(__file__))",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "peekOfCode": "__all__ = [\"_C\"]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "compute_sh_color",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def compute_sh_color(\n    viewdirs: Float[Tensor, \"*batch 3\"],\n    sh_coeffs: Float[Tensor, \"*batch D C\"],\n    method: Literal[\"poly\", \"fast\"] = \"fast\",\n):\n    \"\"\"\n    :param viewdirs (*, C)\n    :param sh_coeffs (*, D, C) sh coefficients for each color channel\n    return colors (*, C)\n    \"\"\"",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "eval_sh_bases",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def eval_sh_bases(basis_dim: int, dirs: torch.Tensor):\n    \"\"\"\n    Evaluate spherical harmonics bases at unit directions,\n    without taking linear combination.\n    At each point, the final result may the be\n    obtained through simple multiplication.\n    :param basis_dim: int SH basis dim. Currently, 1-25 square numbers supported\n    :param dirs: torch.Tensor (..., 3) unit directions\n    :return: torch.Tensor (..., basis_dim)\n    \"\"\"",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "eval_sh_bases_fast",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def eval_sh_bases_fast(basis_dim: int, dirs: torch.Tensor):\n    \"\"\"\n    Evaluate spherical harmonics bases at unit direction for high orders\n    using approach described by\n    Efficient Spherical Harmonic Evaluation, Peter-Pike Sloan, JCGT 2013\n    https://jcgt.org/published/0002/02/06/\n    :param basis_dim: int SH basis dim. Currently, only 1-25 square numbers supported\n    :param dirs: torch.Tensor (..., 3) unit directions\n    :return: torch.Tensor (..., basis_dim)\n    See reference C++ code in https://jcgt.org/published/0002/02/06/code.zip",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "normalized_quat_to_rotmat",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def normalized_quat_to_rotmat(quat: Tensor) -> Tensor:\n    assert quat.shape[-1] == 4, quat.shape\n    w, x, y, z = torch.unbind(quat, dim=-1)\n    mat = torch.stack(\n        [\n            1 - 2 * (y**2 + z**2),\n            2 * (x * y - w * z),\n            2 * (x * z + w * y),\n            2 * (x * y + w * z),\n            1 - 2 * (x**2 + z**2),",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "quat_to_rotmat",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def quat_to_rotmat(quat: Tensor) -> Tensor:\n    assert quat.shape[-1] == 4, quat.shape\n    return normalized_quat_to_rotmat(F.normalize(quat, dim=-1))\ndef scale_rot_to_cov3d(scale: Tensor, glob_scale: float, quat: Tensor) -> Tensor:\n    assert scale.shape[-1] == 3, scale.shape\n    assert quat.shape[-1] == 4, quat.shape\n    assert scale.shape[:-1] == quat.shape[:-1], (scale.shape, quat.shape)\n    R = normalized_quat_to_rotmat(quat)  # (..., 3, 3)\n    M = R * glob_scale * scale[..., None, :]  # (..., 3, 3)\n    # TODO: save upper right because symmetric",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "scale_rot_to_cov3d",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def scale_rot_to_cov3d(scale: Tensor, glob_scale: float, quat: Tensor) -> Tensor:\n    assert scale.shape[-1] == 3, scale.shape\n    assert quat.shape[-1] == 4, quat.shape\n    assert scale.shape[:-1] == quat.shape[:-1], (scale.shape, quat.shape)\n    R = normalized_quat_to_rotmat(quat)  # (..., 3, 3)\n    M = R * glob_scale * scale[..., None, :]  # (..., 3, 3)\n    # TODO: save upper right because symmetric\n    return M @ M.transpose(-1, -2)  # (..., 3, 3)\ndef project_cov3d_ewa(\n    mean3d: Tensor,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "project_cov3d_ewa",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def project_cov3d_ewa(\n    mean3d: Tensor,\n    cov3d: Tensor,\n    viewmat: Tensor,\n    fx: float,\n    fy: float,\n    tan_fovx: float,\n    tan_fovy: float,\n    is_valid: Optional[Tensor] = None,\n) -> Tuple[Tensor, Tensor]:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "compute_compensation",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def compute_compensation(cov2d_mat: Tensor):\n    \"\"\"\n    params: cov2d matrix (*, 2, 2)\n    returns: compensation factor as calculated in project_cov3d_ewa\n    \"\"\"\n    det_denom = cov2d_mat[..., 0, 0] * cov2d_mat[..., 1, 1] - cov2d_mat[..., 0, 1] ** 2\n    det_nomin = (cov2d_mat[..., 0, 0] - 0.3) * (cov2d_mat[..., 1, 1] - 0.3) - cov2d_mat[\n        ..., 0, 1\n    ] ** 2\n    return torch.sqrt(torch.clamp(det_nomin / det_denom, min=0))",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "compute_cov2d_bounds",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def compute_cov2d_bounds(cov2d_mat: Tensor, cov_valid: Optional[Tensor] = None):\n    \"\"\"\n    param: cov2d matrix (*, 2, 2)\n    returns: conic parameters (*, 3)\n    \"\"\"\n    det_all = cov2d_mat[..., 0, 0] * cov2d_mat[..., 1, 1] - cov2d_mat[..., 0, 1] ** 2\n    valid = det_all != 0\n    if cov_valid is not None:\n        valid = valid & cov_valid\n    # det = torch.clamp(det, min=eps)",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "project_pix",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def project_pix(fxfy, p_view, center, eps=1e-6):\n    fx, fy = fxfy\n    cx, cy = center\n    rw = 1.0 / (p_view[..., 2] + eps)\n    p_proj = (p_view[..., 0] * rw, p_view[..., 1] * rw)\n    u, v = (p_proj[0] * fx + cx, p_proj[1] * fy + cy)\n    return torch.stack([u, v], dim=-1)\ndef clip_near_plane(p, viewmat, clip_thresh=0.01):\n    R = viewmat[:3, :3]\n    T = viewmat[:3, 3]",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "clip_near_plane",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def clip_near_plane(p, viewmat, clip_thresh=0.01):\n    R = viewmat[:3, :3]\n    T = viewmat[:3, 3]\n    p_view = torch.einsum(\"ij,nj->ni\", R, p) + T[None]\n    return p_view, p_view[..., 2] < clip_thresh\ndef get_tile_bbox(pix_center, pix_radius, tile_bounds, block_width):\n    tile_size = torch.tensor(\n        [block_width, block_width], dtype=torch.float32, device=pix_center.device\n    )\n    tile_center = pix_center / tile_size",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "get_tile_bbox",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def get_tile_bbox(pix_center, pix_radius, tile_bounds, block_width):\n    tile_size = torch.tensor(\n        [block_width, block_width], dtype=torch.float32, device=pix_center.device\n    )\n    tile_center = pix_center / tile_size\n    tile_radius = pix_radius[..., None] / tile_size\n    top_left = (tile_center - tile_radius).to(torch.int32)\n    bottom_right = (tile_center + tile_radius).to(torch.int32) + 1\n    tile_min = torch.stack(\n        [",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "project_gaussians_forward",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def project_gaussians_forward(\n    means3d,\n    scales,\n    glob_scale,\n    quats,\n    viewmat,\n    intrins,\n    img_size,\n    block_width,\n    clip_thresh=0.01,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "map_gaussian_to_intersects",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def map_gaussian_to_intersects(\n    num_points, xys, depths, radii, cum_tiles_hit, tile_bounds, block_width\n):\n    num_intersects = cum_tiles_hit[-1]\n    isect_ids = torch.zeros(num_intersects, dtype=torch.int64, device=xys.device)\n    gaussian_ids = torch.zeros(num_intersects, dtype=torch.int32, device=xys.device)\n    for idx in range(num_points):\n        if radii[idx] <= 0:\n            break\n        tile_min, tile_max = get_tile_bbox(",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "get_tile_bin_edges",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def get_tile_bin_edges(num_intersects, isect_ids_sorted, tile_bounds):\n    tile_bins = torch.zeros(\n        (tile_bounds[0] * tile_bounds[1], 2),\n        dtype=torch.int32,\n        device=isect_ids_sorted.device,\n    )\n    for idx in range(num_intersects):\n        cur_tile_idx = isect_ids_sorted[idx] >> 32\n        if idx == 0:\n            tile_bins[cur_tile_idx, 0] = 0",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "rasterize_forward",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def rasterize_forward(\n    tile_bounds,\n    block,\n    img_size,\n    gaussian_ids_sorted,\n    tile_bins,\n    xys,\n    conics,\n    colors,\n    opacities,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C0",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C0 = 0.28209479177387814\nSH_C1 = 0.4886025119029199\nSH_C2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396,\n]\nSH_C3 = [",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C1",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C1 = 0.4886025119029199\nSH_C2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396,\n]\nSH_C3 = [\n    -0.5900435899266435,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C2",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396,\n]\nSH_C3 = [\n    -0.5900435899266435,\n    2.890611442640554,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C3",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C3 = [\n    -0.5900435899266435,\n    2.890611442640554,\n    -0.4570457994644658,\n    0.3731763325901154,\n    -0.4570457994644658,\n    1.445305721320277,\n    -0.5900435899266435,\n]\nSH_C4 = [",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C4",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C4 = [\n    2.5033429417967046,\n    -1.7701307697799304,\n    0.9461746957575601,\n    -0.6690465435572892,\n    0.10578554691520431,\n    -0.6690465435572892,\n    0.47308734787878004,\n    -1.7701307697799304,\n    0.6258357354491761,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "MAX_SH_BASIS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "MAX_SH_BASIS = 10\ndef eval_sh_bases(basis_dim: int, dirs: torch.Tensor):\n    \"\"\"\n    Evaluate spherical harmonics bases at unit directions,\n    without taking linear combination.\n    At each point, the final result may the be\n    obtained through simple multiplication.\n    :param basis_dim: int SH basis dim. Currently, 1-25 square numbers supported\n    :param dirs: torch.Tensor (..., 3) unit directions\n    :return: torch.Tensor (..., basis_dim)",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "_SphericalHarmonics",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "class _SphericalHarmonics(Function):\n    \"\"\"Compute spherical harmonics\n    Args:\n        degrees_to_use (int): degree of SHs to use (<= total number available).\n        viewdirs (Tensor): viewing directions.\n        coeffs (Tensor): harmonic coefficients.\n    \"\"\"\n    @staticmethod\n    def forward(\n        ctx,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "_RasterizeGaussians",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "class _RasterizeGaussians(Function):\n    \"\"\"Rasterizes 2D gaussians\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        xys: Float[Tensor, \"*batch 2\"],\n        depths: Float[Tensor, \"*batch 1\"],\n        radii: Float[Tensor, \"*batch 1\"],\n        conics: Float[Tensor, \"*batch 3\"],\n        num_tiles_hit: Int[Tensor, \"*batch 1\"],",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "_ProjectGaussians",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "class _ProjectGaussians(Function):\n    \"\"\"Project 3D gaussians to 2D.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means3d: Float[Tensor, \"*batch 3\"],\n        scales: Float[Tensor, \"*batch 3\"],\n        glob_scale: float,\n        quats: Float[Tensor, \"*batch 4\"],\n        viewmat: Float[Tensor, \"4 4\"],",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "map_gaussian_to_intersects",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def map_gaussian_to_intersects(\n    num_points: int,\n    num_intersects: int,\n    xys: Float[Tensor, \"batch 2\"],\n    depths: Float[Tensor, \"batch 1\"],\n    radii: Float[Tensor, \"batch 1\"],\n    cum_tiles_hit: Float[Tensor, \"batch 1\"],\n    tile_bounds: Tuple[int, int, int],\n    block_size: int,\n) -> Tuple[Float[Tensor, \"cum_tiles_hit 1\"], Float[Tensor, \"cum_tiles_hit 1\"]]:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "get_tile_bin_edges",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def get_tile_bin_edges(\n    num_intersects: int,\n    isect_ids_sorted: Int[Tensor, \"num_intersects 1\"],\n    tile_bounds: Tuple[int, int, int],\n) -> Int[Tensor, \"num_intersects 2\"]:\n    \"\"\"Map sorted intersection IDs to tile bins which give the range of unique gaussian IDs belonging to each tile.\n    Expects that intersection IDs are sorted by increasing tile ID.\n    Indexing into tile_bins[tile_idx] returns the range (lower,upper) of gaussian IDs that hit tile_idx.\n    Note:\n        This function is not differentiable to any input.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "compute_cov2d_bounds",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def compute_cov2d_bounds(\n    cov2d: Float[Tensor, \"batch 3\"],\n) -> Tuple[Float[Tensor, \"batch_conics 3\"], Float[Tensor, \"batch_radii 1\"]]:\n    \"\"\"Computes bounds of 2D covariance matrix\n    Args:\n        cov2d (Tensor): input cov2d of size  (batch, 3) of upper triangular 2D covariance values\n    Returns:\n        A tuple of {Tensor, Tensor}:\n        - **conic** (Tensor): conic parameters for 2D gaussian.\n        - **radii** (Tensor): radii of 2D gaussian projections.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "compute_cumulative_intersects",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def compute_cumulative_intersects(\n    num_tiles_hit: Float[Tensor, \"batch 1\"],\n) -> Tuple[int, Float[Tensor, \"batch 1\"]]:\n    \"\"\"Computes cumulative intersections of gaussians. This is useful for creating unique gaussian IDs and for sorting.\n    Note:\n        This function is not differentiable to any input.\n    Args:\n        num_tiles_hit (Tensor): number of intersected tiles per gaussian.\n    Returns:\n        A tuple of {int, Tensor}:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "bin_and_sort_gaussians",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def bin_and_sort_gaussians(\n    num_points: int,\n    num_intersects: int,\n    xys: Float[Tensor, \"batch 2\"],\n    depths: Float[Tensor, \"batch 1\"],\n    radii: Float[Tensor, \"batch 1\"],\n    cum_tiles_hit: Float[Tensor, \"batch 1\"],\n    tile_bounds: Tuple[int, int, int],\n    block_size: int,\n) -> Tuple[",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "spherical_harmonics",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def spherical_harmonics(\n    degrees_to_use: int,\n    viewdirs: Float[Tensor, \"*batch 3\"],\n    coeffs: Float[Tensor, \"*batch D C\"],\n    method: Literal[\"poly\", \"fast\"] = \"fast\",\n) -> Float[Tensor, \"*batch C\"]:\n    \"\"\"Compute spherical harmonics\n    Note:\n        This function is only differentiable to the input coeffs.\n    Args:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "num_sh_bases",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def num_sh_bases(degree: int):\n    if degree == 0:\n        return 1\n    if degree == 1:\n        return 4\n    if degree == 2:\n        return 9\n    if degree == 3:\n        return 16\n    return 25",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "deg_from_sh",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def deg_from_sh(num_bases: int):\n    if num_bases == 1:\n        return 0\n    if num_bases == 4:\n        return 1\n    if num_bases == 9:\n        return 2\n    if num_bases == 16:\n        return 3\n    if num_bases == 25:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "rasterize_gaussians",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def rasterize_gaussians(\n    xys: Float[Tensor, \"*batch 2\"],\n    depths: Float[Tensor, \"*batch 1\"],\n    radii: Float[Tensor, \"*batch 1\"],\n    conics: Float[Tensor, \"*batch 3\"],\n    num_tiles_hit: Int[Tensor, \"*batch 1\"],\n    colors: Float[Tensor, \"*batch channels\"],\n    opacity: Float[Tensor, \"*batch 1\"],\n    img_height: int,\n    img_width: int,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "project_gaussians",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def project_gaussians(\n    means3d: Float[Tensor, \"*batch 3\"],\n    scales: Float[Tensor, \"*batch 3\"],\n    glob_scale: float,\n    quats: Float[Tensor, \"*batch 4\"],\n    viewmat: Float[Tensor, \"4 4\"],\n    fx: float,\n    fy: float,\n    cx: float,\n    cy: float,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.base",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.base",
        "peekOfCode": "class Strategy:\n    \"\"\"Base class for the GS densification strategy.\n    This class is an base class that defines the interface for the GS\n    densification strategy.\n    \"\"\"\n    def check_sanity(\n        self,\n        params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n        optimizers: Dict[str, torch.optim.Optimizer],\n    ):",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.base",
        "documentation": {}
    },
    {
        "label": "DefaultStrategy",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.default",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.default",
        "peekOfCode": "class DefaultStrategy(Strategy):\n    \"\"\"A default strategy that follows the original 3DGS paper:\n    `3D Gaussian Splatting for Real-Time Radiance Field Rendering <https://arxiv.org/abs/2308.04079>`_\n    The strategy will:\n    - Periodically duplicate GSs with high image plane gradients and small scales.\n    - Periodically split GSs with high image plane gradients and large scales.\n    - Periodically prune GSs with low opacity.\n    - Periodically reset GSs to a lower opacity.\n    If `absgrad=True`, it will use the absolute gradients instead of average gradients\n    for GS duplicating & splitting, following the AbsGS paper:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.default",
        "documentation": {}
    },
    {
        "label": "MCMCStrategy",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.mcmc",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.mcmc",
        "peekOfCode": "class MCMCStrategy(Strategy):\n    \"\"\"Strategy that follows the paper:\n    `3D Gaussian Splatting as Markov Chain Monte Carlo <https://arxiv.org/abs/2404.09591>`_\n    This strategy will:\n    - Periodically teleport GSs with low opacity to a place that has high opacity.\n    - Periodically introduce new GSs sampled based on the opacity distribution.\n    - Periodically perturb the GSs locations.\n    Args:\n        cap_max (int): Maximum number of GSs. Default to 1_000_000.\n        noise_lr (float): MCMC samping noise learning rate. Default to 5e5.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.mcmc",
        "documentation": {}
    },
    {
        "label": "duplicate",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "peekOfCode": "def duplicate(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n):\n    \"\"\"Inplace duplicate the Gaussian with the given mask.\n    Args:\n        params: A dictionary of parameters.\n        optimizers: A dictionary of optimizers, each corresponding to a parameter.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "split",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "peekOfCode": "def split(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n    revised_opacity: bool = False,\n):\n    \"\"\"Inplace split the Gaussian with the given mask.\n    Args:\n        params: A dictionary of parameters.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "remove",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "peekOfCode": "def remove(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n):\n    \"\"\"Inplace remove the Gaussian with the given mask.\n    Args:\n        params: A dictionary of parameters.\n        optimizers: A dictionary of optimizers, each corresponding to a parameter.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "reset_opa",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "peekOfCode": "def reset_opa(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    value: float,\n):\n    \"\"\"Inplace reset the opacities to the given post-sigmoid value.\n    Args:\n        params: A dictionary of parameters.\n        optimizers: A dictionary of optimizers, each corresponding to a parameter.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "relocate",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "peekOfCode": "def relocate(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n    binoms: Tensor,\n    min_opacity: float = 0.005,\n):\n    \"\"\"Inplace relocate some dead Gaussians to the lives ones.\n    Args:",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "sample_add",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "peekOfCode": "def sample_add(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    n: int,\n    binoms: Tensor,\n    min_opacity: float = 0.005,\n):\n    opacities = torch.sigmoid(params[\"opacities\"])\n    eps = torch.finfo(torch.float32).eps",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "inject_noise_to_position",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "peekOfCode": "def inject_noise_to_position(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    scaler: float,\n):\n    opacities = torch.sigmoid(params[\"opacities\"])\n    scales = torch.exp(params[\"scales\"])\n    covars, _ = quat_scale_to_covar_preci(\n        params[\"quats\"],",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "load_test_data",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat._helper",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat._helper",
        "peekOfCode": "def load_test_data(\n    data_path: Optional[str] = None,\n    device=\"cuda\",\n    scene_crop: Tuple[float, float, float, float, float, float] = (-2, -2, -2, 2, 2, 2),\n    scene_grid: int = 1,\n):\n    \"\"\"Load the test data.\"\"\"\n    assert scene_grid % 2 == 1, \"scene_grid must be odd\"\n    if data_path is None:\n        data_path = os.path.join(os.path.dirname(__file__), \"../assets/test_garden.npz\")",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat._helper",
        "documentation": {}
    },
    {
        "label": "all_gather_int32",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "peekOfCode": "def all_gather_int32(\n    world_size: int, value: Union[int, Tensor], device: Optional[torch.device] = None\n) -> List[int]:\n    \"\"\"Gather an 32-bit integer from all ranks.\n    .. note::\n        This implementation is faster than using `torch.distributed.all_gather_object`.\n    .. note::\n        This function is not differentiable to the input tensor.\n    Args:\n        world_size: The total number of ranks.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_to_all_int32",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "peekOfCode": "def all_to_all_int32(\n    world_size: int,\n    values: List[Union[int, Tensor]],\n    device: Optional[torch.device] = None,\n) -> List[int]:\n    \"\"\"Exchange 32-bit integers between all ranks in a many-to-many fashion.\n    .. note::\n        This function is not differentiable to the input tensors.\n    Args:\n        world_size: The total number of ranks.",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_gather_tensor_list",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "peekOfCode": "def all_gather_tensor_list(world_size: int, tensor_list: List[Tensor]) -> List[Tensor]:\n    \"\"\"Gather a list of tensors from all ranks.\n    .. note::\n        This function expects the tensors in the `tensor_list` to have the same shape\n        and data type across all ranks.\n    .. note::\n        This function is differentiable to the tensors in `tensor_list`.\n    .. note::\n        For efficiency, this function internally concatenates the tensors in `tensor_list`\n        and performs a single gather operation. Thus it requires all tensors in the list",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_to_all_tensor_list",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "peekOfCode": "def all_to_all_tensor_list(\n    world_size: int,\n    tensor_list: List[Tensor],\n    splits: List[Union[int, Tensor]],\n    output_splits: Optional[List[Union[int, Tensor]]] = None,\n) -> List[Tensor]:\n    \"\"\"Split and exchange tensors between all ranks in a many-to-many fashion.\n    Args:\n        world_size: The total number of ranks.\n        tensor_list: A list of tensors to split and exchange. The size of the first",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "peekOfCode": "def cli(fn: Callable, args: Any, verbose: bool = False) -> bool:\n    \"\"\"Wrapper to run a function in a distributed environment.\n    The function `fn` should have the following signature:\n    ```python\n    def fn(local_rank: int, world_rank: int, world_size: int, args: Any) -> None:\n        pass\n    ```\n    Usage:\n    ```python\n    # Launch with \"CUDA_VISIBLE_DEVICES=0,1,2,3 python my_script.py\"",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "timeit",
        "kind": 6,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.profile",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.profile",
        "peekOfCode": "class timeit(object):\n    \"\"\"Profiler that is controled by the TIMEIT environment variable.\n    If TIMEIT is set to 1, the profiler will measure the time taken by the decorated function.\n    Usage:\n    ```python\n    @timeit()\n    def my_function():\n        pass\n    # Or\n    with timeit(name=\"stage1\"):",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.profile",
        "documentation": {}
    },
    {
        "label": "profiler",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.profile",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.profile",
        "peekOfCode": "profiler = {}\nclass timeit(object):\n    \"\"\"Profiler that is controled by the TIMEIT environment variable.\n    If TIMEIT is set to 1, the profiler will measure the time taken by the decorated function.\n    Usage:\n    ```python\n    @timeit()\n    def my_function():\n        pass\n    # Or",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.profile",
        "documentation": {}
    },
    {
        "label": "compute_relocation",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.relocation",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.relocation",
        "peekOfCode": "def compute_relocation(\n    opacities: Tensor,  # [N]\n    scales: Tensor,  # [N, 3]\n    ratios: Tensor,  # [N]\n    binoms: Tensor,  # [n_max, n_max]\n) -> Tuple[Tensor, Tensor]:\n    \"\"\"Compute new Gaussians from a set of old Gaussians.\n    This function interprets the Gaussians as samples from a likelihood distribution.\n    It uses the old opacities and scales to compute the new opacities and scales.\n    This is an implementation of the paper",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.relocation",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "peekOfCode": "def rasterization(\n    means: Tensor,  # [N, 3]\n    quats: Tensor,  # [N, 4]\n    scales: Tensor,  # [N, 3]\n    opacities: Tensor,  # [N]\n    colors: Tensor,  # [(C,) N, D] or [(C,) N, K, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "rasterization_legacy_wrapper",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "peekOfCode": "def rasterization_legacy_wrapper(\n    means: Tensor,  # [N, 3]\n    quats: Tensor,  # [N, 4]\n    scales: Tensor,  # [N, 3]\n    opacities: Tensor,  # [N]\n    colors: Tensor,  # [N, D] or [N, K, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "rasterization_inria_wrapper",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "peekOfCode": "def rasterization_inria_wrapper(\n    means: Tensor,  # [N, 3]\n    quats: Tensor,  # [N, 4]\n    scales: Tensor,  # [N, 3]\n    opacities: Tensor,  # [N]\n    colors: Tensor,  # [N, D] or [N, K, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "normalized_quat_to_rotmat",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "peekOfCode": "def normalized_quat_to_rotmat(quat: Tensor) -> Tensor:\n    \"\"\"Convert normalized quaternion to rotation matrix.\n    Args:\n        quat: Normalized quaternion in wxyz convension. (..., 4)\n    Returns:\n        Rotation matrix (..., 3, 3)\n    \"\"\"\n    assert quat.shape[-1] == 4, quat.shape\n    w, x, y, z = torch.unbind(quat, dim=-1)\n    mat = torch.stack(",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "documentation": {}
    },
    {
        "label": "log_transform",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "peekOfCode": "def log_transform(x):\n    return torch.sign(x) * torch.log1p(torch.abs(x))\ndef inverse_log_transform(y):\n    return torch.sign(y) * (torch.expm1(torch.abs(y)))",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "documentation": {}
    },
    {
        "label": "inverse_log_transform",
        "kind": 2,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "peekOfCode": "def inverse_log_transform(y):\n    return torch.sign(y) * (torch.expm1(torch.abs(y)))",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.version",
        "description": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.version",
        "peekOfCode": "__version__ = \"1.2.0\"",
        "detail": "thirdparty.gsplat.build.lib.linux-x86_64-cpython-310.gsplat.version",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "__version__ = None\nexec(open(\"../../gsplat/version.py\", \"r\").read())\n# -- Project information\nproject = \"gsplat\"\ncopyright = \"2023, nerfstudio team\"\nauthor = \"nerfstudio\"\n# Formatting!\n#     0.1.30 => v0.1.30\n#     dev => dev\nif not __version__.isalpha():",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "project = \"gsplat\"\ncopyright = \"2023, nerfstudio team\"\nauthor = \"nerfstudio\"\n# Formatting!\n#     0.1.30 => v0.1.30\n#     dev => dev\nif not __version__.isalpha():\n    __version__ = \"v\" + __version__\nversion = __version__\ndel __version__",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "copyright = \"2023, nerfstudio team\"\nauthor = \"nerfstudio\"\n# Formatting!\n#     0.1.30 => v0.1.30\n#     dev => dev\nif not __version__.isalpha():\n    __version__ = \"v\" + __version__\nversion = __version__\ndel __version__\n# The full version, including alpha/beta/rc tags",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "author",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "author = \"nerfstudio\"\n# Formatting!\n#     0.1.30 => v0.1.30\n#     dev => dev\nif not __version__.isalpha():\n    __version__ = \"v\" + __version__\nversion = __version__\ndel __version__\n# The full version, including alpha/beta/rc tags\nrelease = \"\"",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "version = __version__\ndel __version__\n# The full version, including alpha/beta/rc tags\nrelease = \"\"\n# -- General configuration\nextensions = [\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.duration\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.autodoc\",",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "release",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "release = \"\"\n# -- General configuration\nextensions = [\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.duration\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosummary\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinxcontrib.bibtex\",",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "extensions",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "extensions = [\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.duration\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.autosummary\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinxcontrib.bibtex\",\n    \"sphinxcontrib.video\",\n    \"sphinx.ext.viewcode\",",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "intersphinx_mapping",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "intersphinx_mapping = {\n    \"python\": (\"https://docs.python.org/3/\", None),\n    \"sphinx\": (\"https://www.sphinx-doc.org/en/master/\", None),\n}\nintersphinx_disabled_domains = [\"std\"]\ntemplates_path = [\"_templates\"]\n# -- Options for HTML output\nhtml_theme = \"furo\"\nhtml_static_path = [\"assets/\"]\n# Ignore >>> when copying code",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "intersphinx_disabled_domains",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "intersphinx_disabled_domains = [\"std\"]\ntemplates_path = [\"_templates\"]\n# -- Options for HTML output\nhtml_theme = \"furo\"\nhtml_static_path = [\"assets/\"]\n# Ignore >>> when copying code\ncopybutton_prompt_text = r\">>> |\\.\\.\\. \"\ncopybutton_prompt_is_regexp = True\n# -- Options for EPUB output\nepub_show_urls = \"footnote\"",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "templates_path",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "templates_path = [\"_templates\"]\n# -- Options for HTML output\nhtml_theme = \"furo\"\nhtml_static_path = [\"assets/\"]\n# Ignore >>> when copying code\ncopybutton_prompt_text = r\">>> |\\.\\.\\. \"\ncopybutton_prompt_is_regexp = True\n# -- Options for EPUB output\nepub_show_urls = \"footnote\"\n# typehints",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "html_theme = \"furo\"\nhtml_static_path = [\"assets/\"]\n# Ignore >>> when copying code\ncopybutton_prompt_text = r\">>> |\\.\\.\\. \"\ncopybutton_prompt_is_regexp = True\n# -- Options for EPUB output\nepub_show_urls = \"footnote\"\n# typehints\n# autodoc_typehints = \"description\"\n# citations",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "html_static_path",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "html_static_path = [\"assets/\"]\n# Ignore >>> when copying code\ncopybutton_prompt_text = r\">>> |\\.\\.\\. \"\ncopybutton_prompt_is_regexp = True\n# -- Options for EPUB output\nepub_show_urls = \"footnote\"\n# typehints\n# autodoc_typehints = \"description\"\n# citations\nbibtex_bibfiles = [\"references.bib\"]",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "copybutton_prompt_text",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "copybutton_prompt_text = r\">>> |\\.\\.\\. \"\ncopybutton_prompt_is_regexp = True\n# -- Options for EPUB output\nepub_show_urls = \"footnote\"\n# typehints\n# autodoc_typehints = \"description\"\n# citations\nbibtex_bibfiles = [\"references.bib\"]\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "copybutton_prompt_is_regexp",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "copybutton_prompt_is_regexp = True\n# -- Options for EPUB output\nepub_show_urls = \"footnote\"\n# typehints\n# autodoc_typehints = \"description\"\n# citations\nbibtex_bibfiles = [\"references.bib\"]\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\nadd_module_names = False",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "epub_show_urls",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "epub_show_urls = \"footnote\"\n# typehints\n# autodoc_typehints = \"description\"\n# citations\nbibtex_bibfiles = [\"references.bib\"]\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\nadd_module_names = False",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "bibtex_bibfiles",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "bibtex_bibfiles = [\"references.bib\"]\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\nadd_module_names = False",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "add_module_names",
        "kind": 5,
        "importPath": "thirdparty.gsplat.docs.source.conf",
        "description": "thirdparty.gsplat.docs.source.conf",
        "peekOfCode": "add_module_names = False",
        "detail": "thirdparty.gsplat.docs.source.conf",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.benchmarks.compression.summarize_stats",
        "description": "thirdparty.gsplat.examples.benchmarks.compression.summarize_stats",
        "peekOfCode": "def main(results_dir: str, scenes: List[str]):\n    print(\"scenes:\", scenes)\n    stage = \"compress\"\n    summary = defaultdict(list)\n    for scene in scenes:\n        scene_dir = os.path.join(results_dir, scene)\n        if stage == \"compress\":\n            zip_path = f\"{scene_dir}/compression.zip\"\n            if os.path.exists(zip_path):\n                subprocess.run(f\"rm {zip_path}\", shell=True)",
        "detail": "thirdparty.gsplat.examples.benchmarks.compression.summarize_stats",
        "documentation": {}
    },
    {
        "label": "Parser",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.datasets.colmap",
        "description": "thirdparty.gsplat.examples.datasets.colmap",
        "peekOfCode": "class Parser:\n    \"\"\"COLMAP parser.\"\"\"\n    def __init__(\n        self,\n        data_dir: str,\n        factor: int = 1,\n        normalize: bool = False,\n        test_every: int = 8,\n    ):\n        self.data_dir = data_dir",
        "detail": "thirdparty.gsplat.examples.datasets.colmap",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.datasets.colmap",
        "description": "thirdparty.gsplat.examples.datasets.colmap",
        "peekOfCode": "class Dataset:\n    \"\"\"A simple dataset class.\"\"\"\n    def __init__(\n        self,\n        parser: Parser,\n        split: str = \"train\",\n        patch_size: Optional[int] = None,\n        load_depths: bool = False,\n    ):\n        self.parser = parser",
        "detail": "thirdparty.gsplat.examples.datasets.colmap",
        "documentation": {}
    },
    {
        "label": "DownloadData",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.datasets.download_dataset",
        "description": "thirdparty.gsplat.examples.datasets.download_dataset",
        "peekOfCode": "class DownloadData:\n    dataset: dataset_names = \"mipnerf360\"\n    save_dir: Path = Path(os.getcwd() + \"/data\")\n    def main(self):\n        self.save_dir.mkdir(parents=True, exist_ok=True)\n        self.dataset_download(self.dataset)\n    def dataset_download(self, dataset: dataset_names):\n        (self.save_dir / dataset_rename_map[dataset]).mkdir(parents=True, exist_ok=True)\n        file_name = Path(urls[dataset]).name\n        # download",
        "detail": "thirdparty.gsplat.examples.datasets.download_dataset",
        "documentation": {}
    },
    {
        "label": "dataset_names",
        "kind": 5,
        "importPath": "thirdparty.gsplat.examples.datasets.download_dataset",
        "description": "thirdparty.gsplat.examples.datasets.download_dataset",
        "peekOfCode": "dataset_names = Literal[\"mipnerf360\"]\n# dataset urls\nurls = {\"mipnerf360\": \"http://storage.googleapis.com/gresearch/refraw360/360_v2.zip\"}\n# rename maps\ndataset_rename_map = {\"mipnerf360\": \"360_v2\"}\n@dataclass\nclass DownloadData:\n    dataset: dataset_names = \"mipnerf360\"\n    save_dir: Path = Path(os.getcwd() + \"/data\")\n    def main(self):",
        "detail": "thirdparty.gsplat.examples.datasets.download_dataset",
        "documentation": {}
    },
    {
        "label": "urls",
        "kind": 5,
        "importPath": "thirdparty.gsplat.examples.datasets.download_dataset",
        "description": "thirdparty.gsplat.examples.datasets.download_dataset",
        "peekOfCode": "urls = {\"mipnerf360\": \"http://storage.googleapis.com/gresearch/refraw360/360_v2.zip\"}\n# rename maps\ndataset_rename_map = {\"mipnerf360\": \"360_v2\"}\n@dataclass\nclass DownloadData:\n    dataset: dataset_names = \"mipnerf360\"\n    save_dir: Path = Path(os.getcwd() + \"/data\")\n    def main(self):\n        self.save_dir.mkdir(parents=True, exist_ok=True)\n        self.dataset_download(self.dataset)",
        "detail": "thirdparty.gsplat.examples.datasets.download_dataset",
        "documentation": {}
    },
    {
        "label": "dataset_rename_map",
        "kind": 5,
        "importPath": "thirdparty.gsplat.examples.datasets.download_dataset",
        "description": "thirdparty.gsplat.examples.datasets.download_dataset",
        "peekOfCode": "dataset_rename_map = {\"mipnerf360\": \"360_v2\"}\n@dataclass\nclass DownloadData:\n    dataset: dataset_names = \"mipnerf360\"\n    save_dir: Path = Path(os.getcwd() + \"/data\")\n    def main(self):\n        self.save_dir.mkdir(parents=True, exist_ok=True)\n        self.dataset_download(self.dataset)\n    def dataset_download(self, dataset: dataset_names):\n        (self.save_dir / dataset_rename_map[dataset]).mkdir(parents=True, exist_ok=True)",
        "detail": "thirdparty.gsplat.examples.datasets.download_dataset",
        "documentation": {}
    },
    {
        "label": "similarity_from_cameras",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.normalize",
        "description": "thirdparty.gsplat.examples.datasets.normalize",
        "peekOfCode": "def similarity_from_cameras(c2w, strict_scaling=False, center_method=\"focus\"):\n    \"\"\"\n    reference: nerf-factory\n    Get a similarity transform to normalize dataset\n    from c2w (OpenCV convention) cameras\n    :param c2w: (N, 4)\n    :return T (4,4) , scale (float)\n    \"\"\"\n    t = c2w[:, :3, 3]\n    R = c2w[:, :3, :3]",
        "detail": "thirdparty.gsplat.examples.datasets.normalize",
        "documentation": {}
    },
    {
        "label": "align_principle_axes",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.normalize",
        "description": "thirdparty.gsplat.examples.datasets.normalize",
        "peekOfCode": "def align_principle_axes(point_cloud):\n    # Compute centroid\n    centroid = np.median(point_cloud, axis=0)\n    # Translate point cloud to centroid\n    translated_point_cloud = point_cloud - centroid\n    # Compute covariance matrix\n    covariance_matrix = np.cov(translated_point_cloud, rowvar=False)\n    # Compute eigenvectors and eigenvalues\n    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n    # Sort eigenvectors by eigenvalues (descending order) so that the z-axis",
        "detail": "thirdparty.gsplat.examples.datasets.normalize",
        "documentation": {}
    },
    {
        "label": "transform_points",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.normalize",
        "description": "thirdparty.gsplat.examples.datasets.normalize",
        "peekOfCode": "def transform_points(matrix, points):\n    \"\"\"Transform points using an SE(3) matrix.\n    Args:\n        matrix: 4x4 SE(3) matrix\n        points: Nx3 array of points\n    Returns:\n        Nx3 array of transformed points\n    \"\"\"\n    assert matrix.shape == (4, 4)\n    assert len(points.shape) == 2 and points.shape[1] == 3",
        "detail": "thirdparty.gsplat.examples.datasets.normalize",
        "documentation": {}
    },
    {
        "label": "transform_cameras",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.normalize",
        "description": "thirdparty.gsplat.examples.datasets.normalize",
        "peekOfCode": "def transform_cameras(matrix, camtoworlds):\n    \"\"\"Transform cameras using an SE(3) matrix.\n    Args:\n        matrix: 4x4 SE(3) matrix\n        camtoworlds: Nx4x4 array of camera-to-world matrices\n    Returns:\n        Nx4x4 array of transformed camera-to-world matrices\n    \"\"\"\n    assert matrix.shape == (4, 4)\n    assert len(camtoworlds.shape) == 3 and camtoworlds.shape[1:] == (4, 4)",
        "detail": "thirdparty.gsplat.examples.datasets.normalize",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.normalize",
        "description": "thirdparty.gsplat.examples.datasets.normalize",
        "peekOfCode": "def normalize(camtoworlds, points=None):\n    T1 = similarity_from_cameras(camtoworlds)\n    camtoworlds = transform_cameras(T1, camtoworlds)\n    if points is not None:\n        points = transform_points(T1, points)\n        T2 = align_principle_axes(points)\n        camtoworlds = transform_cameras(T2, camtoworlds)\n        points = transform_points(T2, points)\n        return camtoworlds, points, T2 @ T1\n    else:",
        "detail": "thirdparty.gsplat.examples.datasets.normalize",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.traj",
        "description": "thirdparty.gsplat.examples.datasets.traj",
        "peekOfCode": "def normalize(x: np.ndarray) -> np.ndarray:\n    \"\"\"Normalization helper function.\"\"\"\n    return x / np.linalg.norm(x)\ndef viewmatrix(lookdir: np.ndarray, up: np.ndarray, position: np.ndarray) -> np.ndarray:\n    \"\"\"Construct lookat view matrix.\"\"\"\n    vec2 = normalize(lookdir)\n    vec0 = normalize(np.cross(up, vec2))\n    vec1 = normalize(np.cross(vec2, vec0))\n    m = np.stack([vec0, vec1, vec2, position], axis=1)\n    return m",
        "detail": "thirdparty.gsplat.examples.datasets.traj",
        "documentation": {}
    },
    {
        "label": "viewmatrix",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.traj",
        "description": "thirdparty.gsplat.examples.datasets.traj",
        "peekOfCode": "def viewmatrix(lookdir: np.ndarray, up: np.ndarray, position: np.ndarray) -> np.ndarray:\n    \"\"\"Construct lookat view matrix.\"\"\"\n    vec2 = normalize(lookdir)\n    vec0 = normalize(np.cross(up, vec2))\n    vec1 = normalize(np.cross(vec2, vec0))\n    m = np.stack([vec0, vec1, vec2, position], axis=1)\n    return m\ndef focus_point_fn(poses: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate nearest point to all focal axes in poses.\"\"\"\n    directions, origins = poses[:, :3, 2:3], poses[:, :3, 3:4]",
        "detail": "thirdparty.gsplat.examples.datasets.traj",
        "documentation": {}
    },
    {
        "label": "focus_point_fn",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.traj",
        "description": "thirdparty.gsplat.examples.datasets.traj",
        "peekOfCode": "def focus_point_fn(poses: np.ndarray) -> np.ndarray:\n    \"\"\"Calculate nearest point to all focal axes in poses.\"\"\"\n    directions, origins = poses[:, :3, 2:3], poses[:, :3, 3:4]\n    m = np.eye(3) - directions * np.transpose(directions, [0, 2, 1])\n    mt_m = np.transpose(m, [0, 2, 1]) @ m\n    focus_pt = np.linalg.inv(mt_m.mean(0)) @ (mt_m @ origins).mean(0)[:, 0]\n    return focus_pt\ndef generate_ellipse_path_z(\n    poses: np.ndarray,\n    n_frames: int = 120,",
        "detail": "thirdparty.gsplat.examples.datasets.traj",
        "documentation": {}
    },
    {
        "label": "generate_ellipse_path_z",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.traj",
        "description": "thirdparty.gsplat.examples.datasets.traj",
        "peekOfCode": "def generate_ellipse_path_z(\n    poses: np.ndarray,\n    n_frames: int = 120,\n    # const_speed: bool = True,\n    variation: float = 0.0,\n    phase: float = 0.0,\n    height: float = 0.0,\n) -> np.ndarray:\n    \"\"\"Generate an elliptical render path based on the given poses.\"\"\"\n    # Calculate the focal point for the path (cameras point toward this).",
        "detail": "thirdparty.gsplat.examples.datasets.traj",
        "documentation": {}
    },
    {
        "label": "generate_ellipse_path_y",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.traj",
        "description": "thirdparty.gsplat.examples.datasets.traj",
        "peekOfCode": "def generate_ellipse_path_y(\n    poses: np.ndarray,\n    n_frames: int = 120,\n    # const_speed: bool = True,\n    variation: float = 0.0,\n    phase: float = 0.0,\n    height: float = 0.0,\n) -> np.ndarray:\n    \"\"\"Generate an elliptical render path based on the given poses.\"\"\"\n    # Calculate the focal point for the path (cameras point toward this).",
        "detail": "thirdparty.gsplat.examples.datasets.traj",
        "documentation": {}
    },
    {
        "label": "generate_interpolated_path",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.datasets.traj",
        "description": "thirdparty.gsplat.examples.datasets.traj",
        "peekOfCode": "def generate_interpolated_path(\n    poses: np.ndarray,\n    n_interp: int,\n    spline_degree: int = 5,\n    smoothness: float = 0.03,\n    rot_weight: float = 0.1,\n):\n    \"\"\"Creates a smooth spline path between input keyframe camera poses.\n    Spline is calculated with poses in format (position, lookat-point, up-point).\n    Args:",
        "detail": "thirdparty.gsplat.examples.datasets.traj",
        "documentation": {}
    },
    {
        "label": "SimpleTrainer",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.image_fitting",
        "description": "thirdparty.gsplat.examples.image_fitting",
        "peekOfCode": "class SimpleTrainer:\n    \"\"\"Trains random gaussians to fit an image.\"\"\"\n    def __init__(\n        self,\n        gt_image: Tensor,\n        num_points: int = 2000,\n    ):\n        self.device = torch.device(\"cuda:0\")\n        self.gt_image = gt_image.to(device=self.device)\n        self.num_points = num_points",
        "detail": "thirdparty.gsplat.examples.image_fitting",
        "documentation": {}
    },
    {
        "label": "image_path_to_tensor",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.image_fitting",
        "description": "thirdparty.gsplat.examples.image_fitting",
        "peekOfCode": "def image_path_to_tensor(image_path: Path):\n    import torchvision.transforms as transforms\n    img = Image.open(image_path)\n    transform = transforms.ToTensor()\n    img_tensor = transform(img).permute(1, 2, 0)[..., :3]\n    return img_tensor\ndef main(\n    height: int = 256,\n    width: int = 256,\n    num_points: int = 100000,",
        "detail": "thirdparty.gsplat.examples.image_fitting",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.image_fitting",
        "description": "thirdparty.gsplat.examples.image_fitting",
        "peekOfCode": "def main(\n    height: int = 256,\n    width: int = 256,\n    num_points: int = 100000,\n    save_imgs: bool = True,\n    img_path: Optional[Path] = None,\n    iterations: int = 1000,\n    lr: float = 0.01,\n) -> None:\n    if img_path:",
        "detail": "thirdparty.gsplat.examples.image_fitting",
        "documentation": {}
    },
    {
        "label": "Config",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.simple_trainer",
        "description": "thirdparty.gsplat.examples.simple_trainer",
        "peekOfCode": "class Config:\n    # Disable viewer\n    disable_viewer: bool = False\n    # Path to the .pt file. If provide, it will skip training and render a video\n    ckpt: Optional[str] = None\n    # Name of compression strategy to use\n    compression: Optional[Literal[\"png\"]] = None\n    # Path to the Mip-NeRF 360 dataset\n    data_dir: str = \"data/360_v2/garden\"\n    # Downsample factor for the dataset",
        "detail": "thirdparty.gsplat.examples.simple_trainer",
        "documentation": {}
    },
    {
        "label": "Runner",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.simple_trainer",
        "description": "thirdparty.gsplat.examples.simple_trainer",
        "peekOfCode": "class Runner:\n    \"\"\"Engine for training and testing.\"\"\"\n    def __init__(\n        self, local_rank: int, world_rank, world_size: int, cfg: Config\n    ) -> None:\n        set_random_seed(42 + local_rank)\n        self.cfg = cfg\n        self.world_rank = world_rank\n        self.local_rank = local_rank\n        self.world_size = world_size",
        "detail": "thirdparty.gsplat.examples.simple_trainer",
        "documentation": {}
    },
    {
        "label": "create_splats_with_optimizers",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.simple_trainer",
        "description": "thirdparty.gsplat.examples.simple_trainer",
        "peekOfCode": "def create_splats_with_optimizers(\n    parser: Parser,\n    init_type: str = \"sfm\",\n    init_num_pts: int = 100_000,\n    init_extent: float = 3.0,\n    init_opacity: float = 0.1,\n    init_scale: float = 1.0,\n    scene_scale: float = 1.0,\n    sh_degree: int = 3,\n    sparse_grad: bool = False,",
        "detail": "thirdparty.gsplat.examples.simple_trainer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.simple_trainer",
        "description": "thirdparty.gsplat.examples.simple_trainer",
        "peekOfCode": "def main(local_rank: int, world_rank, world_size: int, cfg: Config):\n    if world_size > 1 and not cfg.disable_viewer:\n        cfg.disable_viewer = True\n        if world_rank == 0:\n            print(\"Viewer is disabled in distributed training.\")\n    runner = Runner(local_rank, world_rank, world_size, cfg)\n    if cfg.ckpt is not None:\n        # run eval only\n        ckpt = torch.load(cfg.ckpt, map_location=runner.device, weights_only=True)\n        for k in runner.splats.keys():",
        "detail": "thirdparty.gsplat.examples.simple_trainer",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.simple_viewer",
        "description": "thirdparty.gsplat.examples.simple_viewer",
        "peekOfCode": "def main(local_rank: int, world_rank, world_size: int, args):\n    torch.manual_seed(42)\n    device = torch.device(\"cuda\", local_rank)\n    if args.ckpt is None:\n        (\n            means,\n            quats,\n            scales,\n            opacities,\n            colors,",
        "detail": "thirdparty.gsplat.examples.simple_viewer",
        "documentation": {}
    },
    {
        "label": "CameraOptModule",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.utils",
        "description": "thirdparty.gsplat.examples.utils",
        "peekOfCode": "class CameraOptModule(torch.nn.Module):\n    \"\"\"Camera pose optimization module.\"\"\"\n    def __init__(self, n: int):\n        super().__init__()\n        # Delta positions (3D) + Delta rotations (6D)\n        self.embeds = torch.nn.Embedding(n, 9)\n        # Identity rotation in 6D representation\n        self.register_buffer(\"identity\", torch.tensor([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]))\n    def zero_init(self):\n        torch.nn.init.zeros_(self.embeds.weight)",
        "detail": "thirdparty.gsplat.examples.utils",
        "documentation": {}
    },
    {
        "label": "AppearanceOptModule",
        "kind": 6,
        "importPath": "thirdparty.gsplat.examples.utils",
        "description": "thirdparty.gsplat.examples.utils",
        "peekOfCode": "class AppearanceOptModule(torch.nn.Module):\n    \"\"\"Appearance optimization module.\"\"\"\n    def __init__(\n        self,\n        n: int,\n        feature_dim: int,\n        embed_dim: int = 16,\n        sh_degree: int = 3,\n        mlp_width: int = 64,\n        mlp_depth: int = 2,",
        "detail": "thirdparty.gsplat.examples.utils",
        "documentation": {}
    },
    {
        "label": "rotation_6d_to_matrix",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.utils",
        "description": "thirdparty.gsplat.examples.utils",
        "peekOfCode": "def rotation_6d_to_matrix(d6: Tensor) -> Tensor:\n    \"\"\"\n    Converts 6D rotation representation by Zhou et al. [1] to rotation matrix\n    using Gram--Schmidt orthogonalization per Section B of [1]. Adapted from pytorch3d.\n    Args:\n        d6: 6D rotation representation, of size (*, 6)\n    Returns:\n        batch of rotation matrices of size (*, 3, 3)\n    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n    On the Continuity of Rotation Representations in Neural Networks.",
        "detail": "thirdparty.gsplat.examples.utils",
        "documentation": {}
    },
    {
        "label": "knn",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.utils",
        "description": "thirdparty.gsplat.examples.utils",
        "peekOfCode": "def knn(x: Tensor, K: int = 4) -> Tensor:\n    x_np = x.cpu().numpy()\n    model = NearestNeighbors(n_neighbors=K, metric=\"euclidean\").fit(x_np)\n    distances, _ = model.kneighbors(x_np)\n    return torch.from_numpy(distances).to(x)\ndef rgb_to_sh(rgb: Tensor) -> Tensor:\n    C0 = 0.28209479177387814\n    return (rgb - 0.5) / C0\ndef set_random_seed(seed: int):\n    random.seed(seed)",
        "detail": "thirdparty.gsplat.examples.utils",
        "documentation": {}
    },
    {
        "label": "rgb_to_sh",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.utils",
        "description": "thirdparty.gsplat.examples.utils",
        "peekOfCode": "def rgb_to_sh(rgb: Tensor) -> Tensor:\n    C0 = 0.28209479177387814\n    return (rgb - 0.5) / C0\ndef set_random_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)",
        "detail": "thirdparty.gsplat.examples.utils",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "kind": 2,
        "importPath": "thirdparty.gsplat.examples.utils",
        "description": "thirdparty.gsplat.examples.utils",
        "peekOfCode": "def set_random_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)",
        "detail": "thirdparty.gsplat.examples.utils",
        "documentation": {}
    },
    {
        "label": "PngCompression",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.compression.png_compression",
        "description": "thirdparty.gsplat.gsplat.compression.png_compression",
        "peekOfCode": "class PngCompression:\n    \"\"\"Uses quantization and sorting to compress splats into PNG files and uses\n    K-means clustering to compress the spherical harmonic coefficents.\n    .. warning::\n        This class requires the `imageio <https://pypi.org/project/imageio/>`_,\n        `plas <https://github.com/DeMoriarty/TorchPQ?tab=readme-ov-file#install>`_\n        and `torchpq <https://github.com/fraunhoferhhi/PLAS.git>`_ packages to be installed.\n    .. warning::\n        This class might throw away a few lowest opacities splats if the number of\n        splats is not a square number.",
        "detail": "thirdparty.gsplat.gsplat.compression.png_compression",
        "documentation": {}
    },
    {
        "label": "sort_splats",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.compression.sort",
        "description": "thirdparty.gsplat.gsplat.compression.sort",
        "peekOfCode": "def sort_splats(splats: Dict[str, Tensor], verbose: bool = True) -> Dict[str, Tensor]:\n    \"\"\"Sort splats with Parallel Linear Assignment Sorting from the paper `Compact 3D Scene Representation via\n    Self-Organizing Gaussian Grids <https://arxiv.org/pdf/2312.13299>`_.\n    .. warning::\n        PLAS must installed to use sorting.\n    Args:\n        splats (Dict[str, Tensor]): splats\n        verbose (bool, optional): Whether to print verbose information. Default to True.\n    Returns:\n        Dict[str, Tensor]: sorted splats",
        "detail": "thirdparty.gsplat.gsplat.compression.sort",
        "documentation": {}
    },
    {
        "label": "load_extension",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "def load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,\n    extra_include_paths=None,\n    build_directory=None,\n):\n    \"\"\"Load a JIT compiled extension.\"\"\"",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_available",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "def cuda_toolkit_available():\n    \"\"\"Check if the nvcc is avaiable on the machine.\"\"\"\n    try:\n        call([\"nvcc\"], stdout=DEVNULL, stderr=DEVNULL)\n        return True\n    except FileNotFoundError:\n        return False\ndef cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_version",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "def cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")\n    if os.path.exists(os.path.join(cuda_home, \"version.txt\")):\n        with open(os.path.join(cuda_home, \"version.txt\")) as f:\n            cuda_version = f.read().strip().split()[-1]\n    elif os.path.exists(os.path.join(cuda_home, \"version.json\")):\n        with open(os.path.join(cuda_home, \"version.json\")) as f:\n            cuda_version = json.load(f)[\"cuda\"][\"version\"]\n    else:",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "PATH",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "PATH = os.path.dirname(os.path.abspath(__file__))\nNO_FAST_MATH = os.getenv(\"NO_FAST_MATH\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "NO_FAST_MATH",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "NO_FAST_MATH = os.getenv(\"NO_FAST_MATH\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "MAX_JOBS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "MAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "need_to_unset_max_jobs",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "need_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "_C",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "_C = None\ntry:\n    # try to import the compiled module (via setup.py)\n    from gsplat import csrc as _C\nexcept ImportError:\n    # if failed, try with JIT compilation\n    if cuda_toolkit_available():\n        name = \"gsplat_cuda\"\n        build_dir = _get_build_directory(name, verbose=False)\n        current_dir = os.path.dirname(os.path.abspath(__file__))",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda._backend",
        "description": "thirdparty.gsplat.gsplat.cuda._backend",
        "peekOfCode": "__all__ = [\"_C\"]",
        "detail": "thirdparty.gsplat.gsplat.cuda._backend",
        "documentation": {}
    },
    {
        "label": "accumulate",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda._torch_impl",
        "peekOfCode": "def accumulate(\n    means2d: Tensor,  # [C, N, 2]\n    conics: Tensor,  # [C, N, 3]\n    opacities: Tensor,  # [C, N]\n    colors: Tensor,  # [C, N, channels]\n    gaussian_ids: Tensor,  # [M]\n    pixel_ids: Tensor,  # [M]\n    camera_ids: Tensor,  # [M]\n    image_width: int,\n    image_height: int,",
        "detail": "thirdparty.gsplat.gsplat.cuda._torch_impl",
        "documentation": {}
    },
    {
        "label": "_QuatScaleToCovarPreci",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "class _QuatScaleToCovarPreci(torch.autograd.Function):\n    \"\"\"Converts quaternions and scales to covariance and precision matrices.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        quats: Tensor,  # [N, 4],\n        scales: Tensor,  # [N, 3],\n        compute_covar: bool = True,\n        compute_preci: bool = True,\n        triu: bool = False,",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_Proj",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "class _Proj(torch.autograd.Function):\n    \"\"\"Perspective fully_fused_projection on Gaussians.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [C, N, 3]\n        covars: Tensor,  # [C, N, 3, 3]\n        Ks: Tensor,  # [C, 3, 3]\n        width: int,\n        height: int,",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_WorldToCam",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "class _WorldToCam(torch.autograd.Function):\n    \"\"\"Transforms Gaussians from world to camera space.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [N, 3]\n        covars: Tensor,  # [N, 3, 3]\n        viewmats: Tensor,  # [C, 4, 4]\n    ) -> Tuple[Tensor, Tensor]:\n        means_c, covars_c = _make_lazy_cuda_func(\"world_to_cam_fwd\")(",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_FullyFusedProjection",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "class _FullyFusedProjection(torch.autograd.Function):\n    \"\"\"Projects Gaussians to 2D.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [N, 3]\n        covars: Tensor,  # [N, 6] or None\n        quats: Tensor,  # [N, 4] or None\n        scales: Tensor,  # [N, 3] or None\n        viewmats: Tensor,  # [C, 4, 4]",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_RasterizeToPixels",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "class _RasterizeToPixels(torch.autograd.Function):\n    \"\"\"Rasterize gaussians\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means2d: Tensor,  # [C, N, 2]\n        conics: Tensor,  # [C, N, 3]\n        colors: Tensor,  # [C, N, D]\n        opacities: Tensor,  # [C, N]\n        backgrounds: Tensor,  # [C, D], Optional",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_FullyFusedProjectionPacked",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "class _FullyFusedProjectionPacked(torch.autograd.Function):\n    \"\"\"Projects Gaussians to 2D. Return packed tensors.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means: Tensor,  # [N, 3]\n        covars: Tensor,  # [N, 6] or None\n        quats: Tensor,  # [N, 4] or None\n        scales: Tensor,  # [N, 3] or None\n        viewmats: Tensor,  # [C, 4, 4]",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "_SphericalHarmonics",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "class _SphericalHarmonics(torch.autograd.Function):\n    \"\"\"Spherical Harmonics\"\"\"\n    @staticmethod\n    def forward(\n        ctx, sh_degree: int, dirs: Tensor, coeffs: Tensor, masks: Tensor\n    ) -> Tensor:\n        colors = _make_lazy_cuda_func(\"compute_sh_fwd\")(sh_degree, dirs, coeffs, masks)\n        ctx.save_for_backward(dirs, coeffs, masks)\n        ctx.sh_degree = sh_degree\n        ctx.num_bases = coeffs.shape[-2]",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "spherical_harmonics",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def spherical_harmonics(\n    degrees_to_use: int,\n    dirs: Tensor,  # [..., 3]\n    coeffs: Tensor,  # [..., K, 3]\n    masks: Optional[Tensor] = None,\n) -> Tensor:\n    \"\"\"Computes spherical harmonics.\n    Args:\n        degrees_to_use: The degree to be used.\n        dirs: Directions. [..., 3]",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "quat_scale_to_covar_preci",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def quat_scale_to_covar_preci(\n    quats: Tensor,  # [N, 4],\n    scales: Tensor,  # [N, 3],\n    compute_covar: bool = True,\n    compute_preci: bool = True,\n    triu: bool = False,\n) -> Tuple[Optional[Tensor], Optional[Tensor]]:\n    \"\"\"Converts quaternions and scales to covariance and precision matrices.\n    Args:\n        quats: Quaternions (No need to be normalized). [N, 4]",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "persp_proj",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def persp_proj(\n    means: Tensor,  # [C, N, 3]\n    covars: Tensor,  # [C, N, 3, 3]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,\n) -> Tuple[Tensor, Tensor]:\n    \"\"\"Perspective projection on Gaussians.\n    DEPRECATED: please use `proj` with `ortho=False` instead.\n    Args:",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "proj",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def proj(\n    means: Tensor,  # [C, N, 3]\n    covars: Tensor,  # [C, N, 3, 3]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,\n    ortho: bool,\n) -> Tuple[Tensor, Tensor]:\n    \"\"\"Projection of Gaussians (perspective or orthographic).\n    Args:",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "world_to_cam",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def world_to_cam(\n    means: Tensor,  # [N, 3]\n    covars: Tensor,  # [N, 3, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n) -> Tuple[Tensor, Tensor]:\n    \"\"\"Transforms Gaussians from world to camera coordinate system.\n    Args:\n        means: Gaussian means. [N, 3]\n        covars: Gaussian covariances. [N, 3, 3]\n        viewmats: World-to-camera transformation matrices. [C, 4, 4]",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "fully_fused_projection",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def fully_fused_projection(\n    means: Tensor,  # [N, 3]\n    covars: Optional[Tensor],  # [N, 6] or None\n    quats: Optional[Tensor],  # [N, 4] or None\n    scales: Optional[Tensor],  # [N, 3] or None\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,\n    eps2d: float = 0.3,",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "isect_tiles",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def isect_tiles(\n    means2d: Tensor,  # [C, N, 2] or [nnz, 2]\n    radii: Tensor,  # [C, N] or [nnz]\n    depths: Tensor,  # [C, N] or [nnz]\n    tile_size: int,\n    tile_width: int,\n    tile_height: int,\n    sort: bool = True,\n    packed: bool = False,\n    n_cameras: Optional[int] = None,",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "isect_offset_encode",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def isect_offset_encode(\n    isect_ids: Tensor, n_cameras: int, tile_width: int, tile_height: int\n) -> Tensor:\n    \"\"\"Encodes intersection ids to offsets.\n    Args:\n        isect_ids: Intersection ids. [n_isects]\n        n_cameras: Number of cameras.\n        tile_width: Tile width.\n        tile_height: Tile height.\n    Returns:",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "rasterize_to_pixels",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def rasterize_to_pixels(\n    means2d: Tensor,  # [C, N, 2] or [nnz, 2]\n    conics: Tensor,  # [C, N, 3] or [nnz, 3]\n    colors: Tensor,  # [C, N, channels] or [nnz, channels]\n    opacities: Tensor,  # [C, N] or [nnz]\n    image_width: int,\n    image_height: int,\n    tile_size: int,\n    isect_offsets: Tensor,  # [C, tile_height, tile_width]\n    flatten_ids: Tensor,  # [n_isects]",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "rasterize_to_indices_in_range",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "peekOfCode": "def rasterize_to_indices_in_range(\n    range_start: int,\n    range_end: int,\n    transmittances: Tensor,  # [C, image_height, image_width]\n    means2d: Tensor,  # [C, N, 2]\n    conics: Tensor,  # [C, N, 3]\n    opacities: Tensor,  # [C, N]\n    image_width: int,\n    image_height: int,\n    tile_size: int,",
        "detail": "thirdparty.gsplat.gsplat.cuda._wrapper",
        "documentation": {}
    },
    {
        "label": "load_extension",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "def load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,\n    extra_include_paths=None,\n    build_directory=None,\n):\n    \"\"\"Load a JIT compiled extension.\"\"\"",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_available",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "def cuda_toolkit_available():\n    \"\"\"Check if the nvcc is avaiable on the machine.\"\"\"\n    try:\n        call([\"nvcc\"], stdout=DEVNULL, stderr=DEVNULL)\n        return True\n    except FileNotFoundError:\n        return False\ndef cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "cuda_toolkit_version",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "def cuda_toolkit_version():\n    \"\"\"Get the cuda toolkit version.\"\"\"\n    cuda_home = os.path.join(os.path.dirname(shutil.which(\"nvcc\")), \"..\")\n    if os.path.exists(os.path.join(cuda_home, \"version.txt\")):\n        with open(os.path.join(cuda_home, \"version.txt\")) as f:\n            cuda_version = f.read().strip().split()[-1]\n    elif os.path.exists(os.path.join(cuda_home, \"version.json\")):\n        with open(os.path.join(cuda_home, \"version.json\")) as f:\n            cuda_version = json.load(f)[\"cuda\"][\"version\"]\n    else:",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "PATH",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "PATH = os.path.dirname(os.path.abspath(__file__))\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "MAX_JOBS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "MAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "need_to_unset_max_jobs",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "need_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\ndef load_extension(\n    name,\n    sources,\n    extra_cflags=None,\n    extra_cuda_cflags=None,\n    extra_ldflags=None,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "_C",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "_C = None\ntry:\n    # try to import the compiled module (via setup.py)\n    from gsplat import csrc_legacy as _C\nexcept ImportError:\n    # if failed, try with JIT compilation\n    if cuda_toolkit_available():\n        name = \"gsplat_cuda_legacy\"\n        build_dir = _get_build_directory(name, verbose=False)\n        current_dir = os.path.dirname(os.path.abspath(__file__))",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "peekOfCode": "__all__ = [\"_C\"]",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._backend",
        "documentation": {}
    },
    {
        "label": "compute_sh_color",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def compute_sh_color(\n    viewdirs: Float[Tensor, \"*batch 3\"],\n    sh_coeffs: Float[Tensor, \"*batch D C\"],\n    method: Literal[\"poly\", \"fast\"] = \"fast\",\n):\n    \"\"\"\n    :param viewdirs (*, C)\n    :param sh_coeffs (*, D, C) sh coefficients for each color channel\n    return colors (*, C)\n    \"\"\"",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "eval_sh_bases",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def eval_sh_bases(basis_dim: int, dirs: torch.Tensor):\n    \"\"\"\n    Evaluate spherical harmonics bases at unit directions,\n    without taking linear combination.\n    At each point, the final result may the be\n    obtained through simple multiplication.\n    :param basis_dim: int SH basis dim. Currently, 1-25 square numbers supported\n    :param dirs: torch.Tensor (..., 3) unit directions\n    :return: torch.Tensor (..., basis_dim)\n    \"\"\"",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "eval_sh_bases_fast",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def eval_sh_bases_fast(basis_dim: int, dirs: torch.Tensor):\n    \"\"\"\n    Evaluate spherical harmonics bases at unit direction for high orders\n    using approach described by\n    Efficient Spherical Harmonic Evaluation, Peter-Pike Sloan, JCGT 2013\n    https://jcgt.org/published/0002/02/06/\n    :param basis_dim: int SH basis dim. Currently, only 1-25 square numbers supported\n    :param dirs: torch.Tensor (..., 3) unit directions\n    :return: torch.Tensor (..., basis_dim)\n    See reference C++ code in https://jcgt.org/published/0002/02/06/code.zip",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "normalized_quat_to_rotmat",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def normalized_quat_to_rotmat(quat: Tensor) -> Tensor:\n    assert quat.shape[-1] == 4, quat.shape\n    w, x, y, z = torch.unbind(quat, dim=-1)\n    mat = torch.stack(\n        [\n            1 - 2 * (y**2 + z**2),\n            2 * (x * y - w * z),\n            2 * (x * z + w * y),\n            2 * (x * y + w * z),\n            1 - 2 * (x**2 + z**2),",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "quat_to_rotmat",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def quat_to_rotmat(quat: Tensor) -> Tensor:\n    assert quat.shape[-1] == 4, quat.shape\n    return normalized_quat_to_rotmat(F.normalize(quat, dim=-1))\ndef scale_rot_to_cov3d(scale: Tensor, glob_scale: float, quat: Tensor) -> Tensor:\n    assert scale.shape[-1] == 3, scale.shape\n    assert quat.shape[-1] == 4, quat.shape\n    assert scale.shape[:-1] == quat.shape[:-1], (scale.shape, quat.shape)\n    R = normalized_quat_to_rotmat(quat)  # (..., 3, 3)\n    M = R * glob_scale * scale[..., None, :]  # (..., 3, 3)\n    # TODO: save upper right because symmetric",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "scale_rot_to_cov3d",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def scale_rot_to_cov3d(scale: Tensor, glob_scale: float, quat: Tensor) -> Tensor:\n    assert scale.shape[-1] == 3, scale.shape\n    assert quat.shape[-1] == 4, quat.shape\n    assert scale.shape[:-1] == quat.shape[:-1], (scale.shape, quat.shape)\n    R = normalized_quat_to_rotmat(quat)  # (..., 3, 3)\n    M = R * glob_scale * scale[..., None, :]  # (..., 3, 3)\n    # TODO: save upper right because symmetric\n    return M @ M.transpose(-1, -2)  # (..., 3, 3)\ndef project_cov3d_ewa(\n    mean3d: Tensor,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "project_cov3d_ewa",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def project_cov3d_ewa(\n    mean3d: Tensor,\n    cov3d: Tensor,\n    viewmat: Tensor,\n    fx: float,\n    fy: float,\n    tan_fovx: float,\n    tan_fovy: float,\n    is_valid: Optional[Tensor] = None,\n) -> Tuple[Tensor, Tensor]:",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "compute_compensation",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def compute_compensation(cov2d_mat: Tensor):\n    \"\"\"\n    params: cov2d matrix (*, 2, 2)\n    returns: compensation factor as calculated in project_cov3d_ewa\n    \"\"\"\n    det_denom = cov2d_mat[..., 0, 0] * cov2d_mat[..., 1, 1] - cov2d_mat[..., 0, 1] ** 2\n    det_nomin = (cov2d_mat[..., 0, 0] - 0.3) * (cov2d_mat[..., 1, 1] - 0.3) - cov2d_mat[\n        ..., 0, 1\n    ] ** 2\n    return torch.sqrt(torch.clamp(det_nomin / det_denom, min=0))",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "compute_cov2d_bounds",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def compute_cov2d_bounds(cov2d_mat: Tensor, cov_valid: Optional[Tensor] = None):\n    \"\"\"\n    param: cov2d matrix (*, 2, 2)\n    returns: conic parameters (*, 3)\n    \"\"\"\n    det_all = cov2d_mat[..., 0, 0] * cov2d_mat[..., 1, 1] - cov2d_mat[..., 0, 1] ** 2\n    valid = det_all != 0\n    if cov_valid is not None:\n        valid = valid & cov_valid\n    # det = torch.clamp(det, min=eps)",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "project_pix",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def project_pix(fxfy, p_view, center, eps=1e-6):\n    fx, fy = fxfy\n    cx, cy = center\n    rw = 1.0 / (p_view[..., 2] + eps)\n    p_proj = (p_view[..., 0] * rw, p_view[..., 1] * rw)\n    u, v = (p_proj[0] * fx + cx, p_proj[1] * fy + cy)\n    return torch.stack([u, v], dim=-1)\ndef clip_near_plane(p, viewmat, clip_thresh=0.01):\n    R = viewmat[:3, :3]\n    T = viewmat[:3, 3]",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "clip_near_plane",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def clip_near_plane(p, viewmat, clip_thresh=0.01):\n    R = viewmat[:3, :3]\n    T = viewmat[:3, 3]\n    p_view = torch.einsum(\"ij,nj->ni\", R, p) + T[None]\n    return p_view, p_view[..., 2] < clip_thresh\ndef get_tile_bbox(pix_center, pix_radius, tile_bounds, block_width):\n    tile_size = torch.tensor(\n        [block_width, block_width], dtype=torch.float32, device=pix_center.device\n    )\n    tile_center = pix_center / tile_size",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "get_tile_bbox",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def get_tile_bbox(pix_center, pix_radius, tile_bounds, block_width):\n    tile_size = torch.tensor(\n        [block_width, block_width], dtype=torch.float32, device=pix_center.device\n    )\n    tile_center = pix_center / tile_size\n    tile_radius = pix_radius[..., None] / tile_size\n    top_left = (tile_center - tile_radius).to(torch.int32)\n    bottom_right = (tile_center + tile_radius).to(torch.int32) + 1\n    tile_min = torch.stack(\n        [",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "project_gaussians_forward",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def project_gaussians_forward(\n    means3d,\n    scales,\n    glob_scale,\n    quats,\n    viewmat,\n    intrins,\n    img_size,\n    block_width,\n    clip_thresh=0.01,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "map_gaussian_to_intersects",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def map_gaussian_to_intersects(\n    num_points, xys, depths, radii, cum_tiles_hit, tile_bounds, block_width\n):\n    num_intersects = cum_tiles_hit[-1]\n    isect_ids = torch.zeros(num_intersects, dtype=torch.int64, device=xys.device)\n    gaussian_ids = torch.zeros(num_intersects, dtype=torch.int32, device=xys.device)\n    for idx in range(num_points):\n        if radii[idx] <= 0:\n            break\n        tile_min, tile_max = get_tile_bbox(",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "get_tile_bin_edges",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def get_tile_bin_edges(num_intersects, isect_ids_sorted, tile_bounds):\n    tile_bins = torch.zeros(\n        (tile_bounds[0] * tile_bounds[1], 2),\n        dtype=torch.int32,\n        device=isect_ids_sorted.device,\n    )\n    for idx in range(num_intersects):\n        cur_tile_idx = isect_ids_sorted[idx] >> 32\n        if idx == 0:\n            tile_bins[cur_tile_idx, 0] = 0",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "rasterize_forward",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "def rasterize_forward(\n    tile_bounds,\n    block,\n    img_size,\n    gaussian_ids_sorted,\n    tile_bins,\n    xys,\n    conics,\n    colors,\n    opacities,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C0",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C0 = 0.28209479177387814\nSH_C1 = 0.4886025119029199\nSH_C2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396,\n]\nSH_C3 = [",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C1",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C1 = 0.4886025119029199\nSH_C2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396,\n]\nSH_C3 = [\n    -0.5900435899266435,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C2",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C2 = [\n    1.0925484305920792,\n    -1.0925484305920792,\n    0.31539156525252005,\n    -1.0925484305920792,\n    0.5462742152960396,\n]\nSH_C3 = [\n    -0.5900435899266435,\n    2.890611442640554,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C3",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C3 = [\n    -0.5900435899266435,\n    2.890611442640554,\n    -0.4570457994644658,\n    0.3731763325901154,\n    -0.4570457994644658,\n    1.445305721320277,\n    -0.5900435899266435,\n]\nSH_C4 = [",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "SH_C4",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "SH_C4 = [\n    2.5033429417967046,\n    -1.7701307697799304,\n    0.9461746957575601,\n    -0.6690465435572892,\n    0.10578554691520431,\n    -0.6690465435572892,\n    0.47308734787878004,\n    -1.7701307697799304,\n    0.6258357354491761,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "MAX_SH_BASIS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "peekOfCode": "MAX_SH_BASIS = 10\ndef eval_sh_bases(basis_dim: int, dirs: torch.Tensor):\n    \"\"\"\n    Evaluate spherical harmonics bases at unit directions,\n    without taking linear combination.\n    At each point, the final result may the be\n    obtained through simple multiplication.\n    :param basis_dim: int SH basis dim. Currently, 1-25 square numbers supported\n    :param dirs: torch.Tensor (..., 3) unit directions\n    :return: torch.Tensor (..., basis_dim)",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._torch_impl",
        "documentation": {}
    },
    {
        "label": "_SphericalHarmonics",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "class _SphericalHarmonics(Function):\n    \"\"\"Compute spherical harmonics\n    Args:\n        degrees_to_use (int): degree of SHs to use (<= total number available).\n        viewdirs (Tensor): viewing directions.\n        coeffs (Tensor): harmonic coefficients.\n    \"\"\"\n    @staticmethod\n    def forward(\n        ctx,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "_RasterizeGaussians",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "class _RasterizeGaussians(Function):\n    \"\"\"Rasterizes 2D gaussians\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        xys: Float[Tensor, \"*batch 2\"],\n        depths: Float[Tensor, \"*batch 1\"],\n        radii: Float[Tensor, \"*batch 1\"],\n        conics: Float[Tensor, \"*batch 3\"],\n        num_tiles_hit: Int[Tensor, \"*batch 1\"],",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "_ProjectGaussians",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "class _ProjectGaussians(Function):\n    \"\"\"Project 3D gaussians to 2D.\"\"\"\n    @staticmethod\n    def forward(\n        ctx,\n        means3d: Float[Tensor, \"*batch 3\"],\n        scales: Float[Tensor, \"*batch 3\"],\n        glob_scale: float,\n        quats: Float[Tensor, \"*batch 4\"],\n        viewmat: Float[Tensor, \"4 4\"],",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "map_gaussian_to_intersects",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def map_gaussian_to_intersects(\n    num_points: int,\n    num_intersects: int,\n    xys: Float[Tensor, \"batch 2\"],\n    depths: Float[Tensor, \"batch 1\"],\n    radii: Float[Tensor, \"batch 1\"],\n    cum_tiles_hit: Float[Tensor, \"batch 1\"],\n    tile_bounds: Tuple[int, int, int],\n    block_size: int,\n) -> Tuple[Float[Tensor, \"cum_tiles_hit 1\"], Float[Tensor, \"cum_tiles_hit 1\"]]:",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "get_tile_bin_edges",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def get_tile_bin_edges(\n    num_intersects: int,\n    isect_ids_sorted: Int[Tensor, \"num_intersects 1\"],\n    tile_bounds: Tuple[int, int, int],\n) -> Int[Tensor, \"num_intersects 2\"]:\n    \"\"\"Map sorted intersection IDs to tile bins which give the range of unique gaussian IDs belonging to each tile.\n    Expects that intersection IDs are sorted by increasing tile ID.\n    Indexing into tile_bins[tile_idx] returns the range (lower,upper) of gaussian IDs that hit tile_idx.\n    Note:\n        This function is not differentiable to any input.",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "compute_cov2d_bounds",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def compute_cov2d_bounds(\n    cov2d: Float[Tensor, \"batch 3\"],\n) -> Tuple[Float[Tensor, \"batch_conics 3\"], Float[Tensor, \"batch_radii 1\"]]:\n    \"\"\"Computes bounds of 2D covariance matrix\n    Args:\n        cov2d (Tensor): input cov2d of size  (batch, 3) of upper triangular 2D covariance values\n    Returns:\n        A tuple of {Tensor, Tensor}:\n        - **conic** (Tensor): conic parameters for 2D gaussian.\n        - **radii** (Tensor): radii of 2D gaussian projections.",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "compute_cumulative_intersects",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def compute_cumulative_intersects(\n    num_tiles_hit: Float[Tensor, \"batch 1\"],\n) -> Tuple[int, Float[Tensor, \"batch 1\"]]:\n    \"\"\"Computes cumulative intersections of gaussians. This is useful for creating unique gaussian IDs and for sorting.\n    Note:\n        This function is not differentiable to any input.\n    Args:\n        num_tiles_hit (Tensor): number of intersected tiles per gaussian.\n    Returns:\n        A tuple of {int, Tensor}:",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "bin_and_sort_gaussians",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def bin_and_sort_gaussians(\n    num_points: int,\n    num_intersects: int,\n    xys: Float[Tensor, \"batch 2\"],\n    depths: Float[Tensor, \"batch 1\"],\n    radii: Float[Tensor, \"batch 1\"],\n    cum_tiles_hit: Float[Tensor, \"batch 1\"],\n    tile_bounds: Tuple[int, int, int],\n    block_size: int,\n) -> Tuple[",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "spherical_harmonics",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def spherical_harmonics(\n    degrees_to_use: int,\n    viewdirs: Float[Tensor, \"*batch 3\"],\n    coeffs: Float[Tensor, \"*batch D C\"],\n    method: Literal[\"poly\", \"fast\"] = \"fast\",\n) -> Float[Tensor, \"*batch C\"]:\n    \"\"\"Compute spherical harmonics\n    Note:\n        This function is only differentiable to the input coeffs.\n    Args:",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "num_sh_bases",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def num_sh_bases(degree: int):\n    if degree == 0:\n        return 1\n    if degree == 1:\n        return 4\n    if degree == 2:\n        return 9\n    if degree == 3:\n        return 16\n    return 25",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "deg_from_sh",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def deg_from_sh(num_bases: int):\n    if num_bases == 1:\n        return 0\n    if num_bases == 4:\n        return 1\n    if num_bases == 9:\n        return 2\n    if num_bases == 16:\n        return 3\n    if num_bases == 25:",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "rasterize_gaussians",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def rasterize_gaussians(\n    xys: Float[Tensor, \"*batch 2\"],\n    depths: Float[Tensor, \"*batch 1\"],\n    radii: Float[Tensor, \"*batch 1\"],\n    conics: Float[Tensor, \"*batch 3\"],\n    num_tiles_hit: Int[Tensor, \"*batch 1\"],\n    colors: Float[Tensor, \"*batch channels\"],\n    opacity: Float[Tensor, \"*batch 1\"],\n    img_height: int,\n    img_width: int,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "project_gaussians",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "description": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "peekOfCode": "def project_gaussians(\n    means3d: Float[Tensor, \"*batch 3\"],\n    scales: Float[Tensor, \"*batch 3\"],\n    glob_scale: float,\n    quats: Float[Tensor, \"*batch 4\"],\n    viewmat: Float[Tensor, \"4 4\"],\n    fx: float,\n    fy: float,\n    cx: float,\n    cy: float,",
        "detail": "thirdparty.gsplat.gsplat.cuda_legacy._wrapper",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.strategy.base",
        "description": "thirdparty.gsplat.gsplat.strategy.base",
        "peekOfCode": "class Strategy:\n    \"\"\"Base class for the GS densification strategy.\n    This class is an base class that defines the interface for the GS\n    densification strategy.\n    \"\"\"\n    def check_sanity(\n        self,\n        params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n        optimizers: Dict[str, torch.optim.Optimizer],\n    ):",
        "detail": "thirdparty.gsplat.gsplat.strategy.base",
        "documentation": {}
    },
    {
        "label": "DefaultStrategy",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.strategy.default",
        "description": "thirdparty.gsplat.gsplat.strategy.default",
        "peekOfCode": "class DefaultStrategy(Strategy):\n    \"\"\"A default strategy that follows the original 3DGS paper:\n    `3D Gaussian Splatting for Real-Time Radiance Field Rendering <https://arxiv.org/abs/2308.04079>`_\n    The strategy will:\n    - Periodically duplicate GSs with high image plane gradients and small scales.\n    - Periodically split GSs with high image plane gradients and large scales.\n    - Periodically prune GSs with low opacity.\n    - Periodically reset GSs to a lower opacity.\n    If `absgrad=True`, it will use the absolute gradients instead of average gradients\n    for GS duplicating & splitting, following the AbsGS paper:",
        "detail": "thirdparty.gsplat.gsplat.strategy.default",
        "documentation": {}
    },
    {
        "label": "MCMCStrategy",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.strategy.mcmc",
        "description": "thirdparty.gsplat.gsplat.strategy.mcmc",
        "peekOfCode": "class MCMCStrategy(Strategy):\n    \"\"\"Strategy that follows the paper:\n    `3D Gaussian Splatting as Markov Chain Monte Carlo <https://arxiv.org/abs/2404.09591>`_\n    This strategy will:\n    - Periodically teleport GSs with low opacity to a place that has high opacity.\n    - Periodically introduce new GSs sampled based on the opacity distribution.\n    - Periodically perturb the GSs locations.\n    Args:\n        cap_max (int): Maximum number of GSs. Default to 1_000_000.\n        noise_lr (float): MCMC samping noise learning rate. Default to 5e5.",
        "detail": "thirdparty.gsplat.gsplat.strategy.mcmc",
        "documentation": {}
    },
    {
        "label": "duplicate",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.gsplat.strategy.ops",
        "peekOfCode": "def duplicate(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n):\n    \"\"\"Inplace duplicate the Gaussian with the given mask.\n    Args:\n        params: A dictionary of parameters.\n        optimizers: A dictionary of optimizers, each corresponding to a parameter.",
        "detail": "thirdparty.gsplat.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "split",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.gsplat.strategy.ops",
        "peekOfCode": "def split(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n    revised_opacity: bool = False,\n):\n    \"\"\"Inplace split the Gaussian with the given mask.\n    Args:\n        params: A dictionary of parameters.",
        "detail": "thirdparty.gsplat.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "remove",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.gsplat.strategy.ops",
        "peekOfCode": "def remove(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n):\n    \"\"\"Inplace remove the Gaussian with the given mask.\n    Args:\n        params: A dictionary of parameters.\n        optimizers: A dictionary of optimizers, each corresponding to a parameter.",
        "detail": "thirdparty.gsplat.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "reset_opa",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.gsplat.strategy.ops",
        "peekOfCode": "def reset_opa(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    value: float,\n):\n    \"\"\"Inplace reset the opacities to the given post-sigmoid value.\n    Args:\n        params: A dictionary of parameters.\n        optimizers: A dictionary of optimizers, each corresponding to a parameter.",
        "detail": "thirdparty.gsplat.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "relocate",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.gsplat.strategy.ops",
        "peekOfCode": "def relocate(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    mask: Tensor,\n    binoms: Tensor,\n    min_opacity: float = 0.005,\n):\n    \"\"\"Inplace relocate some dead Gaussians to the lives ones.\n    Args:",
        "detail": "thirdparty.gsplat.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "sample_add",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.gsplat.strategy.ops",
        "peekOfCode": "def sample_add(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    n: int,\n    binoms: Tensor,\n    min_opacity: float = 0.005,\n):\n    opacities = torch.sigmoid(params[\"opacities\"])\n    eps = torch.finfo(torch.float32).eps",
        "detail": "thirdparty.gsplat.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "inject_noise_to_position",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.strategy.ops",
        "description": "thirdparty.gsplat.gsplat.strategy.ops",
        "peekOfCode": "def inject_noise_to_position(\n    params: Union[Dict[str, torch.nn.Parameter], torch.nn.ParameterDict],\n    optimizers: Dict[str, torch.optim.Optimizer],\n    state: Dict[str, Tensor],\n    scaler: float,\n):\n    opacities = torch.sigmoid(params[\"opacities\"].flatten())\n    scales = torch.exp(params[\"scales\"])\n    covars, _ = quat_scale_to_covar_preci(\n        params[\"quats\"],",
        "detail": "thirdparty.gsplat.gsplat.strategy.ops",
        "documentation": {}
    },
    {
        "label": "load_test_data",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat._helper",
        "description": "thirdparty.gsplat.gsplat._helper",
        "peekOfCode": "def load_test_data(\n    data_path: Optional[str] = None,\n    device=\"cuda\",\n    scene_crop: Tuple[float, float, float, float, float, float] = (-2, -2, -2, 2, 2, 2),\n    scene_grid: int = 1,\n):\n    \"\"\"Load the test data.\"\"\"\n    assert scene_grid % 2 == 1, \"scene_grid must be odd\"\n    if data_path is None:\n        data_path = os.path.join(os.path.dirname(__file__), \"../assets/test_garden.npz\")",
        "detail": "thirdparty.gsplat.gsplat._helper",
        "documentation": {}
    },
    {
        "label": "all_gather_int32",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.distributed",
        "description": "thirdparty.gsplat.gsplat.distributed",
        "peekOfCode": "def all_gather_int32(\n    world_size: int, value: Union[int, Tensor], device: Optional[torch.device] = None\n) -> List[int]:\n    \"\"\"Gather an 32-bit integer from all ranks.\n    .. note::\n        This implementation is faster than using `torch.distributed.all_gather_object`.\n    .. note::\n        This function is not differentiable to the input tensor.\n    Args:\n        world_size: The total number of ranks.",
        "detail": "thirdparty.gsplat.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_to_all_int32",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.distributed",
        "description": "thirdparty.gsplat.gsplat.distributed",
        "peekOfCode": "def all_to_all_int32(\n    world_size: int,\n    values: List[Union[int, Tensor]],\n    device: Optional[torch.device] = None,\n) -> List[int]:\n    \"\"\"Exchange 32-bit integers between all ranks in a many-to-many fashion.\n    .. note::\n        This function is not differentiable to the input tensors.\n    Args:\n        world_size: The total number of ranks.",
        "detail": "thirdparty.gsplat.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_gather_tensor_list",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.distributed",
        "description": "thirdparty.gsplat.gsplat.distributed",
        "peekOfCode": "def all_gather_tensor_list(world_size: int, tensor_list: List[Tensor]) -> List[Tensor]:\n    \"\"\"Gather a list of tensors from all ranks.\n    .. note::\n        This function expects the tensors in the `tensor_list` to have the same shape\n        and data type across all ranks.\n    .. note::\n        This function is differentiable to the tensors in `tensor_list`.\n    .. note::\n        For efficiency, this function internally concatenates the tensors in `tensor_list`\n        and performs a single gather operation. Thus it requires all tensors in the list",
        "detail": "thirdparty.gsplat.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "all_to_all_tensor_list",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.distributed",
        "description": "thirdparty.gsplat.gsplat.distributed",
        "peekOfCode": "def all_to_all_tensor_list(\n    world_size: int,\n    tensor_list: List[Tensor],\n    splits: List[Union[int, Tensor]],\n    output_splits: Optional[List[Union[int, Tensor]]] = None,\n) -> List[Tensor]:\n    \"\"\"Split and exchange tensors between all ranks in a many-to-many fashion.\n    Args:\n        world_size: The total number of ranks.\n        tensor_list: A list of tensors to split and exchange. The size of the first",
        "detail": "thirdparty.gsplat.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.distributed",
        "description": "thirdparty.gsplat.gsplat.distributed",
        "peekOfCode": "def cli(fn: Callable, args: Any, verbose: bool = False) -> bool:\n    \"\"\"Wrapper to run a function in a distributed environment.\n    The function `fn` should have the following signature:\n    ```python\n    def fn(local_rank: int, world_rank: int, world_size: int, args: Any) -> None:\n        pass\n    ```\n    Usage:\n    ```python\n    # Launch with \"CUDA_VISIBLE_DEVICES=0,1,2,3 python my_script.py\"",
        "detail": "thirdparty.gsplat.gsplat.distributed",
        "documentation": {}
    },
    {
        "label": "timeit",
        "kind": 6,
        "importPath": "thirdparty.gsplat.gsplat.profile",
        "description": "thirdparty.gsplat.gsplat.profile",
        "peekOfCode": "class timeit(object):\n    \"\"\"Profiler that is controled by the TIMEIT environment variable.\n    If TIMEIT is set to 1, the profiler will measure the time taken by the decorated function.\n    Usage:\n    ```python\n    @timeit()\n    def my_function():\n        pass\n    # Or\n    with timeit(name=\"stage1\"):",
        "detail": "thirdparty.gsplat.gsplat.profile",
        "documentation": {}
    },
    {
        "label": "profiler",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.profile",
        "description": "thirdparty.gsplat.gsplat.profile",
        "peekOfCode": "profiler = {}\nclass timeit(object):\n    \"\"\"Profiler that is controled by the TIMEIT environment variable.\n    If TIMEIT is set to 1, the profiler will measure the time taken by the decorated function.\n    Usage:\n    ```python\n    @timeit()\n    def my_function():\n        pass\n    # Or",
        "detail": "thirdparty.gsplat.gsplat.profile",
        "documentation": {}
    },
    {
        "label": "compute_relocation",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.relocation",
        "description": "thirdparty.gsplat.gsplat.relocation",
        "peekOfCode": "def compute_relocation(\n    opacities: Tensor,  # [N]\n    scales: Tensor,  # [N, 3]\n    ratios: Tensor,  # [N]\n    binoms: Tensor,  # [n_max, n_max]\n) -> Tuple[Tensor, Tensor]:\n    \"\"\"Compute new Gaussians from a set of old Gaussians.\n    This function interprets the Gaussians as samples from a likelihood distribution.\n    It uses the old opacities and scales to compute the new opacities and scales.\n    This is an implementation of the paper",
        "detail": "thirdparty.gsplat.gsplat.relocation",
        "documentation": {}
    },
    {
        "label": "rasterization",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.rendering",
        "description": "thirdparty.gsplat.gsplat.rendering",
        "peekOfCode": "def rasterization(\n    means: Tensor,  # [N, 3]\n    quats: Tensor,  # [N, 4]\n    scales: Tensor,  # [N, 3]\n    opacities: Tensor,  # [N]\n    colors: Tensor,  # [(C,) N, D] or [(C,) N, K, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,",
        "detail": "thirdparty.gsplat.gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "rasterization_legacy_wrapper",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.rendering",
        "description": "thirdparty.gsplat.gsplat.rendering",
        "peekOfCode": "def rasterization_legacy_wrapper(\n    means: Tensor,  # [N, 3]\n    quats: Tensor,  # [N, 4]\n    scales: Tensor,  # [N, 3]\n    opacities: Tensor,  # [N]\n    colors: Tensor,  # [N, D] or [N, K, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,",
        "detail": "thirdparty.gsplat.gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "rasterization_inria_wrapper",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.rendering",
        "description": "thirdparty.gsplat.gsplat.rendering",
        "peekOfCode": "def rasterization_inria_wrapper(\n    means: Tensor,  # [N, 3]\n    quats: Tensor,  # [N, 4]\n    scales: Tensor,  # [N, 3]\n    opacities: Tensor,  # [N]\n    colors: Tensor,  # [N, D] or [N, K, 3]\n    viewmats: Tensor,  # [C, 4, 4]\n    Ks: Tensor,  # [C, 3, 3]\n    width: int,\n    height: int,",
        "detail": "thirdparty.gsplat.gsplat.rendering",
        "documentation": {}
    },
    {
        "label": "normalized_quat_to_rotmat",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.utils",
        "description": "thirdparty.gsplat.gsplat.utils",
        "peekOfCode": "def normalized_quat_to_rotmat(quat: Tensor) -> Tensor:\n    \"\"\"Convert normalized quaternion to rotation matrix.\n    Args:\n        quat: Normalized quaternion in wxyz convension. (..., 4)\n    Returns:\n        Rotation matrix (..., 3, 3)\n    \"\"\"\n    assert quat.shape[-1] == 4, quat.shape\n    w, x, y, z = torch.unbind(quat, dim=-1)\n    mat = torch.stack(",
        "detail": "thirdparty.gsplat.gsplat.utils",
        "documentation": {}
    },
    {
        "label": "log_transform",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.utils",
        "description": "thirdparty.gsplat.gsplat.utils",
        "peekOfCode": "def log_transform(x):\n    return torch.sign(x) * torch.log1p(torch.abs(x))\ndef inverse_log_transform(y):\n    return torch.sign(y) * (torch.expm1(torch.abs(y)))",
        "detail": "thirdparty.gsplat.gsplat.utils",
        "documentation": {}
    },
    {
        "label": "inverse_log_transform",
        "kind": 2,
        "importPath": "thirdparty.gsplat.gsplat.utils",
        "description": "thirdparty.gsplat.gsplat.utils",
        "peekOfCode": "def inverse_log_transform(y):\n    return torch.sign(y) * (torch.expm1(torch.abs(y)))",
        "detail": "thirdparty.gsplat.gsplat.utils",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.gsplat.version",
        "description": "thirdparty.gsplat.gsplat.version",
        "peekOfCode": "__version__ = \"1.3.0\"",
        "detail": "thirdparty.gsplat.gsplat.version",
        "documentation": {}
    },
    {
        "label": "timeit",
        "kind": 2,
        "importPath": "thirdparty.gsplat.profiling.main",
        "description": "thirdparty.gsplat.profiling.main",
        "peekOfCode": "def timeit(repeats: int, f: Callable, *args, **kwargs) -> float:\n    for _ in range(5):  # warmup\n        f(*args, **kwargs)\n    torch.cuda.synchronize()\n    start = time.time()\n    for _ in range(repeats):\n        results = f(*args, **kwargs)\n    torch.cuda.synchronize()\n    end = time.time()\n    return (end - start) / repeats, results",
        "detail": "thirdparty.gsplat.profiling.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.gsplat.profiling.main",
        "description": "thirdparty.gsplat.profiling.main",
        "peekOfCode": "def main(\n    batch_size: int = 1,\n    channels: int = 3,\n    reso: Literal[\"360p\", \"720p\", \"1080p\", \"4k\"] = \"4k\",\n    scene_grid: int = 15,\n    packed: bool = True,\n    sparse_grad: bool = False,\n    backend: Literal[\"gsplat2\", \"gsplat\", \"inria\"] = \"gsplat2\",\n    repeats: int = 100,\n    memory_history: bool = False,",
        "detail": "thirdparty.gsplat.profiling.main",
        "documentation": {}
    },
    {
        "label": "worker",
        "kind": 2,
        "importPath": "thirdparty.gsplat.profiling.main",
        "description": "thirdparty.gsplat.profiling.main",
        "peekOfCode": "def worker(local_rank: int, world_rank: int, world_size: int, args):\n    from tabulate import tabulate\n    # Tested on a NVIDIA TITAN RTX with (24 GB).\n    collection = []\n    for batch_size in args.batch_size:\n        for channels in args.channels:\n            print(\"========================================\")\n            print(f\"Batch Size: {batch_size}, Channels: {channels}\")\n            print(\"========================================\")\n            if \"gsplat\" in args.backends:",
        "detail": "thirdparty.gsplat.profiling.main",
        "documentation": {}
    },
    {
        "label": "RESOLUTIONS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.profiling.main",
        "description": "thirdparty.gsplat.profiling.main",
        "peekOfCode": "RESOLUTIONS = {\n    \"360p\": (640, 360),\n    \"720p\": (1280, 720),\n    \"1080p\": (1920, 1080),\n    \"4k\": (3840, 2160),\n}\ndevice = torch.device(\"cuda\")\ndef timeit(repeats: int, f: Callable, *args, **kwargs) -> float:\n    for _ in range(5):  # warmup\n        f(*args, **kwargs)",
        "detail": "thirdparty.gsplat.profiling.main",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "thirdparty.gsplat.profiling.main",
        "description": "thirdparty.gsplat.profiling.main",
        "peekOfCode": "device = torch.device(\"cuda\")\ndef timeit(repeats: int, f: Callable, *args, **kwargs) -> float:\n    for _ in range(5):  # warmup\n        f(*args, **kwargs)\n    torch.cuda.synchronize()\n    start = time.time()\n    for _ in range(repeats):\n        results = f(*args, **kwargs)\n    torch.cuda.synchronize()\n    end = time.time()",
        "detail": "thirdparty.gsplat.profiling.main",
        "documentation": {}
    },
    {
        "label": "test_all_gather_int32",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests._test_distributed",
        "description": "thirdparty.gsplat.tests._test_distributed",
        "peekOfCode": "def test_all_gather_int32():\n    cli(_main_all_gather_int32, None, verbose=True)\ndef _main_all_to_all_int32(local_rank: int, world_rank: int, world_size: int, _):\n    device = torch.device(\"cuda\", local_rank)\n    values = list(range(world_size))\n    collected = all_to_all_int32(world_size, values, device=device)\n    for i in range(world_size):\n        assert collected[i] == world_rank\n    values = torch.arange(world_size, device=device, dtype=torch.int)\n    collected = all_to_all_int32(world_size, values, device=device)",
        "detail": "thirdparty.gsplat.tests._test_distributed",
        "documentation": {}
    },
    {
        "label": "test_all_to_all_int32",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests._test_distributed",
        "description": "thirdparty.gsplat.tests._test_distributed",
        "peekOfCode": "def test_all_to_all_int32():\n    cli(_main_all_to_all_int32, None, verbose=True)\ndef _main_all_gather_tensor_list(local_rank: int, world_rank: int, world_size: int, _):\n    device = torch.device(\"cuda\", local_rank)\n    N = 10\n    tensor_list = [\n        torch.full((N, 2), world_rank, device=device),\n        torch.full((N, 3, 3), world_rank, device=device),\n    ]\n    target_list = [",
        "detail": "thirdparty.gsplat.tests._test_distributed",
        "documentation": {}
    },
    {
        "label": "test_all_gather_tensor_list",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests._test_distributed",
        "description": "thirdparty.gsplat.tests._test_distributed",
        "peekOfCode": "def test_all_gather_tensor_list():\n    cli(_main_all_gather_tensor_list, None, verbose=True)\ndef _main_all_to_all_tensor_list(local_rank: int, world_rank: int, world_size: int, _):\n    device = torch.device(\"cuda\", local_rank)\n    splits = torch.arange(0, world_size, device=device)\n    N = splits.sum().item()\n    tensor_list = [\n        torch.full((N, 2), world_rank, device=device),\n        torch.full((N, 3, 3), world_rank, device=device),\n    ]",
        "detail": "thirdparty.gsplat.tests._test_distributed",
        "documentation": {}
    },
    {
        "label": "test_all_to_all_tensor_list",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests._test_distributed",
        "description": "thirdparty.gsplat.tests._test_distributed",
        "peekOfCode": "def test_all_to_all_tensor_list():\n    cli(_main_all_to_all_tensor_list, None, verbose=True)\nif __name__ == \"__main__\":\n    test_all_gather_int32()\n    test_all_to_all_int32()\n    test_all_gather_tensor_list()\n    test_all_to_all_tensor_list()",
        "detail": "thirdparty.gsplat.tests._test_distributed",
        "documentation": {}
    },
    {
        "label": "test_data",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_data():\n    (\n        means,\n        quats,\n        scales,\n        opacities,\n        colors,\n        viewmats,\n        Ks,\n        width,",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_quat_scale_to_covar_preci",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_quat_scale_to_covar_preci(test_data, triu: bool):\n    from gsplat.cuda._torch_impl import _quat_scale_to_covar_preci\n    from gsplat.cuda._wrapper import quat_scale_to_covar_preci\n    torch.manual_seed(42)\n    quats = test_data[\"quats\"]\n    scales = test_data[\"scales\"]\n    quats.requires_grad = True\n    scales.requires_grad = True\n    # forward\n    covars, precis = quat_scale_to_covar_preci(quats, scales, triu=triu)",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_world_to_cam",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_world_to_cam(test_data):\n    from gsplat.cuda._torch_impl import _world_to_cam\n    from gsplat.cuda._wrapper import quat_scale_to_covar_preci, world_to_cam\n    torch.manual_seed(42)\n    viewmats = test_data[\"viewmats\"]\n    means = test_data[\"means\"]\n    scales = test_data[\"scales\"]\n    quats = test_data[\"quats\"]\n    covars, _ = quat_scale_to_covar_preci(quats, scales)\n    means.requires_grad = True",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_proj",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_proj(test_data, ortho: bool):\n    from gsplat.cuda._torch_impl import _persp_proj, _ortho_proj\n    from gsplat.cuda._wrapper import proj, quat_scale_to_covar_preci, world_to_cam\n    torch.manual_seed(42)\n    Ks = test_data[\"Ks\"]\n    viewmats = test_data[\"viewmats\"]\n    height = test_data[\"height\"]\n    width = test_data[\"width\"]\n    covars, _ = quat_scale_to_covar_preci(test_data[\"quats\"], test_data[\"scales\"])\n    means, covars = world_to_cam(test_data[\"means\"], covars, viewmats)",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_projection",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_projection(test_data, fused: bool, calc_compensations: bool, ortho: bool):\n    from gsplat.cuda._torch_impl import _fully_fused_projection\n    from gsplat.cuda._wrapper import fully_fused_projection, quat_scale_to_covar_preci\n    torch.manual_seed(42)\n    Ks = test_data[\"Ks\"]\n    viewmats = test_data[\"viewmats\"]\n    height = test_data[\"height\"]\n    width = test_data[\"width\"]\n    quats = test_data[\"quats\"]\n    scales = test_data[\"scales\"]",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_fully_fused_projection_packed",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_fully_fused_projection_packed(\n    test_data, fused: bool, sparse_grad: bool, calc_compensations: bool, ortho: bool\n):\n    from gsplat.cuda._wrapper import fully_fused_projection, quat_scale_to_covar_preci\n    torch.manual_seed(42)\n    Ks = test_data[\"Ks\"]\n    viewmats = test_data[\"viewmats\"]\n    height = test_data[\"height\"]\n    width = test_data[\"width\"]\n    quats = test_data[\"quats\"]",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_isect",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_isect(test_data):\n    from gsplat.cuda._torch_impl import _isect_offset_encode, _isect_tiles\n    from gsplat.cuda._wrapper import isect_offset_encode, isect_tiles\n    torch.manual_seed(42)\n    C, N = 3, 1000\n    width, height = 40, 60\n    means2d = torch.randn(C, N, 2, device=device) * width\n    radii = torch.randint(0, width, (C, N), device=device, dtype=torch.int32)\n    depths = torch.rand(C, N, device=device)\n    tile_size = 16",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_rasterize_to_pixels",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_rasterize_to_pixels(test_data, channels: int):\n    from gsplat.cuda._torch_impl import _rasterize_to_pixels\n    from gsplat.cuda._wrapper import (\n        fully_fused_projection,\n        isect_offset_encode,\n        isect_tiles,\n        quat_scale_to_covar_preci,\n        rasterize_to_pixels,\n    )\n    torch.manual_seed(42)",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_sh",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "def test_sh(test_data, sh_degree: int):\n    from gsplat.cuda._torch_impl import _spherical_harmonics\n    from gsplat.cuda._wrapper import spherical_harmonics\n    torch.manual_seed(42)\n    N = 1000\n    coeffs = torch.randn(N, (4 + 1) ** 2, 3, device=device)\n    dirs = torch.randn(N, 3, device=device)\n    coeffs.requires_grad = True\n    dirs.requires_grad = True\n    colors = spherical_harmonics(sh_degree, dirs, coeffs)",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "thirdparty.gsplat.tests.test_basic",
        "description": "thirdparty.gsplat.tests.test_basic",
        "peekOfCode": "device = torch.device(\"cuda:0\")\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"No CUDA device\")\n@pytest.fixture\ndef test_data():\n    (\n        means,\n        quats,\n        scales,\n        opacities,\n        colors,",
        "detail": "thirdparty.gsplat.tests.test_basic",
        "documentation": {}
    },
    {
        "label": "test_png_compression",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_compression",
        "description": "thirdparty.gsplat.tests.test_compression",
        "peekOfCode": "def test_png_compression():\n    from gsplat.compression import PngCompression\n    torch.manual_seed(42)\n    # Prepare Gaussians\n    N = 100000\n    splats = torch.nn.ParameterDict(\n        {\n            \"means\": torch.randn(N, 3),\n            \"scales\": torch.randn(N, 3),\n            \"quats\": torch.randn(N, 4),",
        "detail": "thirdparty.gsplat.tests.test_compression",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "thirdparty.gsplat.tests.test_compression",
        "description": "thirdparty.gsplat.tests.test_compression",
        "peekOfCode": "device = torch.device(\"cuda:0\")\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"No CUDA device\")\ndef test_png_compression():\n    from gsplat.compression import PngCompression\n    torch.manual_seed(42)\n    # Prepare Gaussians\n    N = 100000\n    splats = torch.nn.ParameterDict(\n        {\n            \"means\": torch.randn(N, 3),",
        "detail": "thirdparty.gsplat.tests.test_compression",
        "documentation": {}
    },
    {
        "label": "test_rasterization",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_rasterization",
        "description": "thirdparty.gsplat.tests.test_rasterization",
        "peekOfCode": "def test_rasterization(\n    per_view_color: bool, sh_degree: Optional[int], render_mode: str, packed: bool\n):\n    from gsplat.rendering import _rasterization, rasterization\n    torch.manual_seed(42)\n    C, N = 2, 10_000\n    means = torch.rand(N, 3, device=device)\n    quats = torch.randn(N, 4, device=device)\n    scales = torch.rand(N, 3, device=device)\n    opacities = torch.rand(N, device=device)",
        "detail": "thirdparty.gsplat.tests.test_rasterization",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "thirdparty.gsplat.tests.test_rasterization",
        "description": "thirdparty.gsplat.tests.test_rasterization",
        "peekOfCode": "device = torch.device(\"cuda:0\")\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"No CUDA device\")\n@pytest.mark.parametrize(\"per_view_color\", [True, False])\n@pytest.mark.parametrize(\"sh_degree\", [None, 3])\n@pytest.mark.parametrize(\"render_mode\", [\"RGB\", \"RGB+D\", \"D\"])\n@pytest.mark.parametrize(\"packed\", [True, False])\ndef test_rasterization(\n    per_view_color: bool, sh_degree: Optional[int], render_mode: str, packed: bool\n):\n    from gsplat.rendering import _rasterization, rasterization",
        "detail": "thirdparty.gsplat.tests.test_rasterization",
        "documentation": {}
    },
    {
        "label": "test_strategy",
        "kind": 2,
        "importPath": "thirdparty.gsplat.tests.test_strategy",
        "description": "thirdparty.gsplat.tests.test_strategy",
        "peekOfCode": "def test_strategy():\n    from gsplat.rendering import rasterization\n    from gsplat.strategy import DefaultStrategy, MCMCStrategy\n    torch.manual_seed(42)\n    # Prepare Gaussians\n    N = 100\n    params = torch.nn.ParameterDict(\n        {\n            \"means\": torch.randn(N, 3),\n            \"scales\": torch.rand(N, 3),",
        "detail": "thirdparty.gsplat.tests.test_strategy",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "thirdparty.gsplat.tests.test_strategy",
        "description": "thirdparty.gsplat.tests.test_strategy",
        "peekOfCode": "device = torch.device(\"cuda:0\")\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"No CUDA device\")\ndef test_strategy():\n    from gsplat.rendering import rasterization\n    from gsplat.strategy import DefaultStrategy, MCMCStrategy\n    torch.manual_seed(42)\n    # Prepare Gaussians\n    N = 100\n    params = torch.nn.ParameterDict(\n        {",
        "detail": "thirdparty.gsplat.tests.test_strategy",
        "documentation": {}
    },
    {
        "label": "get_ext",
        "kind": 2,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "def get_ext():\n    from torch.utils.cpp_extension import BuildExtension\n    return BuildExtension.with_options(no_python_abi_suffix=True, use_ninja=True)\ndef get_extensions():\n    import torch\n    from torch.__config__ import parallel_info\n    from torch.utils.cpp_extension import CUDAExtension\n    extensions_dir_v1 = osp.join(\"gsplat\", \"cuda_legacy\", \"csrc\")\n    sources_v1 = glob.glob(osp.join(extensions_dir_v1, \"*.cu\")) + glob.glob(\n        osp.join(extensions_dir_v1, \"*.cpp\")",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "get_extensions",
        "kind": 2,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "def get_extensions():\n    import torch\n    from torch.__config__ import parallel_info\n    from torch.utils.cpp_extension import CUDAExtension\n    extensions_dir_v1 = osp.join(\"gsplat\", \"cuda_legacy\", \"csrc\")\n    sources_v1 = glob.glob(osp.join(extensions_dir_v1, \"*.cu\")) + glob.glob(\n        osp.join(extensions_dir_v1, \"*.cpp\")\n    )\n    sources_v1 = [path for path in sources_v1 if \"hip\" not in path]\n    extensions_dir_v2 = osp.join(\"gsplat\", \"cuda\", \"csrc\")",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "__version__ = None\nexec(open(\"gsplat/version.py\", \"r\").read())\nURL = \"https://github.com/nerfstudio-project/gsplat\"\nBUILD_NO_CUDA = os.getenv(\"BUILD_NO_CUDA\", \"0\") == \"1\"\nWITH_SYMBOLS = os.getenv(\"WITH_SYMBOLS\", \"0\") == \"1\"\nLINE_INFO = os.getenv(\"LINE_INFO\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "URL",
        "kind": 5,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "URL = \"https://github.com/nerfstudio-project/gsplat\"\nBUILD_NO_CUDA = os.getenv(\"BUILD_NO_CUDA\", \"0\") == \"1\"\nWITH_SYMBOLS = os.getenv(\"WITH_SYMBOLS\", \"0\") == \"1\"\nLINE_INFO = os.getenv(\"LINE_INFO\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\n    print(f\"Setting MAX_JOBS to {os.environ['MAX_JOBS']}\")",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "BUILD_NO_CUDA",
        "kind": 5,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "BUILD_NO_CUDA = os.getenv(\"BUILD_NO_CUDA\", \"0\") == \"1\"\nWITH_SYMBOLS = os.getenv(\"WITH_SYMBOLS\", \"0\") == \"1\"\nLINE_INFO = os.getenv(\"LINE_INFO\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\n    print(f\"Setting MAX_JOBS to {os.environ['MAX_JOBS']}\")\ndef get_ext():",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "WITH_SYMBOLS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "WITH_SYMBOLS = os.getenv(\"WITH_SYMBOLS\", \"0\") == \"1\"\nLINE_INFO = os.getenv(\"LINE_INFO\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\n    print(f\"Setting MAX_JOBS to {os.environ['MAX_JOBS']}\")\ndef get_ext():\n    from torch.utils.cpp_extension import BuildExtension",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "LINE_INFO",
        "kind": 5,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "LINE_INFO = os.getenv(\"LINE_INFO\", \"0\") == \"1\"\nMAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\n    print(f\"Setting MAX_JOBS to {os.environ['MAX_JOBS']}\")\ndef get_ext():\n    from torch.utils.cpp_extension import BuildExtension\n    return BuildExtension.with_options(no_python_abi_suffix=True, use_ninja=True)",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "MAX_JOBS",
        "kind": 5,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "MAX_JOBS = os.getenv(\"MAX_JOBS\")\nneed_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\n    print(f\"Setting MAX_JOBS to {os.environ['MAX_JOBS']}\")\ndef get_ext():\n    from torch.utils.cpp_extension import BuildExtension\n    return BuildExtension.with_options(no_python_abi_suffix=True, use_ninja=True)\ndef get_extensions():",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "need_to_unset_max_jobs",
        "kind": 5,
        "importPath": "thirdparty.gsplat.setup",
        "description": "thirdparty.gsplat.setup",
        "peekOfCode": "need_to_unset_max_jobs = False\nif not MAX_JOBS:\n    need_to_unset_max_jobs = True\n    os.environ[\"MAX_JOBS\"] = \"10\"\n    print(f\"Setting MAX_JOBS to {os.environ['MAX_JOBS']}\")\ndef get_ext():\n    from torch.utils.cpp_extension import BuildExtension\n    return BuildExtension.with_options(no_python_abi_suffix=True, use_ninja=True)\ndef get_extensions():\n    import torch",
        "detail": "thirdparty.gsplat.setup",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "project = 'small_gicp'\ncopyright = '2024, k.koide'\nauthor = 'k.koide'\nversion = '0.1.1'\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath('./build/'))\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\nextensions = ['sphinx.ext.autodoc', 'sphinx.ext.napoleon']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "copyright = '2024, k.koide'\nauthor = 'k.koide'\nversion = '0.1.1'\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath('./build/'))\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\nextensions = ['sphinx.ext.autodoc', 'sphinx.ext.napoleon']\ntemplates_path = ['_templates']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "author",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "author = 'k.koide'\nversion = '0.1.1'\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath('./build/'))\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\nextensions = ['sphinx.ext.autodoc', 'sphinx.ext.napoleon']\ntemplates_path = ['_templates']\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "version = '0.1.1'\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath('./build/'))\n# -- General configuration ---------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration\nextensions = ['sphinx.ext.autodoc', 'sphinx.ext.napoleon']\ntemplates_path = ['_templates']\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\nautoclass_content = 'both'",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "extensions",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "extensions = ['sphinx.ext.autodoc', 'sphinx.ext.napoleon']\ntemplates_path = ['_templates']\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\nautoclass_content = 'both'\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\nhtml_theme = 'sphinx_rtd_theme'\nhtml_static_path = ['_static']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "templates_path",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "templates_path = ['_templates']\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\nautoclass_content = 'both'\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\nhtml_theme = 'sphinx_rtd_theme'\nhtml_static_path = ['_static']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "exclude_patterns",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\nautoclass_content = 'both'\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\nhtml_theme = 'sphinx_rtd_theme'\nhtml_static_path = ['_static']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "autoclass_content",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "autoclass_content = 'both'\n# -- Options for HTML output -------------------------------------------------\n# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output\nhtml_theme = 'sphinx_rtd_theme'\nhtml_static_path = ['_static']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "html_theme = 'sphinx_rtd_theme'\nhtml_static_path = ['_static']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "html_static_path",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.docs.conf",
        "description": "thirdparty.small_gicp.docs.conf",
        "peekOfCode": "html_static_path = ['_static']",
        "detail": "thirdparty.small_gicp.docs.conf",
        "documentation": {}
    },
    {
        "label": "parse_result",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_downsampling",
        "description": "thirdparty.small_gicp.scripts.plot_downsampling",
        "peekOfCode": "def parse_result(filename):\n  leaf_sizes = []\n  results = {}\n  with open(filename, 'r') as f:\n    for line in f.readlines():\n      if '(warmup)' in line:\n        continue\n      found = re.findall(r'leaf_size=(\\S+)', line)\n      if found:\n        leaf_sizes.append(float(found[0]))",
        "detail": "thirdparty.small_gicp.scripts.plot_downsampling",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_downsampling",
        "description": "thirdparty.small_gicp.scripts.plot_downsampling",
        "peekOfCode": "def main():\n  results_path = os.path.dirname(__file__) + '/results'\n  leaf_sizes = None\n  raw_results = []\n  for filename in os.listdir(results_path):\n    found = re.findall(r'downsampling_benchmark_(\\d+).txt', filename)    \n    if not found:\n      continue\n    leaf_sizes, rets = parse_result(results_path + '/' + filename)\n    raw_results.append((int(found[0]), rets))",
        "detail": "thirdparty.small_gicp.scripts.plot_downsampling",
        "documentation": {}
    },
    {
        "label": "Result",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.scripts.plot_downsampling",
        "description": "thirdparty.small_gicp.scripts.plot_downsampling",
        "peekOfCode": "Result = namedtuple('Result', ['time_mean', 'time_std', 'points_mean', 'points_std'])\ndef parse_result(filename):\n  leaf_sizes = []\n  results = {}\n  with open(filename, 'r') as f:\n    for line in f.readlines():\n      if '(warmup)' in line:\n        continue\n      found = re.findall(r'leaf_size=(\\S+)', line)\n      if found:",
        "detail": "thirdparty.small_gicp.scripts.plot_downsampling",
        "documentation": {}
    },
    {
        "label": "parse_result",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_kdtree",
        "description": "thirdparty.small_gicp.scripts.plot_kdtree",
        "peekOfCode": "def parse_result(filename):\n  num_points = []\n  results = {}\n  with open(filename, 'r') as f:\n    for line in f.readlines():\n      matched = re.match(r'num_threads=(\\d+)', line)\n      if matched:\n        num_threads = int(matched.group(1))\n        continue\n      matched = re.match(r'num_points=(\\d+)', line)",
        "detail": "thirdparty.small_gicp.scripts.plot_kdtree",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_kdtree",
        "description": "thirdparty.small_gicp.scripts.plot_kdtree",
        "peekOfCode": "def main():\n  results_path = os.path.dirname(__file__) + '/results'\n  results = {}\n  for filename in os.listdir(results_path):\n    matched = re.match(r'kdtree_benchmark_(\\S+)_(\\d+).txt', filename)\n    if not matched:\n      continue\n    method = '{}_{}'.format(matched.group(1), matched.group(2))\n    print(method)\n    num_threads, num_points, rets = parse_result(results_path + '/' + filename)",
        "detail": "thirdparty.small_gicp.scripts.plot_kdtree",
        "documentation": {}
    },
    {
        "label": "parse_result",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry",
        "description": "thirdparty.small_gicp.scripts.plot_odometry",
        "peekOfCode": "def parse_result(filename):\n  reg_mean = None\n  reg_std = None\n  throughput_mean = None\n  throughput_std = None\n  with open(filename, 'r') as f:\n    for line in f.readlines():\n      found = re.findall(r'([^=]+)\\s*\\+\\-\\s*(\\S+)', line)\n      if not found or len(found) != 2:\n        found = re.findall(r'total_throughput=(\\S+)', line)",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry",
        "description": "thirdparty.small_gicp.scripts.plot_odometry",
        "peekOfCode": "def main():\n  results_path = os.path.dirname(__file__) + '/results'\n  results = {}\n  for filename in os.listdir(results_path):\n    found = re.findall(r'odometry_benchmark_(\\S+)_(\\d+).txt', filename)\n    if not found:\n      continue    \n    rets = parse_result(results_path + '/' + filename)\n    results['{}_{}'.format(found[0][0], found[0][1])] = rets\n  fig, axes = pyplot.subplots(2, 2, figsize=(24, 12))",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry",
        "documentation": {}
    },
    {
        "label": "Result",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry",
        "description": "thirdparty.small_gicp.scripts.plot_odometry",
        "peekOfCode": "Result = namedtuple('Result', ['reg_mean', 'reg_std', 'tp_mean', 'tp_std'])\ndef parse_result(filename):\n  reg_mean = None\n  reg_std = None\n  throughput_mean = None\n  throughput_std = None\n  with open(filename, 'r') as f:\n    for line in f.readlines():\n      found = re.findall(r'([^=]+)\\s*\\+\\-\\s*(\\S+)', line)\n      if not found or len(found) != 2:",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry",
        "documentation": {}
    },
    {
        "label": "run_evo",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "description": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "peekOfCode": "def run_evo(commands):\n  p = subprocess.Popen(commands, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n  p.wait()\n  stdout, stderr = p.communicate()\n  if len(stderr):\n    print(stderr.decode('utf-8'))\n  result = stdout.decode('utf-8')\n  results = {}\n  for item in re.findall(r'([a-z]+)\\s+([0-9]+\\.[0-9]+)', result):\n    results[item[0]] = float(item[1])",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "documentation": {}
    },
    {
        "label": "eval_ape",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "description": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "peekOfCode": "def eval_ape(gt_filename, traj_filename, t_offset=0.0):\n  ret = run_evo(['evo_ape', 'kitti', gt_filename, traj_filename, '-a'])\n  return ret\ndef eval_rpe(gt_filename, traj_filename, delta_unit='m', delta=100, all_pairs=True, t_offset=0.0):\n  commands = ['evo_rpe', 'kitti', gt_filename, traj_filename, '-a', '--delta_unit', str(delta_unit), '--delta', str(delta)]\n  if all_pairs:\n    commands += ['--all_pairs']\n  ret = run_evo(commands)\n  return ret\ndef main():",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "documentation": {}
    },
    {
        "label": "eval_rpe",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "description": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "peekOfCode": "def eval_rpe(gt_filename, traj_filename, delta_unit='m', delta=100, all_pairs=True, t_offset=0.0):\n  commands = ['evo_rpe', 'kitti', gt_filename, traj_filename, '-a', '--delta_unit', str(delta_unit), '--delta', str(delta)]\n  if all_pairs:\n    commands += ['--all_pairs']\n  ret = run_evo(commands)\n  return ret\ndef main():\n  gt_path = '/home/koide/datasets/ssd/kitti/poses/00_lidar.txt'\n  results_path = os.path.dirname(__file__) + '/results'\n  filenames = []",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "description": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "peekOfCode": "def main():\n  gt_path = '/home/koide/datasets/ssd/kitti/poses/00_lidar.txt'\n  results_path = os.path.dirname(__file__) + '/results'\n  filenames = []\n  for filename in os.listdir(results_path):\n    found = re.findall(r'traj_lidar_(\\S+)_(\\d+).txt', filename)\n    if not found:\n      continue\n    method = found[0][0] + '_' + found[0][1]\n    filenames.append((method, results_path + '/' + filename))",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry_accuracy",
        "documentation": {}
    },
    {
        "label": "parse_result",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "description": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "peekOfCode": "def parse_result(filename):\n  reg_mean = None\n  reg_std = None\n  throughput_mean = None\n  throughput_std = None\n  with open(filename, 'r') as f:\n    for line in f.readlines():\n      found = re.findall(r'([^=]+)\\s*\\+\\-\\s*(\\S+)', line)\n      if not found or len(found) != 2:\n        found = re.findall(r'total_throughput=(\\S+)', line)",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "description": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "peekOfCode": "def main():\n  results_path = os.path.dirname(__file__) + '/results'\n  results = {}\n  for filename in os.listdir(results_path):\n    found = re.findall(r'odometry_benchmark_(\\S+)_(native|nonnative)_(\\d+).txt', filename)\n    if not found:\n      continue    \n    rets = parse_result(results_path + '/' + filename)\n    results['{}_{}_{}'.format(found[0][0], found[0][1], found[0][2])] = rets\n  fig, axes = pyplot.subplots(1, 1, figsize=(12, 2))",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "documentation": {}
    },
    {
        "label": "Result",
        "kind": 5,
        "importPath": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "description": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "peekOfCode": "Result = namedtuple('Result', ['reg_mean', 'reg_std', 'tp_mean', 'tp_std'])\ndef parse_result(filename):\n  reg_mean = None\n  reg_std = None\n  throughput_mean = None\n  throughput_std = None\n  with open(filename, 'r') as f:\n    for line in f.readlines():\n      found = re.findall(r'([^=]+)\\s*\\+\\-\\s*(\\S+)', line)\n      if not found or len(found) != 2:",
        "detail": "thirdparty.small_gicp.scripts.plot_odometry_native",
        "documentation": {}
    },
    {
        "label": "example_numpy1",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def example_numpy1(target_raw_numpy : numpy.ndarray, source_raw_numpy : numpy.ndarray):\n  print('*** example_numpy1 ***')\n  # Example A : Perform registration with numpy arrays\n  # Arguments\n  # - target_points               : Nx4 or Nx3 numpy array of the target point cloud\n  # - source_points               : Nx4 or Nx3 numpy array of the source point cloud\n  # Optional arguments\n  # - init_T_target_source        : Initial guess of the transformation matrix (4x4 numpy array)\n  # - registration_type           : Registration type (\"ICP\", \"PLANE_ICP\", \"GICP\", \"VGICP\")\n  # - voxel_resolution            : Voxel resolution for VGICP",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "example_numpy2",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def example_numpy2(target_raw_numpy : numpy.ndarray, source_raw_numpy : numpy.ndarray):\n  print('*** example_numpy2 ***')\n  # Example B : Perform preprocessing and registration separately\n  # Preprocess point clouds\n  # Arguments\n  # - points                      : Nx4 or Nx3 numpy array of the target point cloud\n  # Optional arguments\n  # - downsampling_resolution     : Downsampling resolution\n  # - num_neighbors               : Number of neighbors for normal and covariance estimation\n  # - num_threads                 : Number of threads",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "example_small1",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def example_small1(target_raw_numpy : numpy.ndarray, source_raw_numpy : numpy.ndarray):\n  print('*** example_small1 ***')\n  # Convert numpy arrays (Nx3 or Nx4) to small_gicp.PointCloud\n  target_raw = small_gicp.PointCloud(target_raw_numpy)\n  source_raw = small_gicp.PointCloud(source_raw_numpy)\n  # Preprocess point clouds\n  target, target_tree = small_gicp.preprocess_points(target_raw, downsampling_resolution=0.25)\n  source, source_tree = small_gicp.preprocess_points(source_raw, downsampling_resolution=0.25)\n  print('preprocessed target=', target)\n  print('preprocessed source=', source)",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "example_small2",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def example_small2(target_raw_numpy : numpy.ndarray, source_raw_numpy : numpy.ndarray):\n  print('*** example_small2 ***')\n  # Convert numpy arrays (Nx3 or Nx4) to small_gicp.PointCloud\n  target_raw = small_gicp.PointCloud(target_raw_numpy)\n  source_raw = small_gicp.PointCloud(source_raw_numpy)\n  # Downsampling\n  target = small_gicp.voxelgrid_sampling(target_raw, 0.25)\n  source = small_gicp.voxelgrid_sampling(source_raw, 0.25)\n  # KdTree construction\n  target_tree = small_gicp.KdTree(target)",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "verify_result",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def verify_result(T_target_source, gt_T_target_source):\n  error = numpy.linalg.inv(T_target_source) @ gt_T_target_source\n  error_trans = numpy.linalg.norm(error[:3, 3])\n  error_rot = Rotation.from_matrix(error[:3, :3]).magnitude()\n  assert error_trans < 0.05\n  assert error_rot < 0.05\nimport pytest\n# Load the point clouds and the ground truth transformation matrix\n@pytest.fixture(scope='module', autouse=True)\ndef load_points():",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "load_points",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def load_points():\n  gt_T_target_source = numpy.loadtxt('data/T_target_source.txt')  # Load the ground truth transformation matrix\n  print('--- gt_T_target_source ---')\n  print(gt_T_target_source)\n  target_raw = small_gicp.read_ply(('data/target.ply'))  # Read the target point cloud (small_gicp.PointCloud)\n  source_raw = small_gicp.read_ply(('data/source.ply'))  # Read the source point cloud (small_gicp.PointCloud)\n  target_raw_numpy = target_raw.points()                    # Nx4 numpy array of the target point cloud\n  source_raw_numpy = source_raw.points()                    # Nx4 numpy array of the source point cloud\n  yield (gt_T_target_source, target_raw_numpy, source_raw_numpy)\n# Check if the point clouds are loaded correctly",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "test_load_points",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def test_load_points(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  assert gt_T_target_source.shape[0] == 4 and gt_T_target_source.shape[1] == 4\n  assert len(target_raw_numpy) > 0\n  assert len(source_raw_numpy) > 0\ndef test_example_numpy1(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_numpy1(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\ndef test_example_numpy2(load_points):",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "test_example_numpy1",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def test_example_numpy1(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_numpy1(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\ndef test_example_numpy2(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_numpy2(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\ndef test_example_small1(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "test_example_numpy2",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def test_example_numpy2(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_numpy2(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\ndef test_example_small1(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_small1(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\ndef test_example_small2(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "test_example_small1",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def test_example_small1(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_small1(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\ndef test_example_small2(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_small2(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\nif __name__ == \"__main__\":\n  target_raw = small_gicp.read_ply(('data/target.ply'))  # Read the target point cloud (small_gicp.PointCloud)",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "test_example_small2",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.basic_registration",
        "description": "thirdparty.small_gicp.src.example.basic_registration",
        "peekOfCode": "def test_example_small2(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  T_target_source = example_small2(target_raw_numpy, source_raw_numpy)\n  verify_result(T_target_source, gt_T_target_source)\nif __name__ == \"__main__\":\n  target_raw = small_gicp.read_ply(('data/target.ply'))  # Read the target point cloud (small_gicp.PointCloud)\n  source_raw = small_gicp.read_ply(('data/source.ply'))  # Read the source point cloud (small_gicp.PointCloud)\n  target_raw_numpy = target_raw.points()                    # Nx4 numpy array of the target point cloud\n  source_raw_numpy = source_raw.points()                    # Nx4 numpy array of the source point cloud\n  T_target_source = example_numpy1(target_raw_numpy, source_raw_numpy)",
        "detail": "thirdparty.small_gicp.src.example.basic_registration",
        "documentation": {}
    },
    {
        "label": "ScanToScanMatchingOdometry",
        "kind": 6,
        "importPath": "thirdparty.small_gicp.src.example.kitti_odometry",
        "description": "thirdparty.small_gicp.src.example.kitti_odometry",
        "peekOfCode": "class ScanToScanMatchingOdometry(object):\n  def __init__(self, num_threads):\n    self.num_threads = num_threads\n    self.T_last_current = numpy.identity(4)\n    self.T_world_lidar = numpy.identity(4)\n    self.target = None\n  def estimate(self, raw_points):\n    downsampled, tree = small_gicp.preprocess_points(raw_points, 0.25, num_threads=self.num_threads)\n    if self.target is None:\n      self.target = (downsampled, tree)",
        "detail": "thirdparty.small_gicp.src.example.kitti_odometry",
        "documentation": {}
    },
    {
        "label": "ScanToModelMatchingOdometry",
        "kind": 6,
        "importPath": "thirdparty.small_gicp.src.example.kitti_odometry",
        "description": "thirdparty.small_gicp.src.example.kitti_odometry",
        "peekOfCode": "class ScanToModelMatchingOdometry(object):\n  def __init__(self, num_threads):\n    self.num_threads = num_threads\n    self.T_last_current = numpy.identity(4)\n    self.T_world_lidar = numpy.identity(4)\n    self.target = small_gicp.GaussianVoxelMap(1.0)\n    self.target.set_lru(horizon=100, clear_cycle=10)\n  def estimate(self, raw_points):\n    downsampled, tree = small_gicp.preprocess_points(raw_points, 0.25, num_threads=self.num_threads)\n    if self.target.size() == 0:",
        "detail": "thirdparty.small_gicp.src.example.kitti_odometry",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.example.kitti_odometry",
        "description": "thirdparty.small_gicp.src.example.kitti_odometry",
        "peekOfCode": "def main():\n  parser = argparse.ArgumentParser()\n  parser.add_argument('dataset_path', help='/path/to/kitti/velodyne')\n  parser.add_argument('--num_threads', help='Number of threads', type=int, default=4)\n  parser.add_argument('-m', '--model', help='Use scan-to-model matching odometry', action='store_true')\n  args = parser.parse_args()\n  dataset_path = args.dataset_path\n  filenames = sorted([dataset_path + '/' + x for x in os.listdir(dataset_path) if x.endswith('.bin')])\n  if not args.model:\n    odom = ScanToScanMatchingOdometry(args.num_threads)",
        "detail": "thirdparty.small_gicp.src.example.kitti_odometry",
        "documentation": {}
    },
    {
        "label": "example_small1",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def example_small1(target_raw_numpy : numpy.ndarray, source_raw_numpy : numpy.ndarray):\n  # Convert numpy arrays (Nx3 or Nx4) to small_gicp.PointCloud\n  target_raw = small_gicp.PointCloud(target_raw_numpy)\n  source_raw = small_gicp.PointCloud(source_raw_numpy)\n  # Preprocess point clouds\n  target, target_tree = small_gicp.preprocess_points(target_raw, downsampling_resolution=0.25)\n  source, source_tree = small_gicp.preprocess_points(source_raw, downsampling_resolution=0.25)\n  result = small_gicp.align(target, source, target_tree)\n  return result.T_target_source\n# Example to perform each preprocessing and registration separately",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "example_small2",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def example_small2(target_raw_numpy : numpy.ndarray, source_raw_numpy : numpy.ndarray):\n  # Convert numpy arrays (Nx3 or Nx4) to small_gicp.PointCloud\n  target_raw = small_gicp.PointCloud(target_raw_numpy)\n  source_raw = small_gicp.PointCloud(source_raw_numpy)\n  # Downsampling\n  target = small_gicp.voxelgrid_sampling(target_raw, 0.25)\n  source = small_gicp.voxelgrid_sampling(source_raw, 0.25)\n  # KdTree construction\n  target_tree = small_gicp.KdTree(target)\n  source_tree = small_gicp.KdTree(source)",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "verify_result",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def verify_result(T_target_source, gt_T_target_source):\n  error = numpy.linalg.inv(T_target_source) @ gt_T_target_source\n  error_trans = numpy.linalg.norm(error[:3, 3])\n  error_rot = Rotation.from_matrix(error[:3, :3]).magnitude()\n  assert error_trans < 0.05\n  assert error_rot < 0.05\nimport pytest\n# Load the point clouds and the ground truth transformation matrix\n@pytest.fixture(scope='module', autouse=True)\ndef load_points():",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "load_points",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def load_points():\n  gt_T_target_source = numpy.loadtxt('data/T_target_source.txt')  # Load the ground truth transformation matrix\n  target_raw = small_gicp.read_ply(('data/target.ply'))  # Read the target point cloud (small_gicp.PointCloud)\n  source_raw = small_gicp.read_ply(('data/source.ply'))  # Read the source point cloud (small_gicp.PointCloud)\n  target_raw_numpy = target_raw.points()                    # Nx4 numpy array of the target point cloud\n  source_raw_numpy = source_raw.points()                    # Nx4 numpy array of the source point cloud\n  yield (gt_T_target_source, target_raw_numpy, source_raw_numpy)\n# Check if the point clouds are loaded correctly\ndef test_load_points(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_load_points",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_load_points(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  assert gt_T_target_source.shape[0] == 4 and gt_T_target_source.shape[1] == 4\n  assert len(target_raw_numpy) > 0 and target_raw_numpy.shape[1] == 4\n  assert len(source_raw_numpy) > 0 and source_raw_numpy.shape[1] == 4\n# Basic point cloud test\ndef test_points(load_points):\n  _, points_numpy, _ = load_points\n  points = small_gicp.PointCloud(points_numpy)\n  assert points.size() == points_numpy.shape[0]",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_points",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_points(load_points):\n  _, points_numpy, _ = load_points\n  points = small_gicp.PointCloud(points_numpy)\n  assert points.size() == points_numpy.shape[0]\n  assert numpy.all(numpy.abs(points.points() - points_numpy) < 1e-6)\n  points = small_gicp.PointCloud(points_numpy[:, :3])\n  assert points.size() == points_numpy.shape[0]\n  assert numpy.all(numpy.abs(points.points() - points_numpy) < 1e-6)\n  for i in range(10):\n    assert numpy.all(numpy.abs(points.point(i) - points_numpy[i]) < 1e-6)",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_downsampling",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_downsampling(load_points):\n  _, points_numpy, _ = load_points\n  downsampled = small_gicp.voxelgrid_sampling(points_numpy, 0.25)\n  assert downsampled.size() > 0\n  downsampled2 = small_gicp.voxelgrid_sampling(points_numpy, 0.25, num_threads=2)\n  assert abs(1.0 - downsampled.size() / downsampled2.size()) < 0.05\n  downsampled2 = small_gicp.voxelgrid_sampling(small_gicp.PointCloud(points_numpy), 0.25)\n  assert downsampled.size() == downsampled2.size()\n  downsampled2 = small_gicp.voxelgrid_sampling(small_gicp.PointCloud(points_numpy), 0.25, num_threads=2)\n  assert abs(1.0 - downsampled.size() / downsampled2.size()) < 0.05",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_preprocess",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_preprocess(load_points):\n  _, points_numpy, _ = load_points\n  downsampled, _ = small_gicp.preprocess_points(points_numpy, downsampling_resolution=0.25)\n  assert downsampled.size() > 0\n  downsampled2, _ = small_gicp.preprocess_points(points_numpy, downsampling_resolution=0.25, num_threads=2)\n  assert abs(1.0 - downsampled.size() / downsampled2.size()) < 0.05\n  downsampled2, _ = small_gicp.preprocess_points(small_gicp.PointCloud(points_numpy), downsampling_resolution=0.25)\n  assert downsampled.size() == downsampled2.size()\n  downsampled2, _ = small_gicp.preprocess_points(small_gicp.PointCloud(points_numpy), downsampling_resolution=0.25, num_threads=2)\n  assert abs(1.0 - downsampled.size() / downsampled2.size()) < 0.05",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_voxelmap",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_voxelmap(load_points):\n  _, points_numpy, _ = load_points\n  downsampled = small_gicp.voxelgrid_sampling(points_numpy, 0.25)\n  small_gicp.estimate_covariances(downsampled)\n  voxelmap = small_gicp.GaussianVoxelMap(0.5)\n  voxelmap.insert(downsampled)\n  assert voxelmap.size() > 0\n  assert voxelmap.size() == len(voxelmap)\n# Factor test\ndef test_factors(load_points):",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_factors",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_factors(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  target, target_tree = small_gicp.preprocess_points(target_raw_numpy, downsampling_resolution=0.25)\n  source, source_tree = small_gicp.preprocess_points(source_raw_numpy, downsampling_resolution=0.25)\n  result = small_gicp.align(target, source, target_tree, gt_T_target_source)\n  result = small_gicp.align(target, source, target_tree, result.T_target_source)\n  factors = [small_gicp.GICPFactor()]\n  rejector = small_gicp.DistanceRejector()\n  sum_H = numpy.zeros((6, 6))\n  sum_b = numpy.zeros(6)",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_registration",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_registration(load_points):\n  gt_T_target_source, target_raw_numpy, source_raw_numpy = load_points\n  result = small_gicp.align(target_raw_numpy, source_raw_numpy, downsampling_resolution=0.25)\n  verify_result(result.T_target_source, gt_T_target_source)\n  result = small_gicp.align(target_raw_numpy, source_raw_numpy, downsampling_resolution=0.25, num_threads=2)\n  verify_result(result.T_target_source, gt_T_target_source)\n  target, target_tree = small_gicp.preprocess_points(target_raw_numpy, downsampling_resolution=0.25)\n  source, source_tree = small_gicp.preprocess_points(source_raw_numpy, downsampling_resolution=0.25)\n  result = small_gicp.align(target, source)\n  verify_result(result.T_target_source, gt_T_target_source)",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    },
    {
        "label": "test_kdtree",
        "kind": 2,
        "importPath": "thirdparty.small_gicp.src.test.python_test",
        "description": "thirdparty.small_gicp.src.test.python_test",
        "peekOfCode": "def test_kdtree(load_points):\n  _, target_raw_numpy, source_raw_numpy = load_points\n  target, target_tree = small_gicp.preprocess_points(target_raw_numpy, downsampling_resolution=0.5)\n  source, source_tree = small_gicp.preprocess_points(source_raw_numpy, downsampling_resolution=0.5)\n  target_tree_ref = KDTree(target.points())\n  source_tree_ref = KDTree(source.points())\n  def batch_test(points, queries, tree, tree_ref, num_threads):\n    # test for batch interface\n    k_dists_ref, k_indices_ref = tree_ref.query(queries, k=1)\n    k_indices, k_sq_dists = tree.batch_nearest_neighbor_search(queries)",
        "detail": "thirdparty.small_gicp.src.test.python_test",
        "documentation": {}
    }
]
